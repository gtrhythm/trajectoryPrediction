{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#global variable\n",
    "doNormalization=True\n",
    "useGpu=False\n",
    "runOnG814=False\n",
    "isTest=True\n",
    "modelPath='/home/wangyuchen/wholeNet_300epoch_50perEpoch.pt'\n",
    "maxMatrixIndex=250\n",
    "runRelationLSTM=False\n",
    "runObjectRelationNet=False\n",
    "runSeq2SeqRelationModel=True\n",
    "runLSTM=False\n",
    "\n",
    "maxRelationsNumberGlobal=20 # the maximum nubmer of relation in the \"relation within the given range\" version \n",
    "\n",
    "if useGpu:\n",
    "    import os\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fromAllToStr(*args):\n",
    "    returnedStr=str()\n",
    "    for eachItem in args:\n",
    "        returnedStr=returnedStr+str(eachItem)\n",
    "    return returnedStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename='logging.txt',level=logging.DEBUG, format='%(asctime)s -%(lineno)d - %(funcName)s - %(levelname)s - %(message)s',)\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s -%(lineno)d - %(funcName)s - %(levelname)s - %(message)s')\n",
    "console.setFormatter(formatter)\n",
    "logging.getLogger('').addHandler(console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a tuple in which each element is the index of a vehicle\n",
    "#the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "listForEachVehicle=[]\n",
    "for i in range(maxMatrixIndex):\n",
    "    listForEachVehicle.append(i*(maxMatrixIndex-1))\n",
    "tupleForEachVehicle=tuple(listForEachVehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def getValueByLable(lableList,valueList):\n",
    "    \"\"\"\n",
    "    For instance, given a lable list ['Local_X','Local_Y'] and a value list [2.0, 24.0, 437.0, 1118846981300.0, 16.254, \n",
    "    79.349, 6451167.199, 1873312.382, 14.5, 4.9, 2.0, 39.14, -5.73, 2.0, 0.0, 13.0, 0.0, 0.0] which values sorted by the \n",
    "    order of allLableList below, the function return a value Dict {'Local_X':16.254, 'Local_Y':79.349}\n",
    "    Args:\n",
    "        lableList: the list of lables you've required, such as['Vehicle_ID', 'Total_Frames','Global_Time']\n",
    "        valueList: the list contains all legally value, sorted by:['Vehicle_ID', 'Frame_ID','Total_Frames','Global_Time','Local_X','Local_Y','Global_X','Global_Y',\\\n",
    "                      'v_Length','v_Width','v_Class','v_Vel','v_Acc','Lane_ID','Preceding','Following','Space_Headway',\\\n",
    "                      'Time_Headway']\n",
    "    Returns: \n",
    "        value dict of the input lables\n",
    "    For instance, given a lable list ['Local_X','Local_Y'] and a value list [2.0, 24.0, 437.0, 1118846981300.0, 16.254, \n",
    "    79.349, 6451167.199, 1873312.382, 14.5, 4.9, 2.0, 39.14, -5.73, 2.0, 0.0, 13.0, 0.0, 0.0] which values sorted by the \n",
    "    order of allLableList above, the function return a value List [16.254, 79.349]\n",
    "\n",
    "    \"\"\"\n",
    "    allLableList=['Vehicle_ID', 'Frame_ID','Total_Frames','Global_Time','Local_X','Local_Y','Global_X','Global_Y',\\\n",
    "                  'v_Length','v_Width','v_Class','v_Vel','v_Acc','Lane_ID','Preceding','Following','Space_Headway',\\\n",
    "                  'Time_Headway']\n",
    "    valueDictReturn={}\n",
    "    for lableItem in lableList:\n",
    "        valueDictReturn[lableItem]=valueList[allLableList.index(lableItem)]\n",
    "    return valueDictReturn\n",
    "\n",
    "def rearrangeDataByGlobalTime(allValueLists):\n",
    "    '''\n",
    "    Args:\n",
    "        allValueLists: all values have been read from a txt file which have already been converted to a list\n",
    "    Returns:\n",
    "        dict have been arranged by global time. One single global time generally contains several value lists.\n",
    "    '''\n",
    "    valueDict={}\n",
    "    for valueList in allValueLists:\n",
    "        dictKey=getValueByLable(['Global_Time'],valueList)['Global_Time']\n",
    "        if dictKey in valueDict:\n",
    "            # if dictKey already there, then add valueList to the list of the key\n",
    "            valueDict[dictKey].append(valueList)\n",
    "        else:\n",
    "            #else, create a list and append valueList on it\n",
    "            valueDict[dictKey]=[valueList]\n",
    "    return valueDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def readFirstFrame(matrixIndexAndVehicleIDRecordDictParam, valueLists):\n",
    "    \"\"\"\n",
    "    To generate the first set of tensors from the first frame\n",
    "    Args:\n",
    "        matrixIndexAndVehicleIDRecordDictParam: just as its name\n",
    "        valueLists: a list consists of all valuelist at one time\n",
    "    Returns:\n",
    "        several tensors arranged by: positionTensor, speedTensor, accTensor, angleTensor,newVehicleList(type:list)\n",
    "    \n",
    "    \"\"\"\n",
    "    maxMatrixIndex=matrixIndexAndVehicleIDRecordDictParam.keys().__len__()-1\n",
    "    #tensors initialize\n",
    "    positionTensor=torch.zeros(2,maxMatrixIndex)\n",
    "    speedTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    accTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    angleTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    newVehicleIDList=[]\n",
    "    curMatrixIndex=0\n",
    "    matrixIndexAndVehicleIDRecordDictParam['time']=getValueByLable([\"Global_Time\"],valueLists[0])['Global_Time']\n",
    "    #fill out all tensors\n",
    "    for eachValueList in valueLists:\n",
    "        #get values from eachValueList, generate dict\n",
    "        returnedEachValueDict=getValueByLable(['Vehicle_ID','Local_X','Local_Y','v_Vel','v_Acc'],eachValueList)\n",
    "        #assign to the curMatrixIndex-th row of corresponding tensor\n",
    "        #angle Tensor assignment is not neeed for the initial value of each element in it is already zero\n",
    "        positionTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['Local_X'],returnedEachValueDict['Local_Y']))\n",
    "        speedTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Vel']))\n",
    "        accTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Acc']))\n",
    "        #then handle the record matrix\n",
    "        matrixIndexAndVehicleIDRecordDictParam[curMatrixIndex]['Vehicle_ID']=returnedEachValueDict['Vehicle_ID']\n",
    "        matrixIndexAndVehicleIDRecordDictParam[curMatrixIndex]['refresh']=0\n",
    "        newVehicleIDList.append(copy.deepcopy(returnedEachValueDict['Vehicle_ID']))\n",
    "        curMatrixIndex=curMatrixIndex+1\n",
    "    return positionTensor,speedTensor,accTensor,angleTensor,newVehicleIDList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMatrixIndexByVehicleID(matrixIndexAndVehicleIDRecordDictParam, vehicle_ID):\n",
    "    for i in range(0, len(matrixIndexAndVehicleIDRecordDictParam)-1):\n",
    "        if matrixIndexAndVehicleIDRecordDictParam[i]['Vehicle_ID']==vehicle_ID:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def findEmptyMatrixIndex(matrixIndexAndVehicleIDRecordDictParam):\n",
    "    for i in range(0, len(matrixIndexAndVehicleIDRecordDictParam)-1):\n",
    "        if matrixIndexAndVehicleIDRecordDictParam[i]['Vehicle_ID']==-1:\n",
    "            #Vehicle_ID=-1 when there is no existed vehicle ID bounding to the index\n",
    "            return i\n",
    "    raise Exception(\"NO EMPTY ELEMENT IN MATRIX\")\n",
    "\n",
    "def readGeneralFrame(matrixIndexAndVehicleIDRecordDictParam, valueLists, prePositionTensor):\n",
    "    \"\"\"\n",
    "    To generate the first set of tensors from the general frame that have a preceding one.\n",
    "    In this version, we ignore the new vehicle appeared among a serial of frame.\n",
    "    Args:\n",
    "        matrixIndexAndVehicleIDRecordDictParam: just as its name\n",
    "        valueLists: a list consists of all valuelist at one time\n",
    "        prePositionTensor: positionTensor from the preceding frame, which is used to calculate angle tensor\n",
    "    Returns:\n",
    "        everal tensors arranged by: positionTensor, speedTensor, accTensor, angleTensor,newVehicleList(type:list),\n",
    "        vanishedVehicleList(type:list)\n",
    "    \n",
    "    \"\"\"\n",
    "    #tensors initialize\n",
    "    maxMatrixIndex=matrixIndexAndVehicleIDRecordDictParam.keys().__len__()-1\n",
    "    positionTensor=torch.zeros(2,maxMatrixIndex)\n",
    "    speedTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    accTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    angleTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    newVehicleIDList=[]\n",
    "    vanishedVehicleList=[]\n",
    "    curMatrixIndex=0\n",
    "    matrixIndexAndVehicleIDRecordDictParam['time']=getValueByLable([\"Global_Time\"],valueLists[0])['Global_Time']\n",
    "    #fill out all tensors\n",
    "    for eachValueList in valueLists:\n",
    "        #get values from eachValueList, generate dict\n",
    "        returnedEachValueDict=getValueByLable(['Vehicle_ID','Local_X','Local_Y','v_Vel','v_Acc'],eachValueList)\n",
    "        indexOfVehicle=findMatrixIndexByVehicleID(matrixIndexAndVehicleIDRecordDictParam,returnedEachValueDict['Vehicle_ID'])\n",
    "        if indexOfVehicle!=-1:\n",
    "        #if index exist then the vehicle already existed in the preceded frame\n",
    "            matrixIndexAndVehicleIDRecordDictParam[indexOfVehicle]['refresh']=1\n",
    "            curMatrixIndex=indexOfVehicle\n",
    "            #assign to the curMatrixIndex-th row of corresponding tensor\n",
    "            positionTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['Local_X'],returnedEachValueDict['Local_Y']))\n",
    "            speedTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Vel']))\n",
    "            accTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Acc']))\n",
    "            angleTensor[:,curMatrixIndex]=math.atan2(positionTensor[0,curMatrixIndex]-\\\n",
    "                                                     prePositionTensor[0,curMatrixIndex],\\\n",
    "                                                    positionTensor[1,curMatrixIndex]-prePositionTensor[1,curMatrixIndex])\n",
    "        else:\n",
    "            pass #ignore new vehicleID\n",
    "        #a new vehicle ID\n",
    "#             newVehicleIDList.append(copy.deepcopy(returnedEachValueDict['Vehicle_ID']))\n",
    "#             curMatrixIndex=findEmptyMatrixIndex(matrixIndexAndVehicleIDRecordDictParam)\n",
    "#             matrixIndexAndVehicleIDRecordDictParam[curMatrixIndex]['Vehicle_ID']=copy.deepcopy(returnedEachValueDict['Vehicle_ID'])\n",
    "#             matrixIndexAndVehicleIDRecordDictParam[curMatrixIndex]['refresh']=1\n",
    "#             #assign to the curMatrixIndex-th row of corresponding tensor\n",
    "#             positionTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['Local_X'],returnedEachValueDict['Local_Y']))\n",
    "#             speedTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Vel']))\n",
    "#             accTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Acc']))\n",
    "#             angleTensor[:,curMatrixIndex]=math.atan2(positionTensor[0,curMatrixIndex]-\\\n",
    "#                                                      prePositionTensor[0,curMatrixIndex],\\\n",
    "#                                                     positionTensor[1,curMatrixIndex]-prePositionTensor[1,curMatrixIndex])\n",
    "    for i in range(0,maxMatrixIndex):\n",
    "    #find vanished vehicle and remove from dict\n",
    "        if matrixIndexAndVehicleIDRecordDictParam[i]['refresh']==0:\n",
    "            #if refresh=0 then the corresponding vehicle ID was not found in this frame\n",
    "            vanishedVehicleList.append(copy.deepcopy(matrixIndexAndVehicleIDRecordDictParam[i]['Vehicle_ID']))\n",
    "            matrixIndexAndVehicleIDRecordDictParam[i]['refresh']=-1\n",
    "            matrixIndexAndVehicleIDRecordDictParam[i]['Vehicle_ID']=-1\n",
    "    \n",
    "    for i in range(0,maxMatrixIndex):\n",
    "    #set all refrshed which equivalent to 1 to 0 to prepare for the next frame\n",
    "        if matrixIndexAndVehicleIDRecordDictParam[i]['refresh']==1:\n",
    "                #if refresh=0 then the corresponding vehicle ID was not found in this frame\n",
    "                matrixIndexAndVehicleIDRecordDictParam[i]['refresh']=0\n",
    "\n",
    "    return positionTensor,speedTensor,accTensor,angleTensor,newVehicleIDList,vanishedVehicleList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-08 21:12:09,408 -276 - wrapper - DEBUG - $HOME=/home/wangyuchen\n",
      "2020-08-08 21:12:09,409 -276 - wrapper - DEBUG - CONFIGDIR=/home/wangyuchen/.config/matplotlib\n",
      "2020-08-08 21:12:09,410 -276 - wrapper - DEBUG - matplotlib data path: /home/wangyuchen/.conda/envs/pytorch/lib/python3.6/site-packages/matplotlib/mpl-data\n",
      "2020-08-08 21:12:09,414 -1007 - rc_params_from_file - DEBUG - loaded rc file /home/wangyuchen/.conda/envs/pytorch/lib/python3.6/site-packages/matplotlib/mpl-data/matplotlibrc\n",
      "2020-08-08 21:12:09,416 -1644 - <module> - DEBUG - matplotlib version 3.1.3\n",
      "2020-08-08 21:12:09,416 -1645 - <module> - DEBUG - interactive is False\n",
      "2020-08-08 21:12:09,417 -1646 - <module> - DEBUG - platform is linux\n",
      "2020-08-08 21:12:09,418 -1647 - <module> - DEBUG - loaded modules: ['builtins', 'sys', '_frozen_importlib', '_imp', '_warnings', '_thread', '_weakref', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'zipimport', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_weakrefset', '_bootlocale', '_locale', 'site', 'os', 'errno', 'stat', '_stat', 'posixpath', 'genericpath', 'os.path', '_collections_abc', '_sitebuiltins', 'sysconfig', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'types', 'functools', '_functools', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'weakref', 'collections.abc', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'mpl_toolkits', 'runpy', 'pkgutil', 'ipykernel', 'ipykernel._version', 'ipykernel.connect', '__future__', 'json', 'json.decoder', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'copyreg', 'json.scanner', '_json', 'json.encoder', 'subprocess', 'time', 'signal', '_posixsubprocess', 'select', 'selectors', 'math', 'threading', 'traceback', 'linecache', 'tokenize', 'token', 'IPython', 'IPython.core', 'IPython.core.getipython', 'IPython.core.release', 'IPython.core.application', 'atexit', 'copy', 'glob', 'fnmatch', 'logging', 'string', '_string', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'traitlets', 'traitlets.traitlets', 'inspect', 'ast', '_ast', 'dis', 'opcode', '_opcode', 'six', 'struct', '_struct', 'traitlets.utils', 'traitlets.utils.getargspec', 'traitlets.utils.importstring', 'ipython_genutils', 'ipython_genutils._version', 'ipython_genutils.py3compat', 'ipython_genutils.encoding', 'locale', 'platform', 'traitlets.utils.sentinel', 'traitlets.utils.bunch', 'traitlets._version', 'traitlets.config', 'traitlets.config.application', 'decorator', 'traitlets.config.configurable', 'traitlets.config.loader', 'argparse', 'textwrap', 'gettext', 'ipython_genutils.path', 'random', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'ipython_genutils.text', 'ipython_genutils.importstring', 'IPython.core.crashhandler', 'pprint', 'IPython.core.ultratb', 'pydoc', 'urllib', 'urllib.parse', 'IPython.core.debugger', 'bdb', 'IPython.utils', 'IPython.utils.PyColorize', 'IPython.utils.coloransi', 'IPython.utils.ipstruct', 'IPython.utils.colorable', 'pygments', 'pygments.util', 'IPython.utils.py3compat', 'IPython.utils.encoding', 'IPython.core.excolors', 'IPython.testing', 'IPython.testing.skipdoctest', 'pdb', 'cmd', 'code', 'codeop', 'IPython.core.display_trap', 'IPython.utils.path', 'IPython.utils.process', 'IPython.utils._process_posix', 'pexpect', 'pexpect.exceptions', 'pexpect.utils', 'pexpect.expect', 'pexpect.pty_spawn', 'pty', 'tty', 'termios', 'ptyprocess', 'ptyprocess.ptyprocess', 'fcntl', 'resource', 'ptyprocess.util', 'pexpect.spawnbase', 'pexpect.run', 'IPython.utils._process_common', 'shlex', 'IPython.utils.decorators', 'IPython.utils.data', 'IPython.utils.terminal', 'IPython.utils.sysinfo', 'IPython.utils._sysinfo', 'IPython.core.profiledir', 'IPython.paths', 'tempfile', 'IPython.utils.importstring', 'IPython.terminal', 'IPython.terminal.embed', 'IPython.core.compilerop', 'IPython.core.magic_arguments', 'IPython.core.error', 'IPython.utils.text', 'pathlib', 'ntpath', 'IPython.core.magic', 'getopt', 'IPython.core.oinspect', 'typing', 'typing.io', 'typing.re', 'IPython.core.page', 'IPython.core.display', 'binascii', 'mimetypes', 'IPython.lib', 'IPython.lib.security', 'getpass', 'IPython.lib.pretty', 'datetime', '_datetime', 'IPython.utils.openpy', 'IPython.utils.dir2', 'IPython.utils.wildcard', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.plugin', 'pygments.lexers.python', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.token', 'pygments.regexopt', 'pygments.unistring', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'IPython.core.inputtransformer2', 'IPython.core.interactiveshell', 'pickleshare', 'pickle', '_compat_pickle', '_pickle', 'IPython.core.prefilter', 'IPython.core.autocall', 'IPython.core.macro', 'IPython.core.splitinput', 'IPython.core.alias', 'IPython.core.builtin_trap', 'IPython.core.events', 'backcall', 'backcall.backcall', 'IPython.core.displayhook', 'IPython.core.displaypub', 'IPython.core.extensions', 'IPython.core.formatters', 'IPython.utils.sentinel', 'IPython.core.history', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'IPython.core.logger', 'IPython.core.payload', 'IPython.core.usage', 'IPython.display', 'IPython.lib.display', 'html', 'html.entities', 'IPython.utils.io', 'IPython.utils.capture', 'IPython.utils.strdispatch', 'IPython.core.hooks', 'IPython.utils.syspathcontext', 'IPython.utils.tempdir', 'IPython.utils.contexts', 'IPython.core.async_helpers', 'IPython.terminal.interactiveshell', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'concurrent.futures.process', 'queue', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'socket', '_socket', 'array', '__mp_main__', 'multiprocessing.connection', '_multiprocessing', 'multiprocessing.util', 'concurrent.futures.thread', 'asyncio.compat', 'asyncio.coroutines', 'asyncio.constants', 'asyncio.events', 'asyncio.base_futures', 'asyncio.log', 'asyncio.futures', 'asyncio.base_tasks', '_asyncio', 'asyncio.tasks', 'asyncio.locks', 'asyncio.protocols', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.transports', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'ssl', 'ipaddress', '_ssl', 'base64', 'asyncio.sslproto', 'prompt_toolkit', 'prompt_toolkit.application', 'prompt_toolkit.application.application', 'prompt_toolkit.buffer', 'prompt_toolkit.application.current', 'prompt_toolkit.eventloop', 'prompt_toolkit.eventloop.async_generator', 'prompt_toolkit.eventloop.utils', 'prompt_toolkit.eventloop.dummy_contextvars', 'prompt_toolkit.eventloop.inputhook', 'prompt_toolkit.utils', 'wcwidth', 'wcwidth.wcwidth', 'wcwidth.table_wide', 'wcwidth.table_zero', 'prompt_toolkit.application.run_in_terminal', 'prompt_toolkit.eventloop.async_context_manager', 'prompt_toolkit.auto_suggest', 'prompt_toolkit.document', 'prompt_toolkit.clipboard', 'prompt_toolkit.clipboard.base', 'prompt_toolkit.selection', 'prompt_toolkit.clipboard.in_memory', 'prompt_toolkit.filters', 'prompt_toolkit.filters.app', 'prompt_toolkit.cache', 'prompt_toolkit.enums', 'prompt_toolkit.filters.base', 'prompt_toolkit.filters.cli', 'prompt_toolkit.filters.utils', 'prompt_toolkit.completion', 'prompt_toolkit.completion.base', 'prompt_toolkit.formatted_text', 'prompt_toolkit.formatted_text.ansi', 'prompt_toolkit.output', 'prompt_toolkit.output.base', 'prompt_toolkit.data_structures', 'prompt_toolkit.styles', 'prompt_toolkit.styles.base', 'prompt_toolkit.styles.defaults', 'prompt_toolkit.styles.named_colors', 'prompt_toolkit.styles.style', 'prompt_toolkit.styles.pygments', 'prompt_toolkit.styles.style_transformation', 'colorsys', 'prompt_toolkit.output.color_depth', 'prompt_toolkit.output.defaults', 'prompt_toolkit.patch_stdout', 'prompt_toolkit.output.vt100', 'prompt_toolkit.formatted_text.base', 'prompt_toolkit.mouse_events', 'prompt_toolkit.formatted_text.html', 'xml', 'xml.dom', 'xml.dom.domreg', 'xml.dom.minidom', 'xml.dom.minicompat', 'xml.dom.xmlbuilder', 'xml.dom.NodeFilter', 'prompt_toolkit.formatted_text.pygments', 'prompt_toolkit.formatted_text.utils', 'prompt_toolkit.completion.filesystem', 'prompt_toolkit.completion.fuzzy_completer', 'prompt_toolkit.completion.word_completer', 'prompt_toolkit.completion.nested', 'prompt_toolkit.history', 'prompt_toolkit.search', 'prompt_toolkit.key_binding', 'prompt_toolkit.key_binding.key_bindings', 'prompt_toolkit.keys', 'prompt_toolkit.key_binding.key_processor', 'prompt_toolkit.key_binding.vi_state', 'prompt_toolkit.validation', 'prompt_toolkit.input', 'prompt_toolkit.input.base', 'prompt_toolkit.input.defaults', 'prompt_toolkit.input.typeahead', 'prompt_toolkit.key_binding.bindings', 'prompt_toolkit.key_binding.bindings.page_navigation', 'prompt_toolkit.key_binding.bindings.scroll', 'prompt_toolkit.key_binding.defaults', 'prompt_toolkit.key_binding.bindings.basic', 'prompt_toolkit.key_binding.bindings.named_commands', 'prompt_toolkit.layout', 'prompt_toolkit.layout.containers', 'prompt_toolkit.layout.controls', 'prompt_toolkit.lexers', 'prompt_toolkit.lexers.base', 'prompt_toolkit.lexers.pygments', 'prompt_toolkit.layout.processors', 'prompt_toolkit.layout.utils', 'prompt_toolkit.layout.dimension', 'prompt_toolkit.layout.margins', 'prompt_toolkit.layout.mouse_handlers', 'prompt_toolkit.layout.screen', 'prompt_toolkit.layout.layout', 'prompt_toolkit.layout.menus', 'prompt_toolkit.key_binding.bindings.completion', 'prompt_toolkit.key_binding.bindings.cpr', 'prompt_toolkit.key_binding.bindings.emacs', 'prompt_toolkit.key_binding.bindings.mouse', 'prompt_toolkit.key_binding.bindings.vi', 'prompt_toolkit.input.vt100_parser', 'prompt_toolkit.input.ansi_escape_sequences', 'prompt_toolkit.key_binding.digraphs', 'prompt_toolkit.key_binding.emacs_state', 'prompt_toolkit.layout.dummy', 'prompt_toolkit.renderer', 'prompt_toolkit.application.dummy', 'prompt_toolkit.shortcuts', 'prompt_toolkit.shortcuts.dialogs', 'prompt_toolkit.key_binding.bindings.focus', 'prompt_toolkit.widgets', 'prompt_toolkit.widgets.base', 'prompt_toolkit.widgets.toolbars', 'prompt_toolkit.widgets.dialogs', 'prompt_toolkit.widgets.menus', 'prompt_toolkit.shortcuts.progress_bar', 'prompt_toolkit.shortcuts.progress_bar.base', 'prompt_toolkit.shortcuts.progress_bar.formatters', 'prompt_toolkit.shortcuts.prompt', 'prompt_toolkit.key_binding.bindings.auto_suggest', 'prompt_toolkit.key_binding.bindings.open_in_editor', 'prompt_toolkit.shortcuts.utils', 'pygments.style', 'IPython.terminal.debugger', 'IPython.core.completer', 'unicodedata', 'IPython.core.latex_symbols', 'IPython.utils.generics', 'jedi', 'jedi.api', 'parso', 'parso.parser', 'parso.tree', 'parso._compatibility', 'parso.utils', 'parso.pgen2', 'parso.pgen2.generator', 'parso.pgen2.grammar_parser', 'parso.python', 'parso.python.tokenize', 'parso.python.token', 'parso.grammar', 'parso.python.diff', 'difflib', 'parso.python.parser', 'parso.python.tree', 'parso.python.prefix', 'parso.cache', 'gc', 'parso.python.errors', 'parso.normalizer', 'parso.python.pep8', 'parso.file_io', 'jedi._compatibility', 'jedi.file_io', 'jedi.parser_utils', 'jedi.debug', 'jedi.settings', 'jedi.cache', 'jedi.api.classes', 'jedi.inference', 'jedi.inference.imports', 'jedi.inference.sys_path', 'jedi.inference.cache', 'jedi.inference.base_value', 'jedi.common', 'jedi.common.value', 'jedi.inference.helpers', 'jedi.inference.utils', 'jedi.common.utils', 'jedi.inference.compiled', 'jedi.inference.compiled.value', 'jedi.inference.filters', 'jedi.inference.flow_analysis', 'jedi.inference.recursion', 'jedi.inference.names', 'jedi.inference.docstrings', 'jedi.inference.lazy_value', 'jedi.plugins', 'jedi.inference.compiled.access', 'jedi.inference.compiled.getattr_static', 'jedi.inference.signature', 'jedi.inference.context', 'jedi.inference.analysis', 'jedi.inference.gradual', 'jedi.inference.gradual.typeshed', 'jedi.inference.gradual.stub_value', 'jedi.inference.value', 'jedi.inference.value.module', 'jedi.inference.value.klass', 'jedi.inference.arguments', 'jedi.inference.value.iterable', 'jedi.inference.value.dynamic_arrays', 'jedi.inference.value.function', 'jedi.inference.parser_cache', 'jedi.inference.gradual.generics', 'jedi.inference.value.instance', 'jedi.inference.gradual.typing', 'jedi.inference.gradual.base', 'jedi.inference.gradual.type_var', 'jedi.inference.syntax_tree', 'jedi.inference.gradual.annotation', 'jedi.inference.param', 'jedi.inference.value.decorator', 'jedi.inference.gradual.conversion', 'jedi.api.keywords', 'pydoc_data', 'pydoc_data.topics', 'jedi.api.completion_cache', 'jedi.api.helpers', 'jedi.api.interpreter', 'jedi.inference.compiled.mixed', 'jedi.api.completion', 'jedi.api.strings', 'jedi.api.file_name', 'jedi.api.environment', 'filecmp', 'jedi.inference.compiled.subprocess', 'jedi.inference.compiled.subprocess.functions', 'jedi.api.exceptions', 'jedi.api.project', 'jedi.inference.references', 'jedi.inference.gradual.utils', 'jedi.plugins.registry', 'jedi.plugins.stdlib', 'jedi.plugins.flask', 'jedi.plugins.pytest', 'IPython.terminal.ptutils', 'IPython.terminal.shortcuts', 'IPython.terminal.magics', 'IPython.lib.clipboard', 'IPython.terminal.pt_inputhooks', 'IPython.terminal.prompts', 'IPython.terminal.ipapp', 'IPython.core.magics', 'IPython.core.magics.auto', 'IPython.core.magics.basic', 'IPython.core.magics.code', 'urllib.request', 'email', 'http', 'http.client', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'email._parseaddr', 'calendar', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'urllib.error', 'urllib.response', 'IPython.core.magics.config', 'IPython.core.magics.display', 'IPython.core.magics.execution', 'timeit', 'cProfile', '_lsprof', 'profile', 'optparse', 'pstats', 'IPython.utils.module_paths', 'IPython.utils.timing', 'IPython.core.magics.extension', 'IPython.core.magics.history', 'IPython.core.magics.logging', 'IPython.core.magics.namespace', 'IPython.core.magics.osm', 'IPython.core.magics.packaging', 'IPython.core.magics.pylab', 'IPython.core.pylabtools', 'IPython.core.magics.script', 'IPython.lib.backgroundjobs', 'IPython.core.shellapp', 'IPython.extensions', 'IPython.extensions.storemagic', 'IPython.utils.frame', 'jupyter_client', 'jupyter_client._version', 'jupyter_client.connect', 'zmq', 'ctypes', '_ctypes', 'ctypes._endian', 'zmq.backend', 'zmq.backend.select', 'zmq.backend.cython', 'zmq.backend.cython.constants', 'cython_runtime', 'zmq.backend.cython.error', '_cython_0_29_14', 'zmq.backend.cython.message', 'zmq.error', 'zmq.backend.cython.context', 'zmq.backend.cython.socket', 'zmq.backend.cython.utils', 'zmq.backend.cython._poll', 'zmq.backend.cython._version', 'zmq.backend.cython._device', 'zmq.backend.cython._proxy_steerable', 'zmq.sugar', 'zmq.sugar.constants', 'zmq.utils', 'zmq.utils.constant_names', 'zmq.sugar.context', 'zmq.sugar.attrsettr', 'zmq.sugar.socket', 'zmq.sugar.poll', 'zmq.utils.jsonapi', 'zmq.utils.strtypes', 'zmq.sugar.frame', 'zmq.sugar.tracker', 'zmq.sugar.version', 'zmq.sugar.stopwatch', 'jupyter_client.localinterfaces', 'jupyter_core', 'jupyter_core.version', 'jupyter_core.paths', 'jupyter_client.launcher', 'traitlets.log', 'jupyter_client.client', 'jupyter_client.channels', 'jupyter_client.channelsabc', 'jupyter_client.clientabc', 'jupyter_client.manager', 'jupyter_client.kernelspec', 'jupyter_client.managerabc', 'jupyter_client.blocking', 'jupyter_client.blocking.client', 'jupyter_client.blocking.channels', 'jupyter_client.multikernelmanager', 'uuid', 'ctypes.util', 'ipykernel.kernelapp', 'tornado', 'tornado.ioloop', 'numbers', 'tornado.concurrent', 'tornado.log', 'logging.handlers', 'tornado.escape', 'tornado.util', 'tornado.speedups', 'curses', '_curses', 'zmq.eventloop', 'zmq.eventloop.ioloop', 'tornado.platform', 'tornado.platform.asyncio', 'tornado.gen', 'zmq.eventloop.zmqstream', 'ipykernel.iostream', 'imp', 'jupyter_client.session', 'hmac', 'jupyter_client.jsonutil', 'dateutil', 'dateutil._version', 'dateutil.parser', 'dateutil.parser._parser', 'decimal', '_decimal', 'dateutil.relativedelta', 'dateutil._common', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.parser.isoparser', '_strptime', 'jupyter_client.adapter', 'ipykernel.heartbeat', 'ipykernel.ipkernel', 'IPython.utils.tokenutil', 'ipykernel.comm', 'ipykernel.comm.manager', 'ipykernel.comm.comm', 'ipykernel.kernelbase', 'tornado.queues', 'tornado.locks', 'ipykernel.jsonutil', 'ipykernel.zmqshell', 'IPython.core.payloadpage', 'ipykernel.displayhook', 'ipykernel.eventloops', 'distutils', 'distutils.version', 'ipykernel.parentpoller', 'faulthandler', 'ipykernel.datapub', 'ipykernel.serialize', 'ipykernel.pickleutil', 'ipykernel.codeutil', 'IPython.core.completerlib', 'storemagic', 'jedi.inference.finder', 'jedi.inference.dynamic_params', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'mkl._mklinit', 'mkl._py_mkl_service', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'numpy.core.umath', 'numpy.core.numerictypes', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'numpy.lib._iotools', 'numpy.lib.financial', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random._bit_generator', 'numpy.random._common', 'secrets', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'tarfile', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'zipfile', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'pandas', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'pandas.compat', 'pandas.compat.numpy', 'pandas._libs', 'pandas._libs.tslibs', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.c_timestamp', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.ccalendar', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'pandas._libs.tslibs.fields', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.frequencies', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.timestamps', 'pandas._libs.tslibs.resolution', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.ops_dispatch', 'pandas._libs.lib', 'fractions', 'pandas._libs.tslib', 'pandas.core', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes', 'pandas.core.dtypes.dtypes', 'pandas._libs.interval', 'pandas._libs.algos', 'pandas._typing', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.inference', 'pandas.core.dtypes.missing', 'pandas.core.dtypes.common', 'pandas.core.algorithms', 'pandas.util', 'pandas.util._decorators', 'pandas._libs.properties', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.hashing', 'pandas.core.dtypes.cast', 'pandas.util._validators', 'pandas.core.common', 'pandas.core.construction', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.ops', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.ops.missing', 'pandas.core.ops.roperator', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.nanops', 'pandas.core.arrays.masked', 'pandas.core.arrays.categorical', 'pandas.core.accessor', 'pandas.core.base', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.tseries.offsets', 'dateutil.easter', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.indexes.frozen', 'pandas.io.formats.printing', 'pandas.core.strings', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.core.arrays.string_', 'pandas.core.arrays.timedeltas', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.core.indexes.interval', 'pandas.util._exceptions', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas._libs.internals', 'pandas.core.internals.managers', 'pandas.core.internals.concat', 'pandas.io.formats.format', 'pandas.io.common', 'gzip', 'mmap', 'pandas.core.internals.construction', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.window.common', 'pandas.core.groupby.base', 'pandas.core.window.rolling', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.expanding', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.ops', 'pandas._libs.reduction', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.expr', 'pandas.core.computation.parsing', 'pandas.core.reshape', 'pandas.core.reshape.api', 'pandas.core.reshape.concat', 'pandas.core.reshape.melt', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.util', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'csv', '_csv', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.date_converters', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._xlrd', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlsxwriter', 'pandas._libs.json', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._libs.testing', 'pandas._version', 'matplotlib', 'matplotlib.cbook', 'matplotlib.cbook.deprecation', 'matplotlib.rcsetup', 'matplotlib.fontconfig_pattern', 'pyparsing', 'matplotlib.colors', 'matplotlib._color_data', 'cycler', 'matplotlib._version', 'matplotlib.ft2font', 'kiwisolver']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-08 21:12:09,463 -276 - wrapper - DEBUG - CACHEDIR=/home/wangyuchen/.cache/matplotlib\n",
      "2020-08-08 21:12:09,467 -1360 - <module> - DEBUG - Using fontManager instance from /home/wangyuchen/.cache/matplotlib/fontlist-v310.json\n",
      "2020-08-08 21:12:09,601 -225 - switch_backend - DEBUG - Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n",
      "2020-08-08 21:12:09,605 -225 - switch_backend - DEBUG - Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n",
      "2020-08-08 21:12:09,607 -225 - switch_backend - DEBUG - Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as utils\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "if not runOnG814:\n",
    "    %matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fromDirGenerateDict(trajectoryDir):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        valueDict: the key is global time, and the value of each key contain SEVERAL LIST of properties, \n",
    "                   each list consist of all property of a single vehicle at one time.\n",
    "    \"\"\"\n",
    "    trajectoryDataFile=open(trajectoryDir)\n",
    "    count=0\n",
    "    allLineList=[]\n",
    "    count=0\n",
    "    for count,line in enumerate(trajectoryDataFile):\n",
    "        #read a single line, remove space and enter\n",
    "        lineList=line.split(' ')\n",
    "        try:\n",
    "            while True:\n",
    "                lineList.remove('')\n",
    "        except:\n",
    "            try:\n",
    "                lineList.remove('\\n')\n",
    "            except:\n",
    "                pass\n",
    "            pass\n",
    "        for i in range(0,lineList.__len__()):\n",
    "            # convert string to float\n",
    "            lineList[i]=float(lineList[i])\n",
    "        allLineList.append(lineList)\n",
    "    valueDict=rearrangeDataByGlobalTime(allLineList)\n",
    "    return valueDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxAndMinValueFromValueDict(valueDict,lableList):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        valueDict: each key in dict is global time, the value of each key is a list of all value at one time\n",
    "        lableList: lables from which you want to get the max and min value. the type of each value in the list \n",
    "                    is str.\n",
    "    Returns:\n",
    "        a dict, which has keys keys from the input lable list and the value of each key is a dict which formed\n",
    "        as 'max':value, 'min':value\n",
    "    \"\"\"\n",
    "    maxAndMinDict={}\n",
    "    keys=list(valueDict.keys())\n",
    "    for lable in lableList:\n",
    "        max=0\n",
    "        min=0 #speed,  positon are all from 0 to max, accelerate from - to +\n",
    "        for eachKey in keys:\n",
    "            valueLists=valueDict[eachKey]\n",
    "            for valueList in valueLists:\n",
    "                value=getValueByLable([lable],valueList)[lable]\n",
    "                if value>max:\n",
    "                    max=value\n",
    "                if value<min:\n",
    "                    min=value\n",
    "        maxAndMinDict[lable]={'max':max,'min':min}\n",
    "    return maxAndMinDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test function of finding the max and min value: block 1, get valueDict for saving time from file reaidng\n",
    "# valueDict=fromDirGenerateDict(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function of finding the max and min value: block 1, get valueDict for saving time from file reaidng\n",
    "# getMaxAndMinValueFromValueDict(valueDict,['Local_X','Local_Y','v_Acc','v_Vel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valueDict=fromDirGenerateDict(1)\n",
    "# theKey=list(valueDict.keys())[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeTensorData(xTensor,yTensor, maxLength=2500,maxWidth=100,blocksize=10,normalizationDict=False):\n",
    "    \"\"\"\n",
    "    visualize a frame on an white image\n",
    "    Args:\n",
    "        valueVisualize: a list of values, each item in the list can be obtained by function \n",
    "        getValueByLable\n",
    "    Returns:\n",
    "        the image of the input frame\n",
    "    \"\"\"\n",
    "    image=np.ones((maxLength,maxWidth,3),dtype=np.int8)\n",
    "    image=image*255\n",
    "#     figure=plt.figure(figsize=(10,50))\n",
    "#     axe=figure.add_subplot(1,1,1)\n",
    "    xLength=xTensor.shape[0] #the length of y is equivalent to x's\n",
    "#     print('length:',xLength)\n",
    "#     print('xTensor.shape',xTensor.shape)\n",
    "    if doNormalization&(normalizationDict is not False):\n",
    "        originalXTensor=torch.zeros(xLength)\n",
    "        originalYTensor=torch.zeros(xLength) #originalX and Y tensor share the same length\n",
    "        originalXTensor=torch.add(\\\n",
    "                                  torch.mul(xTensor,normalizationDict['positionXMax']-normalizationDict['positionXMin']),\\\n",
    "                                  torch.add(originalXTensor,normalizationDict['positionXMin'])\n",
    "                                 )\n",
    "        originalYTensor=torch.add(\\\n",
    "                                  torch.mul(yTensor,normalizationDict['positionYMax']-normalizationDict['positionYMin']),\\\n",
    "                                  torch.add(originalYTensor,normalizationDict['positionYMin'])\n",
    "                                 )\n",
    "        for i in range(xLength):\n",
    "            x=int(originalXTensor[i])\n",
    "            y=int(originalYTensor[i])\n",
    "            colorR=int((i*17+29)%255)\n",
    "            colorG=int((i*9++93)%255)\n",
    "            colorB=int((i*13+111)%255)\n",
    "            cv2.circle(image,(x,y),int(blocksize/2),(colorB,colorG,colorR),-1) #\n",
    "    #     axe.imshow(image)\n",
    "        return image\n",
    "        \n",
    "    \n",
    "    \n",
    "    for i in range(xLength):\n",
    "        x=int(xTensor[i])\n",
    "        y=int(yTensor[i])\n",
    "        colorR=int((i*17+29)%255)\n",
    "        colorG=int((i*9++93)%255)\n",
    "        colorB=int((i*13+111)%255)\n",
    "        cv2.circle(image,(x,y),int(blocksize/2),(colorB,colorG,colorR),-1) #\n",
    "#     axe.imshow(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-08 21:12:09,863 -225 - switch_backend - DEBUG - Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "if not runOnG814:\n",
    "    %matplotlib inline\n",
    "from IPython import display\n",
    "def visualizeData(valueVisualize, maxLength=1000,maxWidth=100,blocksize=10):\n",
    "    \"\"\"\n",
    "    visualize a frame on an white image\n",
    "    Args:\n",
    "        valueVisualize: a list of values, each item in the list can be obtained by function \n",
    "        getValueByLable\n",
    "    Returns:\n",
    "        the image of the input frame\n",
    "    \"\"\"\n",
    "    image=np.ones((maxLength,maxWidth,3),dtype=np.int8)\n",
    "    image=image*255\n",
    "#     figure=plt.figure(figsize=(10,50))\n",
    "#     axe=figure.add_subplot(1,1,1)\n",
    "    \n",
    "    for item in valueVisualize:\n",
    "        infoList=getValueByLable(['Vehicle_ID','Local_X','Local_Y'],item)\n",
    "        vehicleID=infoList['Vehicle_ID']\n",
    "        x=int(infoList['Local_X'])\n",
    "        y=int(infoList['Local_Y'])\n",
    "        colorR=int((vehicleID+100)%255)\n",
    "        colorG=int((vehicleID+150)%255)\n",
    "        colorB=int((vehicleID+200)%255)\n",
    "        cv2.circle(image,(x,y),int(blocksize/2),(colorB,colorG,colorR),-1) #\n",
    "#     axe.imshow(image)\n",
    "    return image\n",
    "# visualizeData(valueDict[theKey])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discountParameterByExponentialWithDistance(relationTensors, xfactor=1, yfactor=1, w1=1,w2=2,w3=1):\n",
    "    \"\"\"\n",
    "    to calculate a discount parameter matrix from the relations matrix of several vehicl pairs.\n",
    "    Args:\n",
    "        relationTensors: a vehicle pair is a \"relation\" in which two vehilce properties are of the same kind and order,\n",
    "        the relationTensors consists of many vehicle pairs. An extra dimension should be added to the a single vehicle pair\n",
    "        tensor if this function only take as a single vehicle pair. Generally, the relationTensors has to dimension:\n",
    "        the dimension of pairs, the properties of each pair.\n",
    "        xfactor,yfactor:  the weight of x part and y part\n",
    "        w1, w2,w3: facor in exponential operation, w1 and w2 relate to x and w3 relate to y\n",
    "    \"\"\"\n",
    "    vehiclePairDimension=relationTensors.shape[1] #the second dimension of relationTensors is the properties of each vehicle pair\n",
    "    relationsDimension=relationTensors.shape[0]\n",
    "    computationTensor=torch.zeros((relationsDimension,5)) #save the xDifference and yDifference for further computation\n",
    "    secondVehiclePropertyStartIndex=int((vehiclePairDimension)/2 )\n",
    "    logging.debug('secondVehiclePropertyStartIndex'+str(secondVehiclePropertyStartIndex))\n",
    "    \n",
    "    discountTensor=torch.zeros(relationsDimension)\n",
    "    for i in range(relationsDimension):\n",
    "        x1,y1,x2,y2=relationTensors[i][0],relationTensors[i][1],\\\n",
    "                    relationTensors[i][secondVehiclePropertyStartIndex],relationTensors[i][secondVehiclePropertyStartIndex+1]\n",
    "        if y2>=y1: #the second vehilce is in front of the first vehicle\n",
    "            yDifference=y2-y1\n",
    "            wy=w1\n",
    "        else: #the second vehicle is after the fist vehicle\n",
    "            yDifference=y1-y2\n",
    "            wy=w2\n",
    "        xDifference=abs(x1-x2)\n",
    "        wx=w3\n",
    "        computationTensor[i][0]=xDifference\n",
    "        computationTensor[i][1]=yDifference\n",
    "        computationTensor[i][2]=wx\n",
    "        computationTensor[i][3]=wy\n",
    "        if (x1==0 and y1==0)or(x2==0 and y2==0):\n",
    "            computationTensor[i][4]=0\n",
    "        else:\n",
    "            computationTensor[i][4]=1\n",
    "#         discountTensor[i]=(xfactor/math.exp(wx*(xDifference)))*(yfactor/math.exp(wx*(yDifference)))\n",
    "    logging.debug(fromAllToStr('computationTensor:\\n',computationTensor))\n",
    "    discountTensor=torch.mul(torch.mul((xfactor/torch.exp(torch.mul(computationTensor[:,0],computationTensor[:,2]))),\\\n",
    "                             (yfactor/torch.exp(torch.mul(computationTensor[:,1],computationTensor[:,3])))),\n",
    "                             computationTensor[:,4])\n",
    "    return discountTensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: property tensors, target vehicle ID\n",
    "#output: relations, distances between target vehicle and other vehicles which inside the range\n",
    "def relationCalculateWithRange(propertyTensors, distanceRange, targetVehicleId, maxRelationsNumber=maxRelationsNumberGlobal):\n",
    "    \"\"\"\n",
    "    NOTICE:THE PROPERTIES AND DISTANCE RANGE SHOULD BOTH BE NORMALIZED OR UNNORMALIZED!!!\n",
    "    Args:\n",
    "        propertyTensors:property tensors of all vehicles, at position 0 and 1 are the x and y positon of the \n",
    "        corresponding vehicle\n",
    "        distanceRange: the distance on which we decide to take other vehicles into account\n",
    "        targetVehicleId: the center vehicle which we are going to calculate\n",
    "    \"\"\"\n",
    "    propertyTensorsCopy=copy.deepcopy(propertyTensors)\n",
    "    propertiesDimension=propertyTensorsCopy.shape[0]\n",
    "    reservedIndexes=[]\n",
    "    reservedIndexDistanceDict={}\n",
    "    for i in range(maxMatrixIndex):\n",
    "        reservedIndexes.append(i)\n",
    "    #remove vehicles which position are out-of-range\n",
    "    for i in range(propertiesDimension):\n",
    "        #simply remove the out-of-ranged vehicles by comparing y-axis before computing the distance.\n",
    "        #since most vehicles are out of the given range, this would reduce time cost\n",
    "        if abs(propertyTensorsCopy[i][1]-propertyTensors[targetVehicleId][1])>distanceRange:\n",
    "            reservedIndexes.remove(i)\n",
    "        #to compute if vehicle in the range\n",
    "        else:\n",
    "            distance=((propertyTensorsCopy[i][0]-propertyTensors[targetVehicleId][0])**2+\\\n",
    "                (propertyTensorsCopy[i][1]-propertyTensors[targetVehicleId][1])**2)**0.5\n",
    "            if distance>distanceRange:\n",
    "                reservedIndexes.remove(i)\n",
    "            else:\n",
    "                reservedIndexDistanceDict[i]=distance\n",
    "    #sort dict by value, not by key\n",
    "    sortedReservedIndexDistanceDict=sorted(reservedIndexDistanceDict.items(),key=lambda item:(item[1],item[0]))\n",
    "    #keep the top 'maxRelationsNumber' nearest vehicles in the generated relations\n",
    "    if(sortedReservedIndexDistanceDict.__len__()>maxRelationsNumber):\n",
    "        for i in range(maxRelationsNumber,sortedReservedIndexDistanceDict.__len__()):\n",
    "            reservedIndexes.remove(sortedReservedIndexDistanceDict[i][0])\n",
    "    #the final properties tensor is:\n",
    "    finalPropertiesTensor=propertyTensorsCopy[reservedIndexes]\n",
    "    if(sortedReservedIndexDistanceDict.__len__()<maxRelationsNumber):\n",
    "        #make sure the length of all relation are equanl to the value of maxRelationNumber\n",
    "        finalPropertiesTensor=torch.cat((finalPropertiesTensor,\\\n",
    "                                         torch.zeros((maxRelationsNumber-finalPropertiesTensor.shape[0],finalPropertiesTensor.shape[1]))))\n",
    "    \n",
    "#     logging.debug('targetVehicleId'+str(targetVehicleId))\n",
    "#     logging.debug('reservedIndexes.__len__()'+str(reservedIndexes.__len__()))\n",
    "#     logging.debug('propertyTensors[targetVehicleId].shape[0]'+str(propertyTensors[targetVehicleId].shape[0]))\n",
    "    expandedTargetVehicleTensor=propertyTensors[targetVehicleId].expand(maxRelationsNumber,propertyTensors[targetVehicleId].shape[0])\n",
    "    relationTensor=torch.cat((expandedTargetVehicleTensor,finalPropertiesTensor),1)\n",
    "#     logging.debug('expandedTargetVehicleTensor:'+str(expandedTargetVehicleTensor))\n",
    "#     logging.debug('relationTensor:'+str(relationTensor))\n",
    "    return relationTensor\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeRelationAndAllTheOtherTensorsWithDistance(inputFrameTensor,theGivenRange,maxRelationsNumber=20):\n",
    "    '''\n",
    "        to generate relation tensors, discount parameter tensor with relations and the relation quantity tensor\n",
    "    of each vehicle\n",
    "    Args:\n",
    "        inputFrameTensor: vehicle properties graph, which dimension are (timestep, property, vehicle).\n",
    "        To illustrate the meaning of dimensions, supposing we have a inputFrameTensor which \n",
    "        timestep is 10, all vehicle have 6 properties and there are 250 vehicles, then the dimension of the \n",
    "        input tensor are(10, 6, 250)\n",
    "        theGivenRange: only take vehicle pairs which distance are inside the given range into account.\n",
    "    Returns:\n",
    "        relationTensor: the relation tensors of each vehicle pairs in the given range\n",
    "        discountParameterTensor: the discount tensor of each relation, computed by the distance between vehicle pairs\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    #circulation for batch list\n",
    "    logging.debug(fromAllToStr('inputFrameTensor.shape:',inputFrameTensor.shape))\n",
    "    timeStepSize=inputFrameTensor.shape[0]\n",
    "    for timeStepCount in range(0,timeStepSize):\n",
    "        for vehicleId in range(0, inputFrameTensor.shape[2]):\n",
    "            relationTensor=relationCalculateWithRange(inputFrameTensor[timeStepCount].permute(1,0),\n",
    "                                                      theGivenRange,vehicleId,maxRelationsNumber=maxRelationsNumber)\n",
    "            if vehicleId==0:\n",
    "                relationTensorInOneTimeStep=relationTensor\n",
    "            elif vehicleId>0:\n",
    "                relationTensorInOneTimeStep=torch.cat((relationTensorInOneTimeStep,relationTensor),dim=0)\n",
    "        logging.debug(fromAllToStr('relationTensorInOneTimeStep.shape:\\n',relationTensorInOneTimeStep.shape))\n",
    "        discountParameterTensorInOneTimeStep=discountParameterByExponentialWithDistance(relationTensorInOneTimeStep)\n",
    "        if timeStepCount==0:\n",
    "            relationTensorOfAllTimeSteps=relationTensorInOneTimeStep.unsqueeze(0)\n",
    "            discountParameterTensorofAllTimeSteps=discountParameterTensorInOneTimeStep.unsqueeze(0)\n",
    "        else:\n",
    "            relationTensorOfAllTimeSteps=\\\n",
    "            torch.cat((relationTensorOfAllTimeSteps,relationTensorInOneTimeStep.unsqueeze(0)),dim=0)\n",
    "            discountParameterTensorofAllTimeSteps=\\\n",
    "            torch.cat((discountParameterTensorofAllTimeSteps,discountParameterTensorInOneTimeStep.unsqueeze(0)),dim=0)\n",
    "    return relationTensorOfAllTimeSteps,discountParameterTensorofAllTimeSteps\n",
    "    \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-08 21:12:09,907 -5 - <module> - DEBUG - tensor([0.5242, 0.8530, 0.8448, 0.3007, 0.1308, 0.0852])\n",
      "2020-08-08 21:12:09,961 -6 - <module> - DEBUG - tensor([0.9385, 0.6862, 0.6083, 0.3907, 0.7000, 0.7634])\n",
      "2020-08-08 21:12:09,965 -7 - <module> - DEBUG - tensor([0.6290, 0.4422, 0.4306, 0.5817, 0.0257, 0.3017])\n",
      "2020-08-08 21:12:09,970 -8 - <module> - DEBUG - tensor([[0.5242, 0.8530, 0.8448, 0.3007, 0.1308, 0.0852],\n",
      "        [0.9385, 0.6862, 0.6083, 0.3907, 0.7000, 0.7634],\n",
      "        [0.6290, 0.4422, 0.4306, 0.5817, 0.0257, 0.3017]])\n",
      "2020-08-08 21:12:09,976 -10 - <module> - DEBUG - tensor([[0.5242, 0.8530, 0.8448, 0.3007, 0.1308, 0.0852],\n",
      "        [0.5242, 0.8530, 0.8448, 0.3007, 0.1308, 0.0852],\n",
      "        [0.9385, 0.6862, 0.6083, 0.3907, 0.7000, 0.7634],\n",
      "        [0.6290, 0.4422, 0.4306, 0.5817, 0.0257, 0.3017]])\n"
     ]
    }
   ],
   "source": [
    "tensor1=torch.rand((6))\n",
    "tensor2=torch.rand((6))\n",
    "tensor3=torch.rand((6))\n",
    "tensor4=torch.stack((tensor1,tensor2,tensor3),dim=0)\n",
    "logging.debug(tensor1)\n",
    "logging.debug(tensor2)\n",
    "logging.debug(tensor3)\n",
    "logging.debug(tensor4)\n",
    "tensor5=torch.cat((tensor1.unsqueeze(0),tensor4),dim=0)\n",
    "logging.debug(tensor5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differenceBetweenTwoFrame(frameSeries):\n",
    "    \"\"\"\n",
    "    Given a series of frame, return the difference series of those frame. Since this function \n",
    "    compute diffrences by the gap between two adjacent frames, the quantity of frame in difference \n",
    "    series is one less than the input frame series\n",
    "    Args:\n",
    "        frameSeries: input frames, which dimension is (vehicleQuantity, vehicleProperties)\n",
    "    Returns:\n",
    "        the difference series, which first dimension (quantity dimension) is one less than input frame series.\n",
    "    \"\"\"\n",
    "    frameSeriesWithoutTheFirstFrame=frameSeries[1:]\n",
    "    frameSeriesWithoutTheLastFrame=frameSeries[0:-1]\n",
    "    logging.debug(str(frameSeriesWithoutTheFirstFrame))\n",
    "    logging.debug(str(frameSeriesWithoutTheLastFrame))\n",
    "    logging.debug(str(frameSeries))\n",
    "    differenceSeries=frameSeriesWithoutTheFirstFrame-frameSeriesWithoutTheLastFrame\n",
    "    return differenceSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differenceBetweenTwoFrameForTimeSteps(frameSeries):\n",
    "    \"\"\"\n",
    "    Given several time stpes of series of frame, return the difference series of all those frames. Since this function \n",
    "    compute diffrences by the gap between two adjacent frames, the quantity of frame in difference \n",
    "    series is one less than the input frame series\n",
    "    Args:\n",
    "        frameSeries: input frames, which dimension is (timeSteps,vehicleQuantity, vehicleProperties)\n",
    "    Returns:\n",
    "        differenceSeries:the difference series, which second dimension (quantity dimension) is one less than input frame series,\n",
    "        and the dimension of differenceSeries is (timeSteps, vehicleQuantity, vehiclePropertiesDifference)\n",
    "    \"\"\"\n",
    "    \n",
    "    frameSeriesWithoutTheFirstFrame=frameSeries[:,1:]\n",
    "    frameSeriesWithoutTheLastFrame=frameSeries[:,0:-1]\n",
    "    logging.debug(str(frameSeriesWithoutTheFirstFrame))\n",
    "    logging.debug(str(frameSeriesWithoutTheLastFrame))\n",
    "    logging.debug(str(frameSeries))\n",
    "    differenceSeries=frameSeriesWithoutTheFirstFrame-frameSeriesWithoutTheLastFrame\n",
    "    return differenceSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-08 21:12:10,007 -2 - <module> - DEBUG - tensor([[0.6525, 0.0573, 0.4167, 0.7232, 0.1323],\n",
      "        [0.9757, 0.0650, 0.9461, 0.9835, 0.9291],\n",
      "        [0.2860, 0.3710, 0.2702, 0.8673, 0.0772],\n",
      "        [0.9388, 0.0849, 0.2236, 0.0183, 0.5077],\n",
      "        [0.9769, 0.6753, 0.8066, 0.0987, 0.2957]])\n",
      "2020-08-08 21:12:10,011 -13 - differenceBetweenTwoFrame - DEBUG - tensor([[0.9757, 0.0650, 0.9461, 0.9835, 0.9291],\n",
      "        [0.2860, 0.3710, 0.2702, 0.8673, 0.0772],\n",
      "        [0.9388, 0.0849, 0.2236, 0.0183, 0.5077],\n",
      "        [0.9769, 0.6753, 0.8066, 0.0987, 0.2957]])\n",
      "2020-08-08 21:12:10,012 -14 - differenceBetweenTwoFrame - DEBUG - tensor([[0.6525, 0.0573, 0.4167, 0.7232, 0.1323],\n",
      "        [0.9757, 0.0650, 0.9461, 0.9835, 0.9291],\n",
      "        [0.2860, 0.3710, 0.2702, 0.8673, 0.0772],\n",
      "        [0.9388, 0.0849, 0.2236, 0.0183, 0.5077]])\n",
      "2020-08-08 21:12:10,013 -15 - differenceBetweenTwoFrame - DEBUG - tensor([[0.6525, 0.0573, 0.4167, 0.7232, 0.1323],\n",
      "        [0.9757, 0.0650, 0.9461, 0.9835, 0.9291],\n",
      "        [0.2860, 0.3710, 0.2702, 0.8673, 0.0772],\n",
      "        [0.9388, 0.0849, 0.2236, 0.0183, 0.5077],\n",
      "        [0.9769, 0.6753, 0.8066, 0.0987, 0.2957]])\n",
      "2020-08-08 21:12:10,014 -4 - <module> - DEBUG - shapesize2\n"
     ]
    }
   ],
   "source": [
    "inputTensor=torch.rand((5,5))\n",
    "logging.debug(inputTensor)\n",
    "differenceBetweenTwoFrame(inputTensor)\n",
    "logging.debug(fromAllToStr('shapesize',inputTensor.shape.__len__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testExpand=torch.tensor(((1,2,3),(3,4,5))).expand(2,6)\n",
    "# print(testExpand)\n",
    "# theList=[1,2,3,5,7]\n",
    "# theList.remove(7)\n",
    "# d = {'lilee':25, 'wangyan':21, 'liqun':32, 'age':19}\n",
    "# print(d)\n",
    "# d=sorted(d.items(), key=lambda item:item[1])\n",
    "# print(d.__len__())\n",
    "# print(theList)\n",
    "# testTensor=torch.rand(10,10)\n",
    "# print(testTensor)\n",
    "# print(testTensor[[1,4,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save visulized images\n",
    "# for key in list(valueDict.keys())[1:10000]:\n",
    "#     image=visualizeData(valueDict[key])\n",
    "#     cv2.imwrite('visualizeFolder/image'+str(key)+'.png',image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tensorsDataset(Dataset):\n",
    "    def __init__(self, trajectoryFileList, numberOfTensorsEachBatch=100,lableTensorEachBatch=2):\n",
    "        if(numberOfTensorsEachBatch<5):\n",
    "            raise Exception(\"THE NUMBER OF TENSORS IN EACH BATCH IS TOO SMALL\")\n",
    "        self.valueDictList=[]\n",
    "        self.sizeList=[]\n",
    "        self.numberOfTensorsEachBatch=numberOfTensorsEachBatch\n",
    "        self.lableTensorEachBatch=lableTensorEachBatch\n",
    "        self.allTensorsEachBatch=numberOfTensorsEachBatch+lableTensorEachBatch\n",
    "        self.keysList=[]\n",
    "        for eachFile in trajectoryFileList:\n",
    "            valueDict=fromDirGenerateDict(eachFile)\n",
    "            self.valueDictList.append(copy.deepcopy(valueDict))\n",
    "            self.sizeList.append(valueDict.keys().__len__()-self.allTensorsEachBatch)\n",
    "            sortedKeys=list(valueDict.keys())\n",
    "            sortedKeys.sort()\n",
    "            self.keysList.append(copy.deepcopy(sortedKeys))\n",
    "\n",
    "    def __len__(self):\n",
    "        allLen=0\n",
    "        for length in self.sizeList:\n",
    "            allLen=allLen+length\n",
    "        return allLen\n",
    "    \n",
    "    def fromIdxMapToList(self,idx):\n",
    "        \"\"\"\n",
    "        since there are several lists,we have to know which list shoud we use and the ture index in the list\n",
    "        Return:\n",
    "            the trueIndex, listIndex\n",
    "        \"\"\"\n",
    "        countSection=0\n",
    "        for i in range(0,self.sizeList.__len__()):\n",
    "            countSection+=self.sizeList[i]\n",
    "            if(idx<countSection):\n",
    "                return idx-countSection+self.sizeList[i],i\n",
    "            \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        #initialize trueIndex, listIndex\n",
    "        #\n",
    "        #this dict record the relation between matrix index and vehicle ID in the last frame\n",
    "        matrixIndexAndVehicleIDRecordDict={}\n",
    "        #initialize dict above\n",
    "        for i in range(0,maxMatrixIndex):\n",
    "            matrixIndexAndVehicleIDRecordDict[i]={'Vehicle_ID':-1,'refresh':-1}\n",
    "        matrixIndexAndVehicleIDRecordDict['time']=-1\n",
    "        trueIndex,listIndex=self.fromIdxMapToList(idx)\n",
    "        itemDict={'positionTensorList':[],'speedTensorList':[],'accTensorList':[],'angleTensorList':[],'time':[]}\n",
    "        valueDict=self.valueDictList[listIndex] #valueDict is the Dict of many frames\n",
    "        dictKeys=self.keysList[listIndex]\n",
    "        #generate tensors of first frame\n",
    "        positionTensor,speedTensor,accTensor,angleTensor,newVehicleList\\\n",
    "        =readFirstFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[trueIndex]])\n",
    "        angleSinTensor=torch.sin(angleTensor)\n",
    "        angleCosTensor=torch.cos(angleTensor)\n",
    "        combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                 speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                 accTensor.mul(angleCosTensor)),0)\n",
    "        allCombineTensorTrain=combinedTensor.unsqueeze(0)\n",
    "        allCombineTensorValid=0\n",
    "#         itemDict['positionTensorList'].append(positionTensor)\n",
    "#         itemDict['speedTensorList'].append(speedTensor)\n",
    "#         itemDict['accTensorList'].append(accTensor)\n",
    "#         itemDict['angleTensorList'].append(angleTensor)\n",
    "#         time=getValueByLable(['Global_Time'],valueDict[dictKeys[trueIndex]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]][0]\n",
    "#         itemDict['time'].append(time)\n",
    "        \n",
    "        for i in range(trueIndex+1,trueIndex+self.allTensorsEachBatch):\n",
    "            #generate tensor from general frame\n",
    "            positionTensor,speedTensor,accTensor,angleTensor,newVehicleList,vanishedVehicleList\\\n",
    "            =readGeneralFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[i]],positionTensor)\n",
    "            angleSinTensor=torch.sin(angleTensor)\n",
    "            angleCosTensor=torch.cos(angleTensor)\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "            if i<self.numberOfTensorsEachBatch+trueIndex:\n",
    "                allCombineTensorTrain=torch.cat((allCombineTensorTrain,combinedTensor.unsqueeze(0)),0)\n",
    "            elif i==self.numberOfTensorsEachBatch+trueIndex:\n",
    "                allCombineTensorValid=combinedTensor.unsqueeze(0)\n",
    "            else:\n",
    "                allCombineTensorValid=torch.cat((allCombineTensorValid,combinedTensor.unsqueeze(0)),0)\n",
    "#             itemDict['positionTensorList'].append(positionTensor)\n",
    "#             itemDict['speedTensorList'].append(speedTensor)\n",
    "#             itemDict['accTensorList'].append(accTensor)\n",
    "#             itemDict['angleTensorList'].append(angleTensor)\n",
    "#             time=getValueByLable(['Global_Time'],valueDict[dictKeys[i]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]]\n",
    "#             itemDict['time'].append(time)\n",
    "        return allCombineTensorTrain,allCombineTensorValid\n",
    "# trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0805am-0820am/trajectories-0805am-0820am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0820am-0835am/trajectories-0820am-0835am.txt']\n",
    "trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class tensorsDatasetV2(Dataset):\n",
    "    \"\"\"\n",
    "    dataset for relation model\n",
    "    \"\"\"\n",
    "    def __init__(self, trajectoryFileList, numberOfTensorsEachBatch=1,lableTensorEachBatch=1):\n",
    "        if(numberOfTensorsEachBatch!=1 or lableTensorEachBatch!=1):\n",
    "            raise Exception(\"BOTH TRAIN AND VALID TENSOR NUMBERS SHOULD BE ONE!\")\n",
    "        self.valueDictList=[]\n",
    "        self.sizeList=[]\n",
    "        self.numberOfTensorsEachBatch=numberOfTensorsEachBatch\n",
    "        self.lableTensorEachBatch=lableTensorEachBatch\n",
    "        self.allTensorsEachBatch=numberOfTensorsEachBatch+lableTensorEachBatch\n",
    "        self.keysList=[]\n",
    "        if doNormalization:\n",
    "            self.positionXMax=0\n",
    "            self.positionXMin=999999\n",
    "            self.positionYMax=0\n",
    "            self.positionYMin=99999\n",
    "            self.speedMax=-100\n",
    "            self.speedMin=999999\n",
    "            self.accMax=-100\n",
    "            self.accMin=9999\n",
    "        for eachFile in trajectoryFileList:\n",
    "            valueDict=fromDirGenerateDict(eachFile)\n",
    "            if doNormalization:\n",
    "                #get the max and min value for normalization\n",
    "                maxAndMinDict=getMaxAndMinValueFromValueDict(valueDict,['Local_X','Local_Y','v_Vel','v_Acc'])\n",
    "                #position X\n",
    "                if self.positionXMax<maxAndMinDict['Local_X']['max']:\n",
    "                    self.positionXMax=maxAndMinDict['Local_X']['max']\n",
    "                if self.positionXMin>maxAndMinDict['Local_X']['min']:\n",
    "                    self.positionXMin=maxAndMinDict['Local_X']['min']\n",
    "                #position Y\n",
    "                if self.positionYMax<maxAndMinDict['Local_Y']['max']:\n",
    "                    self.positionYMax=maxAndMinDict['Local_Y']['max']\n",
    "                if self.positionYMin>maxAndMinDict['Local_Y']['min']:\n",
    "                    self.positionYMin=maxAndMinDict['Local_Y']['min']\n",
    "                #speed\n",
    "                if self.speedMax<maxAndMinDict['v_Vel']['max']:\n",
    "                    self.speedMax=maxAndMinDict['v_Vel']['max']\n",
    "                if self.speedMin>maxAndMinDict['v_Vel']['min']:\n",
    "                    self.speedMin=maxAndMinDict['v_Vel']['min']\n",
    "                #acc\n",
    "                if self.accMax<maxAndMinDict['v_Acc']['max']:\n",
    "                    self.accMax=maxAndMinDict['v_Acc']['max']\n",
    "                if self.accMin>maxAndMinDict['v_Acc']['min']:\n",
    "                    self.accMin=maxAndMinDict['v_Acc']['min']\n",
    "            self.valueDictList.append(copy.deepcopy(valueDict))\n",
    "            self.sizeList.append(valueDict.keys().__len__()-self.allTensorsEachBatch)\n",
    "            sortedKeys=list(valueDict.keys())\n",
    "            sortedKeys.sort()\n",
    "            self.keysList.append(copy.deepcopy(sortedKeys))\n",
    "\n",
    "    def getNormalizationDict(self):\n",
    "        '''\n",
    "        Returns:\n",
    "            a dict:{'positionXMax':self.positionXMax,'positonYMax':self.self.positionYMax,\\\n",
    "               'positionXMin':self.positionXMin,'positionYMin':self.positionYMin,\\\n",
    "               'speedMax':self.speedMax,'speedMin':speedMin,\\\n",
    "               'accMax':self.accMax,'accMax':self.accMin}\n",
    "        '''\n",
    "        if not doNormalization:\n",
    "            raise Exception('NORMALIZATION IS NOT APPLIED')\n",
    "        return {'positionXMax':self.positionXMax,'positionYMax':self.positionYMax,\\\n",
    "               'positionXMin':self.positionXMin,'positionYMin':self.positionYMin,\\\n",
    "               'speedMax':self.speedMax,'speedMin':self.speedMin,\\\n",
    "               'accMax':self.accMax,'accMin':self.accMin}\n",
    "    \n",
    "    def __len__(self):\n",
    "        allLen=0\n",
    "        for length in self.sizeList:\n",
    "            allLen=allLen+length\n",
    "        return allLen\n",
    "    \n",
    "    def fromIdxMapToList(self,idx):\n",
    "        \"\"\"\n",
    "        since there are several lists,we have to know which list shoud we use and the ture index in the list\n",
    "        Return:\n",
    "            the trueIndex, listIndex\n",
    "        \"\"\"\n",
    "        countSection=0\n",
    "        for i in range(0,self.sizeList.__len__()):\n",
    "            countSection+=self.sizeList[i]\n",
    "            if(idx<countSection):\n",
    "                return idx-countSection+self.sizeList[i],i\n",
    "            \n",
    "    \n",
    "            \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        #initialize trueIndex, listIndex\n",
    "        #\n",
    "        #this dict record the relation between matrix index and vehicle ID in the last frame\n",
    "        matrixIndexAndVehicleIDRecordDict={}\n",
    "        #initialize dict above\n",
    "        for i in range(0,maxMatrixIndex):\n",
    "            matrixIndexAndVehicleIDRecordDict[i]={'Vehicle_ID':-1,'refresh':-1}\n",
    "        matrixIndexAndVehicleIDRecordDict['time']=-1\n",
    "        trueIndex,listIndex=self.fromIdxMapToList(idx)\n",
    "        itemDict={'positionTensorList':[],'speedTensorList':[],'accTensorList':[],'angleTensorList':[],'time':[]}\n",
    "        valueDict=self.valueDictList[listIndex] #valueDict is the Dict of many frames\n",
    "        dictKeys=self.keysList[listIndex]\n",
    "        #generate tensors of first frame\n",
    "        positionTensor,speedTensor,accTensor,angleTensor,newVehicleList\\\n",
    "        =readFirstFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[trueIndex]])\n",
    "        angleSinTensor=torch.sin(angleTensor)\n",
    "        angleCosTensor=torch.cos(angleTensor)\n",
    "        #first frame normalization\n",
    "        if doNormalization:\n",
    "#             print('before nomalization')\n",
    "#             print(positionTensor.shape,speedTensor.shape,accTensor.shape)\n",
    "            positionTensor=torch.cat((torch.div(torch.sub(positionTensor[0,:],self.positionXMin),self.positionXMax-self.positionXMin).unsqueeze(0),\\\n",
    "                                     torch.div(torch.sub(positionTensor[1,:],self.positionYMin,),self.positionYMax-self.positionYMin).unsqueeze(0)),0)\n",
    "            speedTensor=torch.div(torch.sub(speedTensor,self.speedMin),self.speedMax-self.speedMin)\n",
    "            accTensor=torch.div(torch.sub(accTensor,self.accMin),self.accMax-self.accMin)\n",
    "#             print('after normalization')\n",
    "#             print(positionTensor.shape,speedTensor.shape,accTensor.shape)\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "        else:\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "        #generate relation tensor for all vehicle pairs\n",
    "        print('in getitem, combinedTensor shape: ',combinedTensor.shape)\n",
    "        relationTensorLeft=combinedTensor[:,0].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])\n",
    "        relationTensorRight=torch.transpose(torch.cat((combinedTensor[:,:0],combinedTensor[:,1:]),1),0,1)\n",
    "        print('in getitem, relation tensorleft shape:',relationTensorLeft.shape)\n",
    "        print('in getitem, relationtensorright shape',relationTensorRight.shape)\n",
    "#         print(relationTensorRight.shape,relationTensorRight.shape)\n",
    "        for i in range(1,combinedTensor.shape[1]):\n",
    "            relationTensorLeft=torch.cat((relationTensorLeft,\\\n",
    "                                          combinedTensor[:,i].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])),0)\n",
    "            relationTensorRight=torch.cat((relationTensorRight,\\\n",
    "                                           torch.transpose(torch.cat((combinedTensor[:,:i],combinedTensor[:,i+1:]),1),0,1)),0)\n",
    "#         print(relationTensorLeft.shape,relationTensorRight.shape)\n",
    "        combinedRelationTensor=torch.cat((relationTensorLeft,relationTensorRight),1)  \n",
    "        firstCombinedRelationTensor=combinedRelationTensor\n",
    "        \n",
    "        \n",
    "        allCombineTensorTrain=combinedTensor.unsqueeze(0)\n",
    "        allCombineTensorValid=0\n",
    "#         itemDict['positionTensorList'].append(positionTensor)\n",
    "#         itemDict['speedTensorList'].append(speedTensor)\n",
    "#         itemDict['accTensorList'].append(accTensor)\n",
    "#         itemDict['angleTensorList'].append(angleTensor)\n",
    "#         time=getValueByLable(['Global_Time'],valueDict[dictKeys[trueIndex]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]][0]\n",
    "#         itemDict['time'].append(time)\n",
    "        \n",
    "        for i in range(trueIndex+1,trueIndex+self.allTensorsEachBatch):\n",
    "            #generate tensor from general frame\n",
    "            positionTensor,speedTensor,accTensor,angleTensor,newVehicleList,vanishedVehicleList\\\n",
    "            =readGeneralFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[i]],positionTensor)\n",
    "            angleSinTensor=torch.sin(angleTensor)\n",
    "            angleCosTensor=torch.cos(angleTensor)\n",
    "            if doNormalization:\n",
    "                positionTensor=torch.cat((torch.div(torch.sub(positionTensor[0,:],self.positionXMin),self.positionXMax-self.positionXMin).unsqueeze(0),\\\n",
    "                                         torch.div(torch.sub(positionTensor[1,:],self.positionYMin,),self.positionYMax-self.positionYMin).unsqueeze(0)),0)\n",
    "                speedTensor=torch.div(torch.sub(speedTensor,self.speedMin),self.speedMax-self.speedMin)\n",
    "                accTensor=torch.div(torch.sub(accTensor,self.accMin),self.accMax-self.accMin)\n",
    "                combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                         speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                         accTensor.mul(angleCosTensor)),0)\n",
    "            else:\n",
    "                combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                         accTensor.mul(angleCosTensor)),0)\n",
    "            #generate relation tensor for all vehicle pairs\n",
    "            relationTensorLeft=combinedTensor[:,0].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])\n",
    "            relationTensorRight=torch.transpose(torch.cat((combinedTensor[:,:0],combinedTensor[:,1:]),1),0,1)\n",
    "#             print(relationTensorRight.shape,relationTensorRight.shape)\n",
    "            for j in range(1,combinedTensor.shape[1]):\n",
    "                relationTensorLeft=torch.cat((relationTensorLeft,\\\n",
    "                                              combinedTensor[:,j].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])),0)\n",
    "                relationTensorRight=torch.cat((relationTensorRight,\\\n",
    "                                               torch.transpose(torch.cat((combinedTensor[:,:j],combinedTensor[:,j+1:]),1),0,1)),0)\n",
    "#             print(relationTensorLeft.shape,relationTensorRight.shape)\n",
    "            combinedRelationTensor=torch.cat((relationTensorLeft,relationTensorRight),1)  \n",
    "            secondRelationTensor=combinedRelationTensor\n",
    "            #since we only need two tensors, which is input and output tensor respectively, we could return\n",
    "            #the two tensors in the first loop\n",
    "            #(ok I admit that the true reason is that I am lazy)\n",
    "            return firstCombinedRelationTensor,secondRelationTensor\n",
    "#             if i<self.numberOfTensorsEachBatch+trueIndex:\n",
    "#                 allCombineTensorTrain=torch.cat((allCombineTensorTrain,combinedTensor.unsqueeze(0)),0)\n",
    "#             elif i==self.numberOfTensorsEachBatch+trueIndex:\n",
    "#                 allCombineTensorValid=combinedTensor.unsqueeze(0)\n",
    "#             else:\n",
    "#                 allCombineTensorValid=torch.cat((allCombineTensorValid,combinedTensor.unsqueeze(0)),0)\n",
    "#             itemDict['positionTensorList'].append(positionTensor)\n",
    "#             itemDict['speedTensorList'].append(speedTensor)\n",
    "#             itemDict['accTensorList'].append(accTensor)\n",
    "#             itemDict['angleTensorList'].append(angleTensor)\n",
    "#             time=getValueByLable(['Global_Time'],valueDict[dictKeys[i]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]]\n",
    "#             itemDict['time'].append(time)\n",
    "        return allCombineTensorTrain,allCombineTensorValid\n",
    "# trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0805am-0820am/trajectories-0805am-0820am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0820am-0835am/trajectories-0820am-0835am.txt']\n",
    "trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n",
    "#run on 2080 in g814\n",
    "if runOnG814:\n",
    "    trajectoryFileList=['/home/wangyuchen/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fromObjectsToRelationPairsBatchAndTimestepVersion(batchAndTimestepCombinedTensor):\n",
    "    '''\n",
    "    This function based on the other function termed as 'fromObjectsToRelationPairs'. Instead of process a \n",
    "    single frame, this function takes batch and timestep(the other dimension) into consideration.\n",
    "    note: the dimension of combinedTensor is supposed to be (batchs, timesteps, properties, vehicles)\n",
    "    Args:\n",
    "        The input tensor should already be transposed if it is generated from the network's output\n",
    "    Returns:\n",
    "        Relation pairs\n",
    "    '''\n",
    "    #generate relation tensor for all vehicle pairs\n",
    "    batchSize=batchAndTimestepCombinedTensor.shape[0]\n",
    "    timesteps=batchAndTimestepCombinedTensor.shape[1]\n",
    "    for batch in range(batchSize):\n",
    "        for timestep in range(timesteps):\n",
    "            combinedTensor=batchAndTimestepCombinedTensor[batch,timestep,:,:]\n",
    "            relationTensorLeft=combinedTensor[:,0].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])\n",
    "            relationTensorRight=torch.transpose(torch.cat((combinedTensor[:,:0],combinedTensor[:,1:]),1),0,1)\n",
    "        #         print(relationTensorRight.shape,relationTensorRight.shape)\n",
    "            for i in range(1,combinedTensor.shape[1]):\n",
    "                relationTensorLeft=torch.cat((relationTensorLeft,\\\n",
    "                                              combinedTensor[:,i].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])),0)\n",
    "                relationTensorRight=torch.cat((relationTensorRight,\\\n",
    "                                               torch.transpose(torch.cat((combinedTensor[:,:i],combinedTensor[:,i+1:]),1),0,1)),0)\n",
    "        #         print(relationTensorLeft.shape,relationTensorRight.shape)\n",
    "            combinedRelationTensor=torch.cat((relationTensorLeft,relationTensorRight),1) \n",
    "            if timestep==0:\n",
    "                combineRelationTensorsTimeStep=combinedRelationTensor.unsqueeze(0)\n",
    "            else:\n",
    "                combineRelationTensorsTimeStep=torch.cat((combineRelationTensorsTimeStep,\\\n",
    "                                                          combinedRelationTensor.unsqueeze(0)),0)\n",
    "        if batch==0:\n",
    "            combinedRelationTensorsTimeStepAndBatch=combineRelationTensorsTimeStep.unsqueeze(0)\n",
    "        else:\n",
    "            combinedRelationTensorsTimeStepAndBatch=torch.cat((combinedRelationTensorsTimeStepAndBatch,\\\n",
    "                                                              combineRelationTensorsTimeStep.unsqueeze(0)),0)\n",
    "    return combinedRelationTensorsTimeStepAndBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the combined tensor and relation tensor i tensorsDataV2\n",
    "import math\n",
    "class tensorsDatasetV2Test(Dataset):\n",
    "    \"\"\"\n",
    "    dataset for relation model\n",
    "    \"\"\"\n",
    "    def __init__(self, trajectoryFileList, numberOfTensorsEachBatch=1,lableTensorEachBatch=1):\n",
    "        if(numberOfTensorsEachBatch!=1 or lableTensorEachBatch!=1):\n",
    "            raise Exception(\"BOTH TRAIN AND VALID TENSOR NUMBERS SHOULD BE ONE!\")\n",
    "        self.valueDictList=[]\n",
    "        self.sizeList=[]\n",
    "        self.numberOfTensorsEachBatch=numberOfTensorsEachBatch\n",
    "        self.lableTensorEachBatch=lableTensorEachBatch\n",
    "        self.allTensorsEachBatch=numberOfTensorsEachBatch+lableTensorEachBatch\n",
    "        self.keysList=[]\n",
    "        if doNormalization:\n",
    "            self.positionXMax=0\n",
    "            self.positionXMin=999999\n",
    "            self.positionYMax=0\n",
    "            self.positionYMin=99999\n",
    "            self.speedMax=-100\n",
    "            self.speedMin=999999\n",
    "            self.accMax=-100\n",
    "            self.accMin=9999\n",
    "        for eachFile in trajectoryFileList:\n",
    "            valueDict=fromDirGenerateDict(eachFile)\n",
    "            if doNormalization:\n",
    "                #get the max and min value for normalization\n",
    "                maxAndMinDict=getMaxAndMinValueFromValueDict(valueDict,['Local_X','Local_Y','v_Vel','v_Acc'])\n",
    "                #position X\n",
    "                if self.positionXMax<maxAndMinDict['Local_X']['max']:\n",
    "                    self.positionXMax=maxAndMinDict['Local_X']['max']\n",
    "                if self.positionXMin>maxAndMinDict['Local_X']['min']:\n",
    "                    self.positionXMin=maxAndMinDict['Local_X']['min']\n",
    "                #position Y\n",
    "                if self.positionYMax<maxAndMinDict['Local_Y']['max']:\n",
    "                    self.positionYMax=maxAndMinDict['Local_Y']['max']\n",
    "                if self.positionYMin>maxAndMinDict['Local_Y']['min']:\n",
    "                    self.positionYMin=maxAndMinDict['Local_Y']['min']\n",
    "                #speed\n",
    "                if self.speedMax<maxAndMinDict['v_Vel']['max']:\n",
    "                    self.speedMax=maxAndMinDict['v_Vel']['max']\n",
    "                if self.speedMin>maxAndMinDict['v_Vel']['min']:\n",
    "                    self.speedMin=maxAndMinDict['v_Vel']['min']\n",
    "                #acc\n",
    "                if self.accMax<maxAndMinDict['v_Acc']['max']:\n",
    "                    self.accMax=maxAndMinDict['v_Acc']['max']\n",
    "                if self.accMin>maxAndMinDict['v_Acc']['min']:\n",
    "                    self.accMin=maxAndMinDict['v_Acc']['min']\n",
    "            self.valueDictList.append(copy.deepcopy(valueDict))\n",
    "            self.sizeList.append(valueDict.keys().__len__()-self.allTensorsEachBatch)\n",
    "            sortedKeys=list(valueDict.keys())\n",
    "            sortedKeys.sort()\n",
    "            self.keysList.append(copy.deepcopy(sortedKeys))\n",
    "\n",
    "    def getNormalizationDict(self):\n",
    "        '''\n",
    "        Returns:\n",
    "            a dict:{'positionXMax':self.positionXMax,'positonYMax':self.self.positionYMax,\\\n",
    "               'positionXMin':self.positionXMin,'positionYMin':self.positionYMin,\\\n",
    "               'speedMax':self.speedMax,'speedMin':speedMin,\\\n",
    "               'accMax':self.accMax,'accMax':self.accMin}\n",
    "        '''\n",
    "        if not doNormalization:\n",
    "            raise Exception('NORMALIZATION IS NOT APPLIED')\n",
    "        return {'positionXMax':self.positionXMax,'positionYMax':self.positionYMax,\\\n",
    "               'positionXMin':self.positionXMin,'positionYMin':self.positionYMin,\\\n",
    "               'speedMax':self.speedMax,'speedMin':self.speedMin,\\\n",
    "               'accMax':self.accMax,'accMin':self.accMin}\n",
    "    \n",
    "    def __len__(self):\n",
    "        allLen=0\n",
    "        for length in self.sizeList:\n",
    "            allLen=allLen+length\n",
    "        return allLen\n",
    "    \n",
    "    def fromIdxMapToList(self,idx):\n",
    "        \"\"\"\n",
    "        since there are several lists,we have to know which list shoud we use and the ture index in the list\n",
    "        Return:\n",
    "            the trueIndex, listIndex\n",
    "        \"\"\"\n",
    "        countSection=0\n",
    "        for i in range(0,self.sizeList.__len__()):\n",
    "            countSection+=self.sizeList[i]\n",
    "            if(idx<countSection):\n",
    "                return idx-countSection+self.sizeList[i],i\n",
    "            \n",
    "    \n",
    "            \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        #initialize trueIndex, listIndex\n",
    "        #\n",
    "        #this dict record the relation between matrix index and vehicle ID in the last frame\n",
    "        matrixIndexAndVehicleIDRecordDict={}\n",
    "        #initialize dict above\n",
    "        for i in range(0,maxMatrixIndex):\n",
    "            matrixIndexAndVehicleIDRecordDict[i]={'Vehicle_ID':-1,'refresh':-1}\n",
    "        matrixIndexAndVehicleIDRecordDict['time']=-1\n",
    "        trueIndex,listIndex=self.fromIdxMapToList(idx)\n",
    "        itemDict={'positionTensorList':[],'speedTensorList':[],'accTensorList':[],'angleTensorList':[],'time':[]}\n",
    "        valueDict=self.valueDictList[listIndex] #valueDict is the Dict of many frames\n",
    "        dictKeys=self.keysList[listIndex]\n",
    "        #generate tensors of first frame\n",
    "        positionTensor,speedTensor,accTensor,angleTensor,newVehicleList\\\n",
    "        =readFirstFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[trueIndex]])\n",
    "        angleSinTensor=torch.sin(angleTensor)\n",
    "        angleCosTensor=torch.cos(angleTensor)\n",
    "        fileName='./'+'tensorFromGetitem'+'/'+str(10000000+idx)+'.png'\n",
    "        image=visualizeTensorData(positionTensor[0,:],positionTensor[1,:])\n",
    "        cv2.imwrite(fileName,image)\n",
    "        #first frame normalization\n",
    "        if doNormalization:\n",
    "#             print('before nomalization')\n",
    "#             print(positionTensor.shape,speedTensor.shape,accTensor.shape)\n",
    "            positionTensor=torch.cat((torch.div(torch.sub(positionTensor[0,:],self.positionXMin),self.positionXMax-self.positionXMin).unsqueeze(0),\\\n",
    "                                     torch.div(torch.sub(positionTensor[1,:],self.positionYMin,),self.positionYMax-self.positionYMin).unsqueeze(0)),0)\n",
    "            speedTensor=torch.div(torch.sub(speedTensor,self.speedMin),self.speedMax-self.speedMin)\n",
    "            accTensor=torch.div(torch.sub(accTensor,self.accMin),self.accMax-self.accMin)\n",
    "#             print('after normalization')\n",
    "#             print(positionTensor.shape,speedTensor.shape,accTensor.shape)\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "        else:\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "        #generate relation tensor for all vehicle pairs\n",
    "        print('in getitem, combinedTensor shape: ',combinedTensor.shape)\n",
    "        fileName='./'+'tensorFromGetitemAfterNormalization'+'/'+str(10000000+idx)+'.png'\n",
    "        image=visualizeTensorData(positionTensor[0,:],positionTensor[1,:],normalizationDict=self.getNormalizationDict())\n",
    "        cv2.imwrite(fileName,image)\n",
    "        relationTensorLeft=combinedTensor[:,0].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])\n",
    "        relationTensorRight=torch.transpose(torch.cat((combinedTensor[:,:0],combinedTensor[:,1:]),1),0,1)\n",
    "        print('in getitem, relation tensorleft shape:',relationTensorLeft.shape)\n",
    "        print('in getitem, relationtensorright shape',relationTensorRight.shape)\n",
    "#         print(relationTensorRight.shape,relationTensorRight.shape)\n",
    "        for i in range(1,combinedTensor.shape[1]):\n",
    "            relationTensorLeft=torch.cat((relationTensorLeft,\\\n",
    "                                          combinedTensor[:,i].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])),0)\n",
    "            relationTensorRight=torch.cat((relationTensorRight,\\\n",
    "                                           torch.transpose(torch.cat((combinedTensor[:,:i],combinedTensor[:,i+1:]),1),0,1)),0)\n",
    "#         print(relationTensorLeft.shape,relationTensorRight.shape)\n",
    "        combinedRelationTensor=torch.cat((relationTensorLeft,relationTensorRight),1)  \n",
    "        firstCombinedRelationTensor=combinedRelationTensor\n",
    "        firstCombinedTensor=combinedTensor\n",
    "        \n",
    "        \n",
    "        allCombineTensorTrain=combinedTensor.unsqueeze(0)\n",
    "        allCombineTensorValid=0\n",
    "#         itemDict['positionTensorList'].append(positionTensor)\n",
    "#         itemDict['speedTensorList'].append(speedTensor)\n",
    "#         itemDict['accTensorList'].append(accTensor)\n",
    "#         itemDict['angleTensorList'].append(angleTensor)\n",
    "#         time=getValueByLable(['Global_Time'],valueDict[dictKeys[trueIndex]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]][0]\n",
    "#         itemDict['time'].append(time)\n",
    "        \n",
    "        for i in range(trueIndex+1,trueIndex+self.allTensorsEachBatch):\n",
    "            #generate tensor from general frame\n",
    "            positionTensor,speedTensor,accTensor,angleTensor,newVehicleList,vanishedVehicleList\\\n",
    "            =readGeneralFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[i]],positionTensor)\n",
    "            angleSinTensor=torch.sin(angleTensor)\n",
    "            angleCosTensor=torch.cos(angleTensor)\n",
    "            if doNormalization:\n",
    "                positionTensor=torch.cat((torch.div(torch.sub(positionTensor[0,:],self.positionXMin),self.positionXMax-self.positionXMin).unsqueeze(0),\\\n",
    "                                         torch.div(torch.sub(positionTensor[1,:],self.positionYMin,),self.positionYMax-self.positionYMin).unsqueeze(0)),0)\n",
    "                speedTensor=torch.div(torch.sub(speedTensor,self.speedMin),self.speedMax-self.speedMin)\n",
    "                accTensor=torch.div(torch.sub(accTensor,self.accMin),self.accMax-self.accMin)\n",
    "                combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                         speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                         accTensor.mul(angleCosTensor)),0)\n",
    "            else:\n",
    "                combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                         accTensor.mul(angleCosTensor)),0)\n",
    "            #generate relation tensor for all vehicle pairs\n",
    "            relationTensorLeft=combinedTensor[:,0].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])\n",
    "            relationTensorRight=torch.transpose(torch.cat((combinedTensor[:,:0],combinedTensor[:,1:]),1),0,1)\n",
    "#             print(relationTensorRight.shape,relationTensorRight.shape)\n",
    "            for j in range(1,combinedTensor.shape[1]):\n",
    "                relationTensorLeft=torch.cat((relationTensorLeft,\\\n",
    "                                              combinedTensor[:,j].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])),0)\n",
    "                relationTensorRight=torch.cat((relationTensorRight,\\\n",
    "                                               torch.transpose(torch.cat((combinedTensor[:,:j],combinedTensor[:,j+1:]),1),0,1)),0)\n",
    "#             print(relationTensorLeft.shape,relationTensorRight.shape)\n",
    "            combinedRelationTensor=torch.cat((relationTensorLeft,relationTensorRight),1)  \n",
    "            secondRelationTensor=combinedRelationTensor\n",
    "            secondCombinedTensor=combinedTensor\n",
    "            #since we only need two tensors, which is input and output tensor respectively, we could return\n",
    "            #the two tensors in the first loop\n",
    "            #(ok I admit that the true reason is that I am lazy)\n",
    "            return firstCombinedTensor,secondCombinedTensor\n",
    "            return firstCombinedRelationTensor,secondRelationTensor\n",
    "#             if i<self.numberOfTensorsEachBatch+trueIndex:\n",
    "#                 allCombineTensorTrain=torch.cat((allCombineTensorTrain,combinedTensor.unsqueeze(0)),0)\n",
    "#             elif i==self.numberOfTensorsEachBatch+trueIndex:\n",
    "#                 allCombineTensorValid=combinedTensor.unsqueeze(0)\n",
    "#             else:\n",
    "#                 allCombineTensorValid=torch.cat((allCombineTensorValid,combinedTensor.unsqueeze(0)),0)\n",
    "#             itemDict['positionTensorList'].append(positionTensor)\n",
    "#             itemDict['speedTensorList'].append(speedTensor)\n",
    "#             itemDict['accTensorList'].append(accTensor)\n",
    "#             itemDict['angleTensorList'].append(angleTensor)\n",
    "#             time=getValueByLable(['Global_Time'],valueDict[dictKeys[i]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]]\n",
    "#             itemDict['time'].append(time)\n",
    "        return allCombineTensorTrain,allCombineTensorValid\n",
    "# trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0805am-0820am/trajectories-0805am-0820am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0820am-0835am/trajectories-0820am-0835am.txt']\n",
    "trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n",
    "#run on 2080 in g814\n",
    "if runOnG814:\n",
    "    trajectoryFileList=['/home/wangyuchen/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datasetV2Test=tensorsDatasetV2Test(trajectoryFileList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(datasetV2Test.getNormalizationDict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "firstCombined,secondCombined=datasetV2Test.__getitem__(40)\n",
    "print(firstCombined.shape,secondCombined.shape)\n",
    "image=visualizeTensorData(firstCombined[0,:],firstCombined[1,:],normalizationDict=datasetV2Test.getNormalizationDict())\n",
    "dirName='combinedTensorFolder'+str(int(time.time()))\n",
    "os.mkdir(dirName)\n",
    "for i in range(0,2000):\n",
    "    fileName='./'+dirName+'/'+str(10000000+i)+'.png'\n",
    "    firstCombined,secondCombined=datasetV2Test.__getitem__(i)\n",
    "    image=visualizeTensorData(firstCombined[0,:],firstCombined[1,:],normalizationDict=datasetV2Test.getNormalizationDict())\n",
    "    cv2.imwrite(fileName,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class tensorsDatasetV3(Dataset):\n",
    "    \"\"\"\n",
    "    dataset for relation lstm model\n",
    "    \"\"\"\n",
    "    def __init__(self, trajectoryFileList, numberOfTensorsEachBatch=10,lableTensorEachBatch=10):\n",
    "\n",
    "        self.valueDictList=[]\n",
    "        self.sizeList=[]\n",
    "        self.numberOfTensorsEachBatch=numberOfTensorsEachBatch\n",
    "        self.lableTensorEachBatch=lableTensorEachBatch\n",
    "        self.allTensorsEachBatch=numberOfTensorsEachBatch+lableTensorEachBatch\n",
    "        self.keysList=[]\n",
    "        if doNormalization:\n",
    "            self.positionXMax=0\n",
    "            self.positionXMin=999999\n",
    "            self.positionYMax=0\n",
    "            self.positionYMin=99999\n",
    "            self.speedMax=-100\n",
    "            self.speedMin=999999\n",
    "            self.accMax=-100\n",
    "            self.accMin=9999\n",
    "        for eachFile in trajectoryFileList:\n",
    "            valueDict=fromDirGenerateDict(eachFile)\n",
    "            if doNormalization:\n",
    "                #get the max and min value for normalization\n",
    "                maxAndMinDict=getMaxAndMinValueFromValueDict(valueDict,['Local_X','Local_Y','v_Vel','v_Acc'])\n",
    "                #position X\n",
    "                if self.positionXMax<maxAndMinDict['Local_X']['max']:\n",
    "                    self.positionXMax=maxAndMinDict['Local_X']['max']\n",
    "                if self.positionXMin>maxAndMinDict['Local_X']['min']:\n",
    "                    self.positionXMin=maxAndMinDict['Local_X']['min']\n",
    "                #position Y\n",
    "                if self.positionYMax<maxAndMinDict['Local_Y']['max']:\n",
    "                    self.positionYMax=maxAndMinDict['Local_Y']['max']\n",
    "                if self.positionYMin>maxAndMinDict['Local_Y']['min']:\n",
    "                    self.positionYMin=maxAndMinDict['Local_Y']['min']\n",
    "                #speed\n",
    "                if self.speedMax<maxAndMinDict['v_Vel']['max']:\n",
    "                    self.speedMax=maxAndMinDict['v_Vel']['max']\n",
    "                if self.speedMin>maxAndMinDict['v_Vel']['min']:\n",
    "                    self.speedMin=maxAndMinDict['v_Vel']['min']\n",
    "                #acc\n",
    "                if self.accMax<maxAndMinDict['v_Acc']['max']:\n",
    "                    self.accMax=maxAndMinDict['v_Acc']['max']\n",
    "                if self.accMin>maxAndMinDict['v_Acc']['min']:\n",
    "                    self.accMin=maxAndMinDict['v_Acc']['min']\n",
    "            self.valueDictList.append(copy.deepcopy(valueDict))\n",
    "            self.sizeList.append(valueDict.keys().__len__()-self.allTensorsEachBatch)\n",
    "            sortedKeys=list(valueDict.keys())\n",
    "            sortedKeys.sort()\n",
    "            self.keysList.append(copy.deepcopy(sortedKeys))\n",
    "\n",
    "    def getNormalizationDict(self):\n",
    "        '''\n",
    "        Returns:\n",
    "            a dict:{'positionXMax':self.positionXMax,'positonYMax':self.self.positionYMax,\\\n",
    "               'positionXMin':self.positionXMin,'positionYMin':self.positionYMin,\\\n",
    "               'speedMax':self.speedMax,'speedMin':speedMin,\\\n",
    "               'accMax':self.accMax,'accMax':self.accMin}\n",
    "        '''\n",
    "        if not doNormalization:\n",
    "            raise Exception('NORMALIZATION IS NOT APPLIED')\n",
    "        return {'positionXMax':self.positionXMax,'positionYMax':self.positionYMax,\\\n",
    "               'positionXMin':self.positionXMin,'positionYMin':self.positionYMin,\\\n",
    "               'speedMax':self.speedMax,'speedMin':self.speedMin,\\\n",
    "               'accMax':self.accMax,'accMax':self.accMin}\n",
    "    \n",
    "    def __len__(self):\n",
    "        allLen=0\n",
    "        for length in self.sizeList:\n",
    "            allLen=allLen+length\n",
    "        return allLen\n",
    "    \n",
    "    def fromIdxMapToList(self,idx):\n",
    "        \"\"\"\n",
    "        since there are several lists,we have to know which list shoud we use and the true index in the list\n",
    "        Return:\n",
    "            the trueIndex, listIndex\n",
    "        \"\"\"\n",
    "        countSection=0\n",
    "        for i in range(0,self.sizeList.__len__()):\n",
    "            countSection+=self.sizeList[i]\n",
    "            if(idx<countSection):\n",
    "                return idx-countSection+self.sizeList[i],i\n",
    "            \n",
    "    \n",
    "            \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        #initialize trueIndex, listIndex\n",
    "        #\n",
    "        #this dict record the relation between matrix index and vehicle ID in the last frame\n",
    "        matrixIndexAndVehicleIDRecordDict={}\n",
    "        #initialize dict above\n",
    "        for i in range(0,maxMatrixIndex):\n",
    "            matrixIndexAndVehicleIDRecordDict[i]={'Vehicle_ID':-1,'refresh':-1}\n",
    "        matrixIndexAndVehicleIDRecordDict['time']=-1\n",
    "        trueIndex,listIndex=self.fromIdxMapToList(idx)\n",
    "        itemDict={'positionTensorList':[],'speedTensorList':[],'accTensorList':[],'angleTensorList':[],'time':[]}\n",
    "        valueDict=self.valueDictList[listIndex] #valueDict is the Dict of many frames\n",
    "        dictKeys=self.keysList[listIndex]\n",
    "        #generate tensors of first frame\n",
    "        positionTensor,speedTensor,accTensor,angleTensor,newVehicleList\\\n",
    "        =readFirstFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[trueIndex]])\n",
    "        angleSinTensor=torch.sin(angleTensor)\n",
    "        angleCosTensor=torch.cos(angleTensor)\n",
    "        #first frame normalization\n",
    "        if doNormalization:\n",
    "#             print('before nomalization')\n",
    "#             print(positionTensor.shape,speedTensor.shape,accTensor.shape)\n",
    "            positionTensor=torch.cat((torch.div(torch.sub(positionTensor[0,:],self.positionXMin),self.positionXMax-self.positionXMin).unsqueeze(0),\\\n",
    "                                     torch.div(torch.sub(positionTensor[1,:],self.positionYMin,),self.positionYMax-self.positionYMin).unsqueeze(0)),0)\n",
    "            speedTensor=torch.div(torch.sub(speedTensor,self.speedMin),self.speedMax-self.speedMin)\n",
    "            accTensor=torch.div(torch.sub(accTensor,self.accMin),self.accMax-self.accMin)\n",
    "#             print('after normalization')\n",
    "#             print(positionTensor.shape,speedTensor.shape,accTensor.shape)\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "        else:\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        allCombineTensorTrain=combinedTensor.unsqueeze(0)\n",
    "        allCombineTensorValid=0\n",
    "#         itemDict['positionTensorList'].append(positionTensor)\n",
    "#         itemDict['speedTensorList'].append(speedTensor)\n",
    "#         itemDict['accTensorList'].append(accTensor)\n",
    "#         itemDict['angleTensorList'].append(angleTensor)\n",
    "#         time=getValueByLable(['Global_Time'],valueDict[dictKeys[trueIndex]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]][0]\n",
    "#         itemDict['time'].append(time)\n",
    "        \n",
    "        for i in range(trueIndex+1,trueIndex+self.allTensorsEachBatch):\n",
    "            #generate tensor from general frame\n",
    "            positionTensor,speedTensor,accTensor,angleTensor,newVehicleList,vanishedVehicleList\\\n",
    "            =readGeneralFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[i]],positionTensor)\n",
    "            angleSinTensor=torch.sin(angleTensor)\n",
    "            angleCosTensor=torch.cos(angleTensor)\n",
    "            if doNormalization:\n",
    "                positionTensor=torch.cat((torch.div(torch.sub(positionTensor[0,:],self.positionXMin),self.positionXMax-self.positionXMin).unsqueeze(0),\\\n",
    "                                         torch.div(torch.sub(positionTensor[1,:],self.positionYMin,),self.positionYMax-self.positionYMin).unsqueeze(0)),0)\n",
    "                speedTensor=torch.div(torch.sub(speedTensor,self.speedMin),self.speedMax-self.speedMin)\n",
    "                accTensor=torch.div(torch.sub(accTensor,self.accMin),self.accMax-self.accMin)\n",
    "                combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                         speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                         accTensor.mul(angleCosTensor)),0)\n",
    "            else:\n",
    "                combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                         accTensor.mul(angleCosTensor)),0)\n",
    "            if i<self.numberOfTensorsEachBatch+trueIndex:\n",
    "                allCombineTensorTrain=torch.cat((allCombineTensorTrain,combinedTensor.unsqueeze(0)),0)\n",
    "            elif i==self.numberOfTensorsEachBatch+trueIndex:\n",
    "                allCombineTensorValid=combinedTensor.unsqueeze(0)\n",
    "            else:\n",
    "                allCombineTensorValid=torch.cat((allCombineTensorValid,combinedTensor.unsqueeze(0)),0)\n",
    "#             itemDict['positionTensorList'].append(positionTensor)\n",
    "#             itemDict['speedTensorList'].append(speedTensor)\n",
    "#             itemDict['accTensorList'].append(accTensor)\n",
    "#             itemDict['angleTensorList'].append(angleTensor)\n",
    "#             time=getValueByLable(['Global_Time'],valueDict[dictKeys[i]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]]\n",
    "#             itemDict['time'].append(time)\n",
    "        return allCombineTensorTrain,allCombineTensorValid\n",
    "# trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0805am-0820am/trajectories-0805am-0820am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0820am-0835am/trajectories-0820am-0835am.txt']\n",
    "trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n",
    "#run on 2080 in g814\n",
    "if runOnG814:\n",
    "    trajectoryFileList=['/home/wangyuchen/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class tensorsDatasetV4(Dataset):\n",
    "    \"\"\"\n",
    "    dataset for difference series type\n",
    "    Returns:\n",
    "    INPUTS:\n",
    "    relationTensors,discountParameterTensors,\n",
    "    OUTPUTS:\n",
    "    allCombineTensorTrain, allCombineTensorValid,\\\n",
    "        combinedRelationTensors, combinedDiscountParameterTensors,differenceLabels\n",
    "    \"\"\"\n",
    "    def __init__(self, trajectoryFileList, numberOfTensorsEachBatch=10,lableTensorEachBatch=10,\\\n",
    "                maxRelationNumber=20,givenRange=0.08):\n",
    "\n",
    "        self.valueDictList=[]\n",
    "        self.sizeList=[]\n",
    "        self.numberOfTensorsEachBatch=numberOfTensorsEachBatch\n",
    "        self.lableTensorEachBatch=lableTensorEachBatch\n",
    "        self.allTensorsEachBatch=numberOfTensorsEachBatch+lableTensorEachBatch\n",
    "        self.keysList=[]\n",
    "        self.maxRelationNumber=maxRelationNumber\n",
    "        self.givenRange=givenRange\n",
    "        if doNormalization:\n",
    "            self.positionXMax=0\n",
    "            self.positionXMin=999999\n",
    "            self.positionYMax=0\n",
    "            self.positionYMin=99999\n",
    "            self.speedMax=-100\n",
    "            self.speedMin=999999\n",
    "            self.accMax=-100\n",
    "            self.accMin=9999\n",
    "        for eachFile in trajectoryFileList:\n",
    "            valueDict=fromDirGenerateDict(eachFile)\n",
    "            if doNormalization:\n",
    "                #get the max and min value for normalization\n",
    "                maxAndMinDict=getMaxAndMinValueFromValueDict(valueDict,['Local_X','Local_Y','v_Vel','v_Acc'])\n",
    "                #position X\n",
    "                if self.positionXMax<maxAndMinDict['Local_X']['max']:\n",
    "                    self.positionXMax=maxAndMinDict['Local_X']['max']\n",
    "                if self.positionXMin>maxAndMinDict['Local_X']['min']:\n",
    "                    self.positionXMin=maxAndMinDict['Local_X']['min']\n",
    "                #position Y\n",
    "                if self.positionYMax<maxAndMinDict['Local_Y']['max']:\n",
    "                    self.positionYMax=maxAndMinDict['Local_Y']['max']\n",
    "                if self.positionYMin>maxAndMinDict['Local_Y']['min']:\n",
    "                    self.positionYMin=maxAndMinDict['Local_Y']['min']\n",
    "                #speed\n",
    "                if self.speedMax<maxAndMinDict['v_Vel']['max']:\n",
    "                    self.speedMax=maxAndMinDict['v_Vel']['max']\n",
    "                if self.speedMin>maxAndMinDict['v_Vel']['min']:\n",
    "                    self.speedMin=maxAndMinDict['v_Vel']['min']\n",
    "                #acc\n",
    "                if self.accMax<maxAndMinDict['v_Acc']['max']:\n",
    "                    self.accMax=maxAndMinDict['v_Acc']['max']\n",
    "                if self.accMin>maxAndMinDict['v_Acc']['min']:\n",
    "                    self.accMin=maxAndMinDict['v_Acc']['min']\n",
    "            self.valueDictList.append(copy.deepcopy(valueDict))\n",
    "            self.sizeList.append(valueDict.keys().__len__()-self.allTensorsEachBatch)\n",
    "            sortedKeys=list(valueDict.keys())\n",
    "            sortedKeys.sort()\n",
    "            self.keysList.append(copy.deepcopy(sortedKeys))\n",
    "\n",
    "    def getNormalizationDict(self):\n",
    "        '''\n",
    "        Returns:\n",
    "            a dict:{'positionXMax':self.positionXMax,'positonYMax':self.self.positionYMax,\\\n",
    "               'positionXMin':self.positionXMin,'positionYMin':self.positionYMin,\\\n",
    "               'speedMax':self.speedMax,'speedMin':speedMin,\\\n",
    "               'accMax':self.accMax,'accMax':self.accMin}\n",
    "        '''\n",
    "        if not doNormalization:\n",
    "            raise Exception('NORMALIZATION IS NOT APPLIED')\n",
    "        return {'positionXMax':self.positionXMax,'positionYMax':self.positionYMax,\\\n",
    "               'positionXMin':self.positionXMin,'positionYMin':self.positionYMin,\\\n",
    "               'speedMax':self.speedMax,'speedMin':self.speedMin,\\\n",
    "               'accMax':self.accMax,'accMax':self.accMin}\n",
    "    \n",
    "    def __len__(self):\n",
    "        allLen=0\n",
    "        for length in self.sizeList:\n",
    "            allLen=allLen+length\n",
    "        return allLen\n",
    "    \n",
    "    def fromIdxMapToList(self,idx):\n",
    "        \"\"\"\n",
    "        since there are several lists,we have to know which list shoud we use and the true index in the list\n",
    "        Return:\n",
    "            the trueIndex, listIndex\n",
    "        \"\"\"\n",
    "        countSection=0\n",
    "        for i in range(0,self.sizeList.__len__()):\n",
    "            countSection+=self.sizeList[i]\n",
    "            if(idx<countSection):\n",
    "                return idx-countSection+self.sizeList[i],i\n",
    "            \n",
    "    \n",
    "            \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        #initialize trueIndex, listIndex\n",
    "        #\n",
    "        #this dict record the relation between matrix index and vehicle ID in the last frame\n",
    "        matrixIndexAndVehicleIDRecordDict={}\n",
    "        #initialize dict above\n",
    "        for i in range(0,maxMatrixIndex):\n",
    "            matrixIndexAndVehicleIDRecordDict[i]={'Vehicle_ID':-1,'refresh':-1}\n",
    "        matrixIndexAndVehicleIDRecordDict['time']=-1\n",
    "        trueIndex,listIndex=self.fromIdxMapToList(idx)\n",
    "        itemDict={'positionTensorList':[],'speedTensorList':[],'accTensorList':[],'angleTensorList':[],'time':[]}\n",
    "        valueDict=self.valueDictList[listIndex] #valueDict is the Dict of many frames\n",
    "        dictKeys=self.keysList[listIndex]\n",
    "        #generate tensors of first frame\n",
    "        positionTensor,speedTensor,accTensor,angleTensor,newVehicleList\\\n",
    "        =readFirstFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[trueIndex]])\n",
    "        angleSinTensor=torch.sin(angleTensor)\n",
    "        angleCosTensor=torch.cos(angleTensor)\n",
    "        #first frame normalization\n",
    "        if doNormalization:\n",
    "#             print('before nomalization')\n",
    "#             print(positionTensor.shape,speedTensor.shape,accTensor.shape)\n",
    "            positionTensor=torch.cat((torch.div(torch.sub(positionTensor[0,:],self.positionXMin),self.positionXMax-self.positionXMin).unsqueeze(0),\\\n",
    "                                     torch.div(torch.sub(positionTensor[1,:],self.positionYMin,),self.positionYMax-self.positionYMin).unsqueeze(0)),0)\n",
    "            speedTensor=torch.div(torch.sub(speedTensor,self.speedMin),self.speedMax-self.speedMin)\n",
    "            accTensor=torch.div(torch.sub(accTensor,self.accMin),self.accMax-self.accMin)\n",
    "#             print('after normalization')\n",
    "#             print(positionTensor.shape,speedTensor.shape,accTensor.shape)\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "        else:\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        allCombineTensorTrain=combinedTensor.unsqueeze(0)\n",
    "        allCombineTensorValid=0\n",
    "#         itemDict['positionTensorList'].append(positionTensor)\n",
    "#         itemDict['speedTensorList'].append(speedTensor)\n",
    "#         itemDict['accTensorList'].append(accTensor)\n",
    "#         itemDict['angleTensorList'].append(angleTensor)\n",
    "#         time=getValueByLable(['Global_Time'],valueDict[dictKeys[trueIndex]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]][0]\n",
    "#         itemDict['time'].append(time)\n",
    "        \n",
    "        for i in range(trueIndex+1,trueIndex+self.allTensorsEachBatch):\n",
    "            #generate tensor from general frame\n",
    "            positionTensor,speedTensor,accTensor,angleTensor,newVehicleList,vanishedVehicleList\\\n",
    "            =readGeneralFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[i]],positionTensor)\n",
    "            angleSinTensor=torch.sin(angleTensor)\n",
    "            angleCosTensor=torch.cos(angleTensor)\n",
    "            if doNormalization:\n",
    "                positionTensor=torch.cat((torch.div(torch.sub(positionTensor[0,:],self.positionXMin),self.positionXMax-self.positionXMin).unsqueeze(0),\\\n",
    "                                         torch.div(torch.sub(positionTensor[1,:],self.positionYMin,),self.positionYMax-self.positionYMin).unsqueeze(0)),0)\n",
    "                speedTensor=torch.div(torch.sub(speedTensor,self.speedMin),self.speedMax-self.speedMin)\n",
    "                accTensor=torch.div(torch.sub(accTensor,self.accMin),self.accMax-self.accMin)\n",
    "                combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                         speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                         accTensor.mul(angleCosTensor)),0)\n",
    "            else:\n",
    "                combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                         accTensor.mul(angleCosTensor)),0)\n",
    "            if i<self.numberOfTensorsEachBatch+trueIndex:\n",
    "                allCombineTensorTrain=torch.cat((allCombineTensorTrain,combinedTensor.unsqueeze(0)),0)\n",
    "            elif i==self.numberOfTensorsEachBatch+trueIndex:\n",
    "                allCombineTensorValid=combinedTensor.unsqueeze(0)\n",
    "            else:\n",
    "                allCombineTensorValid=torch.cat((allCombineTensorValid,combinedTensor.unsqueeze(0)),0)\n",
    "#             itemDict['positionTensorList'].append(positionTensor)\n",
    "#             itemDict['speedTensorList'].append(speedTensor)\n",
    "#             itemDict['accTensorList'].append(accTensor)\n",
    "#             itemDict['angleTensorList'].append(angleTensor)\n",
    "#             time=getValueByLable(['Global_Time'],valueDict[dictKeys[i]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]]\n",
    "#             itemDict['time'].append(time)\n",
    "#         return allCombineTensorTrain,allCombineTensorValid\n",
    "        #only consist of position tensor, ignore speed tensor and accelerate tensor\n",
    "        allCombineTensorTrain=allCombineTensorTrain[:,0:2,:]\n",
    "        allCombineTensorValid=allCombineTensorValid[:,0:2,:]\n",
    "        logging.debug(fromAllToStr('allCombineTensorTrain.shape:',allCombineTensorTrain.shape))\n",
    "        logging.debug(fromAllToStr('allCombineTensorValid.shape',allCombineTensorValid))\n",
    "        combinedRelationTensors,combinedDiscountParameterTensors=\\\n",
    "        computeRelationAndAllTheOtherTensorsWithDistance(\\\n",
    "        allCombineTensorTrain,theGivenRange=self.givenRange,\\\n",
    "        maxRelationsNumber=self.maxRelationNumber)\n",
    "        #permute the dimension order of the valid tensor\n",
    "        differenceLabels=differenceBetweenTwoFrameForTimeSteps(allCombineTensorValid.permute(0,2,1))\n",
    "        logging.debug(fromAllToStr(\"differenceLabels.shape:\",differenceLabels.shape))\n",
    "        return allCombineTensorTrain, allCombineTensorValid,\\\n",
    "        combinedRelationTensors, combinedDiscountParameterTensors,differenceLabels\n",
    "        \n",
    "        \n",
    "            \n",
    "# trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0805am-0820am/trajectories-0805am-0820am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0820am-0835am/trajectories-0820am-0835am.txt']\n",
    "trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n",
    "#run on 2080 in g814\n",
    "if runOnG814:\n",
    "    trajectoryFileList=['/home/wangyuchen/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datasetV2=tensorsDatasetV2(trajectoryFileList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "dataIter=iter(datasetV2)\n",
    "first,second=dataIter.__next__()\n",
    "print(first.shape, second.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maxMatrixIndex=250\n",
    "dataloaderV2=DataLoader(datasetV2,batch_size=4,shuffle=True)\n",
    "for i,item in enumerate(dataloaderV2):\n",
    "    if(i>0):\n",
    "        break\n",
    "    print(i)\n",
    "    first,second=item\n",
    "    print(first.shape,second.shape)\n",
    "    print(first[0,:5,:6])\n",
    "    print(first[0,(2,245,246,247,248,249,250,251),6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def generateAdjacencyMatrix(batchedPositionTensor,lambdaX,lambdaY,omegaX,omegaY,m):\n",
    "    \"\"\"\n",
    "    Using batched position tensor generate batched adjacency matrix\n",
    "    Args:\n",
    "        batchedPositionTensor: a batch of position tensor, which size in (batch, timeSequence,2,vehicles), the \n",
    "        value 2 in dim=2 is the position of x and y. \n",
    "        lambda1,lambda2,omega1,omega2,m are parameters of the function. m<1\n",
    "        see detail in my notebook\n",
    "    Returns:\n",
    "        a batch of adjacency matrix\n",
    "    Example:\n",
    "        if given a batch of combined tensor, named theTensor, which size as below:\n",
    "            (4,100,6,250)\n",
    "        which means 4 batches, 100 time step, 6 dimension which respectively of positonx, positony, velocityx, \n",
    "        velocityy, accx,accy.\n",
    "        then we apply the function in such way:\n",
    "        generateAdjacencyMatrix(theTensor(:,:,0:1,:))\n",
    "    \"\"\"\n",
    "    print(batchedPositionTensor.size())\n",
    "    sizeOfEachMatrix=batchedPositionTensor[0,0,0,:].size()[0]\n",
    "    print(sizeOfEachMatrix)\n",
    "    for batchI in range(batchedPositionTensor.size()[0]): #revolve each batch\n",
    "#         print('batchI',batchI)\n",
    "        timeStepsMatrixList=[]\n",
    "        for timeStepI in range(batchedPositionTensor.size()[1]):#revolve each time step\n",
    "#             print('timeStepI:',timeStepI)\n",
    "#             adjacencyMatrix=np.zeros((sizeOfEachMatrix,sizeOfEachMatrix))\n",
    "            adjacencyList=[]\n",
    "            tempPositionList=batchedPositionTensor[batchI,timeStepI,:,:].numpy().tolist()\n",
    "#             start=time.time()\n",
    "            for i in range(sizeOfEachMatrix):\n",
    "                tempLineList=[]\n",
    "                for j in range(sizeOfEachMatrix):\n",
    "#                     adjacencyMatrix[i,j]=1\n",
    "                    if (tempPositionList[1][i]*tempPositionList[1][j]==0):\n",
    "                        toZero=0\n",
    "                    else:\n",
    "                        toZero=1\n",
    "                        \n",
    "                    #calculate original element with linear function\n",
    "#                     tempLineList.append((1-abs(tempPositionList[1][i]-tempPositionList[1][j]))*\\\n",
    "#                         (1-abs(tempPositionList[0][i]-tempPositionList[0][j]))*toZero)\n",
    "                    \n",
    "                    #calculate original element with exponential function\n",
    "                    element=(omegaY/(math.exp(lambdaY*(abs(tempPositionList[1][j]-tempPositionList[1][i])))))*\\\n",
    "                    (omegaX/(math.exp(lambdaX*(abs(tempPositionList[0][j]-tempPositionList[0][i])))))*toZero\n",
    "                    tempLineList.append(element)\n",
    "#                     adjacencyMatrix[i,j]=(batchedPositionTensor[batchI,timeStepI,1,i]-batchedPositionTensor[batchI,timeStepI,1,j])*\\\n",
    "#                         (batchedPositionTensor[batchI,timeStepI,0,i]-batchedPositionTensor[batchI,timeStepI,0,j])\n",
    "#                     (omegaY/math.exp(lambdaX*abs(batchedPositionTensor[batchI,timeStepI,1,i]-batchedPositionTensor[batchI,timeStepI,1,j])))*\\\n",
    "#                     (omegaX/math.exp(lambdaY*abs(batchedPositionTensor[batchI,timeStepI,0,i]-batchedPositionTensor[batchI,timeStepI,0,j])))\n",
    "                    \n",
    "                    #calculate original element with expenential\n",
    "#                     adjacencyMatrix[i,j]=\n",
    "#                     (omegaY/math.exp(lambdaX*abs(batchedPositionTensor[batchI,timeStepI,1,i]-batchedPositionTensor[batchI,timeStepI,1,j])))*\\\n",
    "#                     (omegaX/math.exp(lambdaY*abs(batchedPositionTensor[batchI,timeStepI,0,i]-batchedPositionTensor[batchI,timeStepI,0,j])))\n",
    "                    if(tempPositionList[1][j]-tempPositionList[1][i]<0):\n",
    "                        #if i follows j, then multiple m, m<1\n",
    "                        tempLineList[j]=tempLineList[j]*m\n",
    "                adjacencyList.append(tempLineList)\n",
    "            \n",
    "#             end=time.time()\n",
    "#             print(end-start)\n",
    "            adjacencyMatrix=torch.tensor(adjacencyList).unsqueeze(0)\n",
    "            if timeStepI==0:\n",
    "                matrixSequenceInTimeStepDim=adjacencyMatrix\n",
    "            else:\n",
    "                matrixSequenceInTimeStepDim=\\\n",
    "                torch.cat((matrixSequenceInTimeStepDim,adjacencyMatrix),0)\n",
    "        matrixSequenceInTimeStepDim=matrixSequenceInTimeStepDim.unsqueeze(0)\n",
    "        if batchI==0:\n",
    "            matrixSequenceInBatchDim=matrixSequenceInTimeStepDim\n",
    "        else:\n",
    "            matrixSequenceInBatchDim=torch.cat((matrixSequenceInBatchDim,matrixSequenceInTimeStepDim),0)            \n",
    "    return matrixSequenceInBatchDim\n",
    "\n",
    "def tensorNormalization(inputTensor,minValue,maxValue):\n",
    "    inputTensor.div_(maxValue)\n",
    "    \n",
    "def batchNormalizationForCombinedTensor(inputBatchedTensor,minX,maxX,minY,maxY,minV,maxV,minA,maxA):\n",
    "    tensorNormalization(inputBatchedTensor[:,:,0,:],minX,maxX)\n",
    "    tensorNormalization(inputBatchedTensor[:,:,1,:],minY,maxY)\n",
    "    tensorNormalization(inputBatchedTensor[:,:,2:4,:],minV,maxV)\n",
    "    tensorNormalization(inputBatchedTensor[:,:,4:6,:],minA,maxA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    __init__(self, input_size, cell_size, hidden_size, output_last = True)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, cell_size, hidden_size, output_last = True):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        \"\"\"\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((input, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "            return Hidden_State\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# maxMatrixIndex=250\n",
    "# trajectorDataSet=tensorsDataset(trajectoryFileList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataLoader=DataLoader(trajectorDataSet,batch_size=1,shuffle=True,num_workers=4)\n",
    "# for i,data in enumerate(dataLoader):\n",
    "#     print('11111')\n",
    "#     if(i>10):\n",
    "#         break\n",
    "#     print(data[0].shape)\n",
    "#     print(data[0][0,:,1,1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code fragment below is used to visualize tensor data\n",
    "# dataLoader=DataLoader(trajectorDataSet,batch_size=1,shuffle=True,num_workers=4)\n",
    "# for dataI,data in enumerate(dataLoader):\n",
    "#     if(dataI>10):\n",
    "#         break\n",
    "#     for i in range(int(data[0][0,:,0,0].shape[0])):\n",
    "#         tensorImage=visualizeTensorData(data[0][0,i,0,:],data[0][0,i,1,:],2500,100,10) \n",
    "#         fileName=str(100000+dataI)+'_'+str(100000+i)+'.png'\n",
    "#         cv2.imwrite('./tensorVisualizeFolder/'+fileName,tensorImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class relationNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    process objects to generate relation tensors\n",
    "    \"\"\"\n",
    "    def __init__(self,inputSize=4,outputSize=30,size1=10,size2=10,size3=10,size4=10):\n",
    "        super(relationNetwork,self).__init__()\n",
    "        self.size1=size1\n",
    "        self.size2=size2\n",
    "        self.size3=size3\n",
    "        self.size4=size4\n",
    "        self.layer1=nn.Linear(inputSize,size1)\n",
    "        self.layer2=nn.Linear(size1,size2)\n",
    "        self.layer3=nn.Linear(size2,size3)\n",
    "        self.layer4=nn.Linear(size3,size4)\n",
    "        self.layer5=nn.Linear(size4,outputSize)\n",
    "        self.ReLU=nn.ReLU()\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x1=self.ReLU(self.layer1(inputs))\n",
    "        x2=self.ReLU(self.layer2(x1))\n",
    "        x3=self.ReLU(self.layer3(x2))\n",
    "        x4=self.ReLU(self.layer4(x3))\n",
    "        outputs=self.ReLU(self.layer5(x4))\n",
    "        return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class effectNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    process relationTensor to generate effect tensors\n",
    "    \"\"\"\n",
    "    def __init__(self,inputSize=4,outputSize=30,size1=10,size2=10,size3=10,size4=10):\n",
    "        super(effectNetwork,self).__init__()\n",
    "        self.size1=size1\n",
    "        self.size2=size2\n",
    "        self.size3=size3\n",
    "        self.size4=size4\n",
    "        self.layer1=nn.Linear(inputSize,size1)\n",
    "        self.layer2=nn.Linear(size1,size2)\n",
    "        self.layer3=nn.Linear(size2,size3)\n",
    "        self.layer4=nn.Linear(size3,size4)\n",
    "        self.layer5=nn.Linear(size4,outputSize)\n",
    "        self.ReLU=nn.ReLU()\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x1=self.ReLU(self.layer1(inputs))\n",
    "        x2=self.ReLU(self.layer2(x1))\n",
    "        x3=self.ReLU(self.layer3(x2))\n",
    "        x4=self.ReLU(self.layer4(x3))\n",
    "        outputs=self.ReLU(self.layer5(x4))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class effectCombinationNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    process effect tensor to generate combined effect tensors\n",
    "    \"\"\"\n",
    "    def __init__(self,inputSize=4,outputSize=30,size1=10,size2=10,size3=10,size4=10):\n",
    "        super(effectCombinationNetwork,self).__init__()\n",
    "        self.size1=size1\n",
    "        self.size2=size2\n",
    "        self.size3=size3\n",
    "        self.size4=size4\n",
    "        self.layer1=nn.Linear(inputSize,size1)\n",
    "        self.layer2=nn.Linear(size1,size2)\n",
    "        self.layer3=nn.Linear(size2,size3)\n",
    "        self.layer4=nn.Linear(size3,size4)\n",
    "        self.layer5=nn.Linear(size4,outputSize)\n",
    "        self.ReLU=nn.ReLU()\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x1=self.ReLU(self.layer1(inputs))\n",
    "        x2=self.ReLU(self.layer2(x1))\n",
    "        x3=self.ReLU(self.layer3(x2))\n",
    "        x4=self.ReLU(self.layer4(x3))\n",
    "        outputs=self.ReLU(self.layer5(x4))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class objectModifyNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    modify object with effect tensors\n",
    "    \"\"\"\n",
    "    def __init__(self,inputSize=4,outputSize=30,size1=10,size2=10,size3=10,size4=10):\n",
    "        super(objectModifyNetwork,self).__init__()\n",
    "        self.size1=size1\n",
    "        self.size2=size2\n",
    "        self.size3=size3\n",
    "        self.size4=size4\n",
    "        self.layer1=nn.Linear(inputSize,size1)\n",
    "        self.layer2=nn.Linear(size1,size2)\n",
    "        self.layer3=nn.Linear(size2,size3)\n",
    "        self.layer4=nn.Linear(size3,size4)\n",
    "        self.layer5=nn.Linear(size4,outputSize)\n",
    "        self.ReLU=nn.ReLU()\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x1=self.ReLU(self.layer1(inputs))\n",
    "        x2=self.ReLU(self.layer2(x1))\n",
    "        x3=self.ReLU(self.layer3(x2))\n",
    "        x4=self.ReLU(self.layer4(x3))\n",
    "        outputs=self.layer5(x4)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hiddenStateToEffectNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    process effect tensor to generate combined effect tensors\n",
    "    \"\"\"\n",
    "    def __init__(self,inputSize=4,outputSize=30,size1=10,size2=10,size3=10,size4=10):\n",
    "        super(effectCombinationNetwork,self).__init__()\n",
    "        self.size1=size1\n",
    "        self.size2=size2\n",
    "        self.size3=size3\n",
    "        self.size4=size4\n",
    "        self.layer1=nn.Linear(inputSize,size1)\n",
    "        self.layer2=nn.Linear(size1,size2)\n",
    "        self.layer3=nn.Linear(size2,size3)\n",
    "        self.layer4=nn.Linear(size3,size4)\n",
    "        self.layer5=nn.Linear(size4,outputSize)\n",
    "        self.ReLU=nn.ReLU()\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x1=self.ReLU(self.layer1(inputs))\n",
    "        x2=self.ReLU(self.layer2(x1))\n",
    "        x3=self.ReLU(self.layer3(x2))\n",
    "        x4=self.ReLU(self.layer4(x3))\n",
    "        outputs=self.ReLU(self.layer5(x4))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#this block build for relation network testing\n",
    "#delete later if needed\n",
    "relationTensorSize=40\n",
    "positionTuple=(0,1,6,7)\n",
    "velocityTuple=(2,3,8,9)\n",
    "acclerateTuple=(4,5,10,11)\n",
    "positionRelationNet=relationNetwork(outputSize=relationTensorSize)\n",
    "velocityRelationNet=relationNetwork(outputSize=relationTensorSize)\n",
    "accelerateRelationNet=relationNetwork(outputSize=relationTensorSize)\n",
    "\n",
    "maxMatrixIndex=250\n",
    "\n",
    "#load test data in network testing block\n",
    "dataloaderV2=DataLoader(datasetV2,batch_size=1,shuffle=True)\n",
    "for i,item in enumerate(dataloaderV2):\n",
    "    if(i>0):\n",
    "        break\n",
    "    print(i)\n",
    "    first,second=item\n",
    "#     print(first.shape,second.shape)\n",
    "#     print(first[0,:5,:6])\n",
    "#     print(first[0,(2,245,246,247,248,249,250,251),6:])\n",
    "    #from frame to position, velocity, accelerate\n",
    "    positionRelationTensors=positionRelationNet(first[:,:,positionTuple])\n",
    "    velocityRelationTensors=velocityRelationNet(first[:,:,velocityTuple])\n",
    "    accelerateRelationTensors=accelerateRelationNet(first[:,:,acclerateTuple])\n",
    "    print(positionRelationTensors.shape)\n",
    "    objectsAndRelationTensors=torch.cat((first[:,:,positionTuple],positionRelationTensors),2)\n",
    "    print(objectsAndRelationTensors.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "objectAndTensorSize=relationTensorSize+4 \n",
    "effectOutputTensorSize=20\n",
    "#the number 4 is is the size of positon(or velocity or accelerate) pairs,\n",
    "#such as (positonxObject1,positonyObject1,positionxObject2,positionyObject2)\n",
    "positionEffectNet=effectNetwork(inputSize=objectAndTensorSize,outputSize=effectOutputTensorSize)\n",
    "velocityEffectNet=effectNetwork(inputSize=objectAndTensorSize,outputSize=effectOutputTensorSize)\n",
    "accelerateEffectNet=effectNetwork(inputSize=objectAndTensorSize,outputSize=effectOutputTensorSize)\n",
    "first,second=next(iter(dataloaderV2))\n",
    "print(first.shape)\n",
    "\n",
    "#relation computation\n",
    "positionRelationTensors=positionRelationNet(first[:,:,positionTuple])\n",
    "velocityRelationTensors=velocityRelationNet(first[:,:,velocityTuple])\n",
    "accelerateRelationTensors=accelerateRelationNet(first[:,:,acclerateTuple])\n",
    "                                                      \n",
    "objectsAndPositionRelationTensors=torch.cat((first[:,:,positionTuple],positionRelationTensors),2)\n",
    "objectsAndVelocityRelationTensors=torch.cat((first[:,:,positionTuple],velocityRelationTensors),2)\n",
    "objectsAndAccelerateRelationTensors=torch.cat((first[:,:,positionTuple],accelerateRelationTensors),2)\n",
    "\n",
    "#effect computation\n",
    "positionEffectTensors=positionEffectNet(objectsAndPositionRelationTensors)\n",
    "velocityEffectTensors=velocityEffectNet(objectsAndVelocityRelationTensors)\n",
    "accelerateEffectTensors=accelerateEffectNet(objectsAndAccelerateRelationTensors)\n",
    "\n",
    "#effect combination type 1\n",
    "#tensor summation\n",
    "batchSize=positionRelationTensors.shape[0]\n",
    "positionEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "velocityEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "accelerateEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "for i in range(maxMatrixIndex):\n",
    "    positionEffectSummation[:,i,:]=torch.sum(positionEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "    velocityEffectSummation[:,i,:]=torch.sum(velocityEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "    accelerateEffectSummation[:,i,:]=torch.sum(accelerateEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "    \n",
    "#effect combination net initial\n",
    "#combined tensors length\n",
    "combinedTensorSize=20\n",
    "effectCombinationNet=effectCombinationNetwork(inputSize=effectOutputTensorSize*3,outputSize=combinedTensorSize)\n",
    "\n",
    "#combine tensors and process the combined one\n",
    "combinedEffectTensors=torch.cat((positionEffectSummation,velocityEffectSummation,accelerateEffectSummation),2)\n",
    "print(combinedEffectTensors.shape)\n",
    "processedCombinedEffectTensors=effectCombinationNet(combinedEffectTensors)\n",
    "print(processedCombinedEffectTensors.shape)\n",
    "\n",
    "#generate a tuple in which each element is the index of a vehicle\n",
    "#the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "#this part has been put into init function of Module class\n",
    "listForEachVehicle=[]\n",
    "for i in range(maxMatrixIndex):\n",
    "    listForEachVehicle.append(i*(maxMatrixIndex-1))\n",
    "tupleForEachVehicle=tuple(listForEachVehicle)\n",
    "\n",
    "#the property of each vehicle\n",
    "vehicleProperty=first[:,tupleForEachVehicle,0:6]\n",
    "\n",
    "objectAndFinalEffect=torch.cat((vehicleProperty,processedCombinedEffectTensors),2)\n",
    "print(objectAndFinalEffect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#initialize the final network to generate new objects properties\n",
    "objectModifyNet=objectModifyNetwork(inputSize=combinedTensorSize+6,outputSize=6)\n",
    "finalObjectState=objectModifyNet(objectAndFinalEffect)\n",
    "print(finalObjectState.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from relation to new object network\n",
    "class fromRelationToObjectNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fromRelationToObjectNetwork,self).__init__()\n",
    "        self.maxMatrixIndex=250\n",
    "        #generate a tuple in which each element is the index of a vehicle\n",
    "        #the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "        listForEachVehicle=[]\n",
    "        for i in range(self.maxMatrixIndex):\n",
    "            listForEachVehicle.append(i*(self.maxMatrixIndex-1))\n",
    "        self.tupleForEachVehicle=tuple(listForEachVehicle)\n",
    "        \n",
    "        #position relation network initialize\n",
    "        self.relationTensorSize=40\n",
    "        self.positionTuple=(0,1,6,7)\n",
    "        self.velocityTuple=(2,3,8,9)\n",
    "        self.acclerateTuple=(4,5,10,11)\n",
    "        self.positionRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "        self.velocityRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "        self.accelerateRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "        \n",
    "        #effect network initialize\n",
    "        self.objectAndTensorSize=self.relationTensorSize+4 \n",
    "        self.effectOutputTensorSize=20\n",
    "        #the number 4 is is the size of positon(or velocity or accelerate) pairs,\n",
    "        #such as (positonxObject1,positonyObject1,positionxObject2,positionyObject2)\n",
    "        self.positionEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "        self.velocityEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "        self.accelerateEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "        \n",
    "        #effect combination net initialize\n",
    "        #combined tensors length\n",
    "        self.combinedTensorSize=20\n",
    "        self.effectCombinationNet=\\\n",
    "        effectCombinationNetwork(inputSize=self.effectOutputTensorSize*3,outputSize=self.combinedTensorSize)\n",
    "        \n",
    "        #initialize the final network to generate new objects properties\n",
    "        self.objectModifyNet=objectModifyNetwork(inputSize=self.combinedTensorSize+6,outputSize=6)\n",
    "        \n",
    "    def forward(self,inputObjectsPairs):\n",
    "        #relation computation\n",
    "        positionRelationTensors=self.positionRelationNet(inputObjectsPairs[:,:,self.positionTuple])\n",
    "        velocityRelationTensors=self.velocityRelationNet(inputObjectsPairs[:,:,self.velocityTuple])\n",
    "        accelerateRelationTensors=self.accelerateRelationNet(inputObjectsPairs[:,:,self.acclerateTuple])\n",
    "\n",
    "        objectsAndPositionRelationTensors=torch.cat((inputObjectsPairs[:,:,self.positionTuple],positionRelationTensors),2)\n",
    "        objectsAndVelocityRelationTensors=torch.cat((inputObjectsPairs[:,:,self.velocityTuple],velocityRelationTensors),2)\n",
    "        objectsAndAccelerateRelationTensors=torch.cat((inputObjectsPairs[:,:,self.acclerateTuple],accelerateRelationTensors),2)\n",
    "\n",
    "        #effect computation\n",
    "        positionEffectTensors=self.positionEffectNet(objectsAndPositionRelationTensors)\n",
    "        velocityEffectTensors=self.velocityEffectNet(objectsAndVelocityRelationTensors)\n",
    "        accelerateEffectTensors=self.accelerateEffectNet(objectsAndAccelerateRelationTensors)\n",
    "\n",
    "        \n",
    "        #effect combination type 1\n",
    "        #tensor summation\n",
    "        batchSize=positionRelationTensors.shape[0]\n",
    "        if useGpu==True:\n",
    "            positionEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "            velocityEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "            accelerateEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "        else: \n",
    "            positionEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "            velocityEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "            accelerateEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "        for i in range(maxMatrixIndex):\n",
    "            positionEffectSummation[:,i,:]=torch.sum(positionEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "            velocityEffectSummation[:,i,:]=torch.sum(velocityEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "            accelerateEffectSummation[:,i,:]=torch.sum(accelerateEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "        combinedEffectTensors=torch.cat((positionEffectSummation,velocityEffectSummation,accelerateEffectSummation),2)\n",
    "        processedCombinedEffectTensors=self.effectCombinationNet(combinedEffectTensors)\n",
    "        \n",
    "        #the property of each vehicle\n",
    "        vehicleProperty=inputObjectsPairs[:,self.tupleForEachVehicle,0:6]\n",
    "        objectAndFinalEffect=torch.cat((vehicleProperty,processedCombinedEffectTensors),2)\n",
    "        \n",
    "        #compute final state\n",
    "        finalObjectState=self.objectModifyNet(objectAndFinalEffect)\n",
    "        return finalObjectState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This module is supposed to be placed in LSTM model\n",
    "class fromRelationToEffectNetwork(nn.Module):\n",
    "    def __init__(self,effectOutputTensorSize=20):\n",
    "        super(fromRelationToEffectNetwork,self).__init__()\n",
    "        self.maxMatrixIndex=250\n",
    "        #generate a tuple in which each element is the index of a vehicle\n",
    "        #the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "        listForEachVehicle=[]\n",
    "        for i in range(self.maxMatrixIndex):\n",
    "            listForEachVehicle.append(i*(self.maxMatrixIndex-1))\n",
    "        self.tupleForEachVehicle=tuple(listForEachVehicle)\n",
    "        \n",
    "        #position relation network initialize\n",
    "        self.relationTensorSize=40\n",
    "        self.positionTuple=(0,1,6,7)\n",
    "        self.velocityTuple=(2,3,8,9)\n",
    "        self.acclerateTuple=(4,5,10,11)\n",
    "        self.positionRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "        self.velocityRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "        self.accelerateRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "        \n",
    "        #effect network initialize\n",
    "        self.objectAndTensorSize=self.relationTensorSize+4 \n",
    "        self.effectOutputTensorSize=effectOutputTensorSize\n",
    "        #the number 4 is the size of positon(or velocity or accelerate) pairs,\n",
    "        #such as (positonxObject1,positonyObject1,positionxObject2,positionyObject2)\n",
    "        self.positionEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "        self.velocityEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "        self.accelerateEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "        \n",
    "        #effect combination net initialize\n",
    "        #combined tensors length\n",
    "        self.combinedTensorSize=20\n",
    "        self.effectCombinationNet=\\\n",
    "        effectCombinationNetwork(inputSize=self.effectOutputTensorSize*3,outputSize=self.combinedTensorSize)\n",
    "        \n",
    "        #remove objectModifyNet in objectToEffectModel\n",
    "        #initialize the final network to generate new objects properties\n",
    "#         self.objectModifyNet=objectModifyNetwork(inputSize=self.combinedTensorSize+6,outputSize=6)\n",
    "        \n",
    "    def forward(self,inputObjectsPairs):\n",
    "        #relation computation\n",
    "        effectOutputTensorSize=self.effectOutputTensorSize\n",
    "        positionRelationTensors=self.positionRelationNet(inputObjectsPairs[:,:,self.positionTuple])\n",
    "        velocityRelationTensors=self.velocityRelationNet(inputObjectsPairs[:,:,self.velocityTuple])\n",
    "        accelerateRelationTensors=self.accelerateRelationNet(inputObjectsPairs[:,:,self.acclerateTuple])\n",
    "\n",
    "        objectsAndPositionRelationTensors=torch.cat((inputObjectsPairs[:,:,self.positionTuple],positionRelationTensors),2)\n",
    "        objectsAndVelocityRelationTensors=torch.cat((inputObjectsPairs[:,:,self.velocityTuple],velocityRelationTensors),2)\n",
    "        objectsAndAccelerateRelationTensors=torch.cat((inputObjectsPairs[:,:,self.acclerateTuple],accelerateRelationTensors),2)\n",
    "\n",
    "        #effect computation\n",
    "        positionEffectTensors=self.positionEffectNet(objectsAndPositionRelationTensors)\n",
    "        velocityEffectTensors=self.velocityEffectNet(objectsAndVelocityRelationTensors)\n",
    "        accelerateEffectTensors=self.accelerateEffectNet(objectsAndAccelerateRelationTensors)\n",
    "\n",
    "        \n",
    "        #effect combination type 1\n",
    "        #tensor summation\n",
    "        batchSize=positionRelationTensors.shape[0]\n",
    "        if useGpu==True:\n",
    "            positionEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "            velocityEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "            accelerateEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "        else: \n",
    "            positionEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "            velocityEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "            accelerateEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "        for i in range(maxMatrixIndex):\n",
    "            positionEffectSummation[:,i,:]=torch.sum(positionEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "            velocityEffectSummation[:,i,:]=torch.sum(velocityEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "            accelerateEffectSummation[:,i,:]=torch.sum(accelerateEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "        combinedEffectTensors=torch.cat((positionEffectSummation,velocityEffectSummation,accelerateEffectSummation),2)\n",
    "        processedCombinedEffectTensors=self.effectCombinationNet(combinedEffectTensors)\n",
    "        \n",
    "        #remove object extraction component and computation component\n",
    "#         #the property of each vehicle\n",
    "#         vehicleProperty=inputObjectsPairs[:,self.tupleForEachVehicle,0:6]\n",
    "#         objectAndFinalEffect=torch.cat((vehicleProperty,processedCombinedEffectTensors),2)\n",
    "        \n",
    "#         #compute final state\n",
    "#         finalObjectState=self.objectModifyNet(objectAndFinalEffect)\n",
    "        return processedCombinedEffectTensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This module is supposed to be placed in LSTM model\n",
    "class fromRelationToEffectNetworkPositionOnly(nn.Module):\n",
    "    def __init__(self,effectOutputTensorSize=20):\n",
    "        super(fromRelationToEffectNetwork,self).__init__()\n",
    "        self.maxMatrixIndex=250\n",
    "        #generate a tuple in which each element is the index of a vehicle\n",
    "        #the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "        listForEachVehicle=[]\n",
    "        for i in range(self.maxMatrixIndex):\n",
    "            listForEachVehicle.append(i*(self.maxMatrixIndex-1))\n",
    "        self.tupleForEachVehicle=tuple(listForEachVehicle)\n",
    "        \n",
    "        #position relation network initialize\n",
    "        self.relationTensorSize=40\n",
    "        self.positionTuple=(0,1,6,7)\n",
    "#         self.velocityTuple=(2,3,8,9)\n",
    "#         self.acclerateTuple=(4,5,10,11)\n",
    "        self.positionRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "#         self.velocityRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "#         self.accelerateRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "        \n",
    "        #effect network initialize\n",
    "        self.objectAndTensorSize=self.relationTensorSize+4 \n",
    "        self.effectOutputTensorSize=effectOutputTensorSize\n",
    "        #the number 4 is the size of positon(or velocity or accelerate) pairs,\n",
    "        #such as (positonxObject1,positonyObject1,positionxObject2,positionyObject2)\n",
    "        self.positionEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "#         self.velocityEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "#         self.accelerateEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "        \n",
    "        #effect combination net initialize\n",
    "        #combined tensors length\n",
    "#         self.combinedTensorSize=20\n",
    "#         self.effectCombinationNet=\\\n",
    "#         effectCombinationNetwork(inputSize=self.effectOutputTensorSize*3,outputSize=self.combinedTensorSize)\n",
    "        \n",
    "        #remove objectModifyNet in objectToEffectModel\n",
    "        #initialize the final network to generate new objects properties\n",
    "#         self.objectModifyNet=objectModifyNetwork(inputSize=self.combinedTensorSize+6,outputSize=6)\n",
    "        \n",
    "    def forward(self,inputObjectsPairs):\n",
    "        #relation computation\n",
    "        effectOutputTensorSize=self.effectOutputTensorSize\n",
    "        positionRelationTensors=self.positionRelationNet(inputObjectsPairs[:,:,self.positionTuple])\n",
    "#         velocityRelationTensors=self.velocityRelationNet(inputObjectsPairs[:,:,self.velocityTuple])\n",
    "#         accelerateRelationTensors=self.accelerateRelationNet(inputObjectsPairs[:,:,self.acclerateTuple])\n",
    "\n",
    "        objectsAndPositionRelationTensors=torch.cat((inputObjectsPairs[:,:,self.positionTuple],positionRelationTensors),2)\n",
    "#         objectsAndVelocityRelationTensors=torch.cat((inputObjectsPairs[:,:,self.velocityTuple],velocityRelationTensors),2)\n",
    "#         objectsAndAccelerateRelationTensors=torch.cat((inputObjectsPairs[:,:,self.acclerateTuple],accelerateRelationTensors),2)\n",
    "\n",
    "        #effect computation\n",
    "        positionEffectTensors=self.positionEffectNet(objectsAndPositionRelationTensors)\n",
    "#         velocityEffectTensors=self.velocityEffectNet(objectsAndVelocityRelationTensors)\n",
    "#         accelerateEffectTensors=self.accelerateEffectNet(objectsAndAccelerateRelationTensors)\n",
    "\n",
    "        \n",
    "        #effect combination type 1\n",
    "        #tensor summation\n",
    "        batchSize=positionRelationTensors.shape[0]\n",
    "        if useGpu==True:\n",
    "            positionEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "#             velocityEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "#             accelerateEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "        else: \n",
    "            positionEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "#             velocityEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "#             accelerateEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "        for i in range(maxMatrixIndex):\n",
    "            positionEffectSummation[:,i,:]=torch.sum(positionEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "#             velocityEffectSummation[:,i,:]=torch.sum(velocityEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "#             accelerateEffectSummation[:,i,:]=torch.sum(accelerateEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "#         combinedEffectTensors=torch.cat((positionEffectSummation,velocityEffectSummation,accelerateEffectSummation),2)\n",
    "#         processedCombinedEffectTensors=self.effectCombinationNet(combinedEffectTensors)\n",
    "        \n",
    "        #remove object extraction component and computation component\n",
    "#         #the property of each vehicle\n",
    "#         vehicleProperty=inputObjectsPairs[:,self.tupleForEachVehicle,0:6]\n",
    "#         objectAndFinalEffect=torch.cat((vehicleProperty,processedCombinedEffectTensors),2)\n",
    "        \n",
    "#         #compute final state\n",
    "#         finalObjectState=self.objectModifyNet(objectAndFinalEffect)\n",
    "        return positionEffectSummation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationLSTM(nn.Module):\n",
    "    def __init__(self, input_size=20, cell_size=20, hidden_size=20, output_last = True):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        the input of LSTM  structure was the output of 'fromRelationToEffectNet' module, so that \n",
    "        the effectOutputTensorSize has the same number as input_size. \n",
    "        \n",
    "        \"\"\"\n",
    "        super(RelationLSTM, self).__init__()\n",
    "        self.maxMatrixIndex=250\n",
    "        \n",
    "        #generate a tuple in which each element is the index of a vehicle\n",
    "        #the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "        listForEachVehicle=[]\n",
    "        for i in range(self.maxMatrixIndex):\n",
    "            listForEachVehicle.append(i*(self.maxMatrixIndex-1))\n",
    "        self.tupleForEachVehicle=tuple(listForEachVehicle)\n",
    "        self.positionTuple=(0,1,6,7)\n",
    "        self.velocityTuple=(2,3,8,9)\n",
    "        self.acclerateTuple=(4,5,10,11)\n",
    "        \n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.fromRelationToEffectNet=fromRelationToEffectNetwork(effectOutputTensorSize=input_size)\n",
    "        self.objectModifyNet=objectModifyNetwork(inputSize=hidden_size+6,outputSize=6)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, inputEffectTensor, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((inputEffectTensor, Hidden_State), 2)\n",
    "        print('in step,combined.shape',combined.shape)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            for i in range(time_step):\n",
    "                effects=self.fromRelationToEffectNet(inputs[:,i,:,:])\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(effects), Hidden_State, Cell_State) \n",
    "                #the property of each vehicle\n",
    "            print(inputs.shape)\n",
    "            vehicleProperty=inputs[:,-1,self.tupleForEachVehicle,0:6].squeeze()\n",
    "            objectAndFinalEffect=torch.cat((vehicleProperty,Hidden_State),2)\n",
    "            outputState=self.objectModifyNet(objectAndFinalEffect)\n",
    "            return outputState\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "#         use_gpu = torch.cuda.is_available()\n",
    "        if useGpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size,maxMatrixIndex, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size,maxMatrixIndex, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, maxMatrixIndex,self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, maxMatrixIndex,self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def fromObjectsToRelationPairs(combinedTensor):\n",
    "    '''\n",
    "    Args:\n",
    "        The input tensor should already be transposed if it is generated from the network's output\n",
    "    Returns:\n",
    "        Relation pairs\n",
    "    '''\n",
    "    #generate relation tensor for all vehicle pairs\n",
    "    relationTensorLeft=combinedTensor[:,0].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])\n",
    "    relationTensorRight=torch.transpose(torch.cat((combinedTensor[:,:0],combinedTensor[:,1:]),1),0,1)\n",
    "#         print(relationTensorRight.shape,relationTensorRight.shape)\n",
    "    for i in range(1,combinedTensor.shape[1]):\n",
    "        relationTensorLeft=torch.cat((relationTensorLeft,\\\n",
    "                                      combinedTensor[:,i].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])),0)\n",
    "        relationTensorRight=torch.cat((relationTensorRight,\\\n",
    "                                       torch.transpose(torch.cat((combinedTensor[:,:i],combinedTensor[:,i+1:]),1),0,1)),0)\n",
    "#         print(relationTensorLeft.shape,relationTensorRight.shape)\n",
    "    combinedRelationTensor=torch.cat((relationTensorLeft,relationTensorRight),1) \n",
    "    return combinedRelationTensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationLSTMSeq2Seq(nn.Module):\n",
    "    def __init__(self, input_size=20, cell_size=20, hidden_size=20, \\\n",
    "                 input_size_2=20, cell_size_2=20,hidden_size_2=20, outputTimeFrame=5,output_last = True):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        the input of LSTM  structure was the output of 'fromRelationToEffectNet' module, so that \n",
    "        the effectOutputTensorSize has the same number as input_size. \n",
    "        \n",
    "        \"\"\"\n",
    "        super(RelationLSTMSeq2Seq, self).__init__()\n",
    "        self.maxMatrixIndex=250\n",
    "        \n",
    "        #generate a tuple in which each element is the index of a vehicle\n",
    "        #the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "        listForEachVehicle=[]\n",
    "        for i in range(self.maxMatrixIndex):\n",
    "            listForEachVehicle.append(i*(self.maxMatrixIndex-1))\n",
    "        self.tupleForEachVehicle=tuple(listForEachVehicle)\n",
    "        self.positionTuple=(0,1,6,7)\n",
    "        self.velocityTuple=(2,3,8,9)\n",
    "        self.acclerateTuple=(4,5,10,11)\n",
    "        \n",
    "        #effect representive vector computation lstm\n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        #object modifying lstm\n",
    "        self.cell_size2 = cell_size_2\n",
    "        self.hidden_size2 = hidden_size_2\n",
    "        self.fl2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        self.il2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        self.ol2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        self.Cl2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        \n",
    "        self.outputTimeFrame=outputTimeFrame\n",
    "\n",
    "        self.fromRelationToEffectNet=fromRelationToEffectNetwork(effectOutputTensorSize=input_size)\n",
    "        self.objectModifyNet=objectModifyNetwork(inputSize=hidden_size+6,outputSize=6)\n",
    "        self.hiddenStateToEffectNetwork=hiddenStateToEffectNetwork(inputSize=hidden_size,outputSize=input_size)\n",
    "        #descreption for the statement above: the input_size applied to the parameter outputSize is \n",
    "        #the size of effect tensor in the init function. \n",
    "        \n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, inputEffectTensor, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((inputEffectTensor, Hidden_State), 2)\n",
    "#         print('in step,combined.shape',combined.shape)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def step2(self, inputPreEffectTensor, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((inputPreEffectTensor, Hidden_State), 2)\n",
    "#         print('in step2,combined.shape',combined.shape)\n",
    "        f = F.sigmoid(self.fl2(combined))\n",
    "        i = F.sigmoid(self.il2(combined))\n",
    "        o = F.sigmoid(self.ol2(combined))\n",
    "        C = F.tanh(self.Cl2(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State,Hidden_State_2,Cell_State_2 = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            #effect computation\n",
    "            for i in range(time_step):\n",
    "                effects=self.fromRelationToEffectNet(inputs[:,i,:,:])\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(effects), Hidden_State, Cell_State) \n",
    "                #the property of each vehicle\n",
    "                \n",
    "            Hidden_State_2=Hidden_State\n",
    "            Cell_State_2=Cell_State\n",
    "            \n",
    "            #the lstm process below take as inputs the previous object states and output the next predicted states\n",
    "            #applying function permute to deal with the dimension inconsistency\n",
    "            '''\n",
    "            inputs should be processed by function \"fromObjectsToRelationPairsBatchAndTimestepVersion\" \n",
    "            IF DATASETV3 VERSION IS USED TO GET DATA\n",
    "            '''\n",
    "            print('in seq2seq, inputs shape:',inputs.shape)\n",
    "            preVehicleProperty=inputs[:,-1,self.tupleForEachVehicle,0:6].squeeze()\n",
    "            preVehicleRelations=inputs[:,-1,:,:]\n",
    "            \n",
    "            #object properties computation\n",
    "            for i in range(outputTimeFrame):\n",
    "                objectAndFinalEffect=torch.cat((preVehicleProperty,Hidden_State_2),2)  \n",
    "                preVehicleProperty=self.objectModifyNet(objectAndFinalEffect)\n",
    "                effects=self.fromRelationToEffectNet(preVehicleRelations)\n",
    "                Hidden_State_2,Cell_State_2=self.step2(torch.squeeze(effects),Hidden_State_2,Cell_State_2)\n",
    "                if i==0:\n",
    "                    #add dimension timestep, which in dimension 1\n",
    "                    outputVehicleProperties=preVehicleProperty.unsqueeze(1) \n",
    "                else:\n",
    "                    outputVehicleProperties=torch.cat((outputVehicleProperties,preVehicleProperty.unsqueeze(1)),1)\n",
    "                #don't need to compute new effect vector after the prediction of the last time step\n",
    "                if i<outputTimeFrame-1:\n",
    "                    effectFromHiddenState=self.hiddenStateToEffectNetwork(Hidden_State_2)\n",
    "                    self.objectModifyNet()\n",
    "                    preVehicleProperty.cpu()\n",
    "                    #add timestep dimension for further process\n",
    "                    preVehiclePropertyAddTimestep=preVehicleProperty.unsqueeze(1)\n",
    "                    relationPairs=fromObjectsToRelationPairsBatchAndTimestepVersion(preVehiclePropertyAddTimestep).squeeze()\n",
    "                    if useGpu:\n",
    "                        relationPairs.cuda()\n",
    "                    effectInPropertiesComputation=self.fromRelationToEffectNet(relationPairs)\n",
    "                    Hidden_State_2,Cell_State_2=self.step2(effectInPropertiesComputation,Hidden_State_2,Cell_State_2)\n",
    "                if i==outputTimeFrame:\n",
    "                    break\n",
    "#             print(inputs.shape)\n",
    "#             vehicleProperty=inputs[:,-1,self.tupleForEachVehicle,0:6].squeeze()\n",
    "#             objectAndFinalEffect=torch.cat((vehicleProperty,Hidden_State),2)\n",
    "#             outputState=self.objectModifyNet(objectAndFinalEffect)\n",
    "            return outputVehicleProperties\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "#         use_gpu = torch.cuda.is_available()\n",
    "        if useGpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size,maxMatrixIndex, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size,maxMatrixIndex, self.hidden_size).cuda())\n",
    "            Hidden_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2).cuda())\n",
    "            Cell_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2).cuda())\n",
    "            return Hidden_State, Cell_State,Hidden_State_2,Cell_State_2\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, maxMatrixIndex,self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, maxMatrixIndex,self.hidden_size))\n",
    "            Hidden_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2))\n",
    "            Cell_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2))\n",
    "            return Hidden_State, Cell_State,Hidden_State_2,Cell_State_2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1c18aa71e301>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mRelationLSTMSeq2SeqPositionOnly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     def __init__(self, input_size=20, cell_size=20, hidden_size=20, \\\n\u001b[1;32m      3\u001b[0m                  input_size_2=20, cell_size_2=20,hidden_size_2=20, outputTimeFrame=5,output_last = True):\n\u001b[1;32m      4\u001b[0m         \"\"\"\n\u001b[1;32m      5\u001b[0m         \u001b[0mcell_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msize\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class RelationLSTMSeq2SeqPositionOnly(nn.Module):\n",
    "    def __init__(self, input_size=20, cell_size=20, hidden_size=20, \\\n",
    "                 input_size_2=20, cell_size_2=20,hidden_size_2=20, outputTimeFrame=5,output_last = True):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        the input of LSTM  structure was the output of 'fromRelationToEffectNet' module, so that \n",
    "        the effectOutputTensorSize has the same number as input_size. \n",
    "        \n",
    "        \"\"\"\n",
    "        super(RelationLSTMSeq2Seq, self).__init__()\n",
    "        self.maxMatrixIndex=250\n",
    "        \n",
    "        #generate a tuple in which each element is the index of a vehicle\n",
    "        #the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "        listForEachVehicle=[]\n",
    "        for i in range(self.maxMatrixIndex):\n",
    "            listForEachVehicle.append(i*(self.maxMatrixIndex-1))\n",
    "        self.tupleForEachVehicle=tuple(listForEachVehicle)\n",
    "        self.positionTuple=(0,1,6,7)\n",
    "#         self.velocityTuple=(2,3,8,9)\n",
    "#         self.acclerateTuple=(4,5,10,11)\n",
    "        \n",
    "        #effect representive vector computation lstm\n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        #object modifying lstm\n",
    "        self.cell_size2 = cell_size_2\n",
    "        self.hidden_size2 = hidden_size_2\n",
    "        self.fl2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        self.il2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        self.ol2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        self.Cl2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        \n",
    "        self.outputTimeFrame=outputTimeFrame\n",
    "\n",
    "        self.fromRelationToEffectNet=fromRelationToEffectNetworkPositionOnly(effectOutputTensorSize=input_size)\n",
    "        self.objectModifyNet=objectModifyNetwork(inputSize=input_size+6,outputSize=6)\n",
    "        self.hiddenStateToEffectNetwork=hiddenStateToEffectNetwork(inputSize=hidden_size,outputSize=input_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, inputEffectTensor, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((inputEffectTensor, Hidden_State), 2)\n",
    "#         print('in step,combined.shape',combined.shape)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def step2(self, inputPreEffectTensor, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((inputPreEffectTensor, Hidden_State), 2)\n",
    "#         print('in step2,combined.shape',combined.shape)\n",
    "        f = F.sigmoid(self.fl2(combined))\n",
    "        i = F.sigmoid(self.il2(combined))\n",
    "        o = F.sigmoid(self.ol2(combined))\n",
    "        C = F.tanh(self.Cl2(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State,Hidden_State_2,Cell_State_2 = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            #effect computation\n",
    "            for i in range(time_step):\n",
    "                effects=self.fromRelationToEffectNet(inputs[:,i,:,:])\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(effects), Hidden_State, Cell_State) \n",
    "                #the property of each vehicle\n",
    "                \n",
    "            Hidden_State_2=Hidden_State\n",
    "            Cell_State_2=Cell_State\n",
    "            \n",
    "            #the lstm process below take as inputs the previous object states and output the next predicted states\n",
    "            #applying function permute to deal with the dimension inconsistency\n",
    "            '''\n",
    "            inputs should be processed by function \"fromObjectsToRelationPairsBatchAndTimestepVersion\" \n",
    "            IF DATASETV3 VERSION IS USED TO GET DATA\n",
    "            '''\n",
    "            print('in seq2seq, inputs shape:',inputs.shape)\n",
    "            preVehicleProperty=inputs[:,-1,self.tupleForEachVehicle,0:6].squeeze()\n",
    "            preRelations=inputs[:,-1,:,:]\n",
    "            #object properties computation\n",
    "            for i in range(outputTimeFrame):\n",
    "                #objectAndFinalEffect=torch.cat((preVehicleProperty,Hidden_State_2),2)  #??????????\n",
    "                #WRONG!!!!The final hidden state of the first lstm model is not a effect tensor!!\n",
    "                #The hidden state of the first lstm represents somehow the encode hidden state in translation network,\n",
    "                #and obviously, the hidden state of encode component in translation network \n",
    "                #does not contain the result of translation. We could get the result from the output of\n",
    "                #the decode part of the translation network\n",
    "                #the shape of input tensor to the function fromRelationToEffectNet is (batch, vehicles, properties)\n",
    "                preEffect=self.fromRelationToEffectNet(preRelations)#the effect produced by this function is already a combined effect\n",
    "                Hidden_State_2,Cell_State_2=self.step2(preRelations,Hidden_State_2,Cell_State_2)\n",
    "                effectFromHiddenState=self.hiddenStateToEffectNetwork(Hidden_State_2)\n",
    "                objectAndEffectTensor=torch.cat((effectFromHiddenState,preVehicleProperty),2)\n",
    "                modifiedObject=self.objectModifyNet(objectAndEffectTensor)\n",
    "                newRelation=fromObjectsToRelationPairsBatchAndTimestepVersion(modifiedObject.unsqueeze(1).permute(0,1,3,2))\n",
    "                preRelations=newRelation.squeeze()\n",
    "                if i==0:\n",
    "                    #add dimension timestep, which in dimension 1\n",
    "                    outputVehicleProperties=modifiedObject.unsqueeze(1) \n",
    "                else:\n",
    "                    outputVehicleProperties=torch.cat((outputVehicleProperties,modifiedObject.unsqueeze(1)),1)\n",
    "                #doesn't need to compute new effect vector after the prediction of the last time step\n",
    "                if i==outputTimeFrame:\n",
    "                    break\n",
    "#             print(inputs.shape)\n",
    "#             vehicleProperty=inputs[:,-1,self.tupleForEachVehicle,0:6].squeeze()\n",
    "#             objectAndFinalEffect=torch.cat((vehicleProperty,Hidden_State),2)\n",
    "#             outputState=self.objectModifyNet(objectAndFinalEffect)\n",
    "            return outputVehicleProperties\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "#         use_gpu = torch.cuda.is_available()\n",
    "        if useGpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size,maxMatrixIndex, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size,maxMatrixIndex, self.hidden_size).cuda())\n",
    "            Hidden_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2).cuda())\n",
    "            Cell_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2).cuda())\n",
    "            return Hidden_State, Cell_State,Hidden_State_2,Cell_State_2\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, maxMatrixIndex,self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, maxMatrixIndex,self.hidden_size))\n",
    "            Hidden_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2))\n",
    "            Cell_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2))\n",
    "            return Hidden_State, Cell_State,Hidden_State_2,Cell_State_2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fromRelationToEffectNetworkWithDiscountParameter(nn.Module):\n",
    "    '''\n",
    "    A new network for producing effect from relation with a discount parameter tensor \n",
    "    the dimension of the input relation tensor is (batches, timesteps, properties)\n",
    "    '''\n",
    "    def __init__(self,effectOutputTensorSize=20, maxRelationNumber=20,maxMatrixIndex=250):\n",
    "        super(fromRelationToEffectNetworkWithDiscountParameter,self).__init__()\n",
    "        self.maxMatrixIndex=maxMatrixIndex\n",
    "\n",
    "        \n",
    "        #position relation network initialize\n",
    "        self.relationTensorSize=40\n",
    "        self.positionTuple=(0,1,2,3)\n",
    "        self.positionRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "       \n",
    "        #effect network initialize\n",
    "        self.objectAndTensorSize=self.relationTensorSize+4 #NOTE HERE: does it neccessary to contain both the tow object positions in the effect tensor?\n",
    "        self.effectOutputTensorSize=effectOutputTensorSize\n",
    "        #the number 4 is the size of positon(or velocity or accelerate) pairs,\n",
    "        #such as (positonxObject1,positonyObject1,positionxObject2,positionyObject2)\n",
    "        self.positionEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "\n",
    "  \n",
    "    def forward(self,inputObjectsPairs,discountParameterTensor):\n",
    "        #relation computation\n",
    "        effectOutputTensorSize=self.effectOutputTensorSize\n",
    "        positionRelationTensors=self.positionRelationNet(inputObjectsPairs[:,:,self.positionTuple])\n",
    "        objectsAndPositionRelationTensors=torch.cat((inputObjectsPairs[:,:,self.positionTuple],positionRelationTensors),2)\n",
    "        #effect computation\n",
    "        positionEffectTensors=self.positionEffectNet(objectsAndPositionRelationTensors)\n",
    "        #effect combination with discount parameter\n",
    "        #tensor summation\n",
    "        batchSize=positionRelationTensors.shape[0]\n",
    "        #apply discount parameters of distance to effectTensors\n",
    "        positionEffectTensors=torch.mul(positionEffectTensors,discountParameterTensor)\n",
    "        if useGpu==True:\n",
    "            positionEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "        else: \n",
    "            positionEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "        for i in range(maxMatrixIndex):\n",
    "            positionEffectSummation[:,i,:]=torch.sum(positionEffectTensors[:,(i*self.maxRelationNumber):((i+1)*self.maxRelationNumber),:],1)\n",
    "        \n",
    "        #remove object extraction component and computation component\n",
    "#         #the property of each vehicle\n",
    "#         vehicleProperty=inputObjectsPairs[:,self.tupleForEachVehicle,0:6]\n",
    "#         objectAndFinalEffect=torch.cat((vehicleProperty,processedCombinedEffectTensors),2)\n",
    "        \n",
    "#         #compute final state\n",
    "#         finalObjectState=self.objectModifyNet(objectAndFinalEffect)\n",
    "        return processedCombinedEffectTensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class differenceLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=20, cell_size=20, hidden_size=20, \\\n",
    "                 input_size_2=20, cell_size_2=20,hidden_size_2=20, outputTimeFrame=5,output_last = True,\\\n",
    "                maxRelationNUmber=20):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        the input of LSTM  structure was the output of 'fromRelationToEffectNet' module, so that \n",
    "        the effectOutputTensorSize has the same number as input_size. \n",
    "        \n",
    "        \"\"\"\n",
    "        super(differenceLSTMModel, self).__init__()\n",
    "        self.maxMatrixIndex=250\n",
    "        \n",
    "        #generate a tuple in which each element is the index of a vehicle\n",
    "        #the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "        listForEachVehicle=[]\n",
    "        for i in range(self.maxMatrixIndex):\n",
    "            listForEachVehicle.append(i*(self.maxMatrixIndex-1))\n",
    "        self.tupleForEachVehicle=tuple(listForEachVehicle)\n",
    "        self.positionTuple=(0,1,6,7)\n",
    "#         self.velocityTuple=(2,3,8,9)\n",
    "#         self.acclerateTuple=(4,5,10,11)\n",
    "        \n",
    "        #effect representive vector computation lstm\n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        #object modifying lstm\n",
    "        self.cell_size2 = cell_size_2\n",
    "        self.hidden_size2 = hidden_size_2\n",
    "        self.fl2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        self.il2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        self.ol2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        self.Cl2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        \n",
    "        self.outputTimeFrame=outputTimeFrame\n",
    "\n",
    "        self.fromRelationToEffectNet=fromRelationToEffectNetworkPositionOnly(effectOutputTensorSize=input_size)\n",
    "        self.objectModifyNet=objectModifyNetwork(inputSize=hidden_size+6,outputSize=6)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, inputEffectTensor, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((inputEffectTensor, Hidden_State), 2)\n",
    "#         print('in step,combined.shape',combined.shape)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def step2(self, inputPreEffectTensor, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((inputPreEffectTensor, Hidden_State), 2)\n",
    "#         print('in step2,combined.shape',combined.shape)\n",
    "        f = F.sigmoid(self.fl2(combined))\n",
    "        i = F.sigmoid(self.il2(combined))\n",
    "        o = F.sigmoid(self.ol2(combined))\n",
    "        C = F.tanh(self.Cl2(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs,discountParameterTensor,vehicleGraph):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State,Hidden_State_2,Cell_State_2 = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            #effect computation\n",
    "            for i in range(time_step):\n",
    "                effects=self.fromRelationToEffectNet(inputs[:,i,:,:])\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(effects), Hidden_State, Cell_State) \n",
    "                #the property of each vehicle\n",
    "                \n",
    "            Hidden_State_2=Hidden_State\n",
    "            Cell_State_2=Cell_State\n",
    "            \n",
    "            #the lstm process below take as inputs the previous object states and output the next predicted states\n",
    "            #applying function permute to deal with the dimension inconsistency\n",
    "            '''\n",
    "            inputs should be processed by function \"fromObjectsToRelationPairsBatchAndTimestepVersion\" \n",
    "            IF DATASETV3 VERSION IS USED TO GET DATA\n",
    "            '''\n",
    "            print('in seq2seq, inputs shape:',inputs.shape)\n",
    "            preVehicleProperty=inputs[:,-1,self.tupleForEachVehicle,0:6].squeeze()\n",
    "            \n",
    "            #object properties computation\n",
    "            for i in range(outputTimeFrame):\n",
    "                objectAndFinalEffect=torch.cat((preVehicleProperty,Hidden_State_2),2)  \n",
    "                preVehicleProperty=self.objectModifyNet(objectAndFinalEffect)\n",
    "                if i==0:\n",
    "                    #add dimension timestep, which in dimension 1\n",
    "                    outputVehicleProperties=preVehicleProperty.unsqueeze(1) \n",
    "                else:\n",
    "                    outputVehicleProperties=torch.cat((outputVehicleProperties,preVehicleProperty.unsqueeze(1)),1)\n",
    "                #don't need to compute new effect vector after the prediction of the last time step\n",
    "                if i<outputTimeFrame-1:\n",
    "                    preVehicleProperty.cpu()\n",
    "                    #add timestep dimension for further process\n",
    "                    preVehiclePropertyAddTimestep=preVehicleProperty.unsqueeze(1)\n",
    "                    relationPairs=fromObjectsToRelationPairsBatchAndTimestepVersion(preVehiclePropertyAddTimestep).squeeze()\n",
    "                    if useGpu:\n",
    "                        relationPairs.cuda()\n",
    "                    effectInPropertiesComputation=self.fromRelationToEffectNet(relationPairs)\n",
    "                    Hidden_State_2,Cell_State_2=self.step2(effectInPropertiesComputation,Hidden_State_2,Cell_State_2)\n",
    "                if i==outputTimeFrame:\n",
    "                    break\n",
    "#             print(inputs.shape)\n",
    "#             vehicleProperty=inputs[:,-1,self.tupleForEachVehicle,0:6].squeeze()\n",
    "#             objectAndFinalEffect=torch.cat((vehicleProperty,Hidden_State),2)\n",
    "#             outputState=self.objectModifyNet(objectAndFinalEffect)\n",
    "            return outputVehicleProperties\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "#         use_gpu = torch.cuda.is_available()\n",
    "        if useGpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size,maxMatrixIndex, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size,maxMatrixIndex, self.hidden_size).cuda())\n",
    "            Hidden_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2).cuda())\n",
    "            Cell_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2).cuda())\n",
    "            return Hidden_State, Cell_State,Hidden_State_2,Cell_State_2\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, maxMatrixIndex,self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, maxMatrixIndex,self.hidden_size))\n",
    "            Hidden_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2))\n",
    "            Cell_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2))\n",
    "            return Hidden_State, Cell_State,Hidden_State_2,Cell_State_2\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class elementWeightedLoss(nn.Module):\n",
    "    def __init__(self,lambdaDistance,lambdaVelocity,lambdaAccelerate):\n",
    "        super(elementWeightedLoss,self).__init__()\n",
    "        self.lambdaDistance,self.lambdaVelocity,self.lambdaAccelerate=\\\n",
    "        lambdaDistance,lambdaVelocity,lambdaAccelerate\n",
    "        \n",
    "    def forward(self,output,label):\n",
    "        '''\n",
    "        output and label dimension: [batch, timestep, vehiclenum, properties]\n",
    "        properties dimension:(distancex,distancey,velocityx,velocityy,acceleratex,acceleratey)\n",
    "        '''\n",
    "        distanceLoss=torch.mean(torch.pow(output[:,:,:,0:2]-label[:,:,:,0:2],2))\n",
    "        velocityLoss=torch.mean(torch.pow(output[:,:,:,2:4]-label[:,:,:,2:4],2))\n",
    "        accelerateLoss=torch.mean(torch.pow(output[:,:,:,4:6]-label[:,:,:,4:6],2))\n",
    "        return torch.mul(distanceLoss,self.lambdaDistance)+torch.mul(velocityLoss,self.lambdaVelocity)+\\\n",
    "                torch.mul(accelerateLoss,self.lambdaAccelerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST RELATION WITHIN A GIVEN RANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetV4Instance=tensorsDatasetV4(trajectoryFileList,lableTensorEachBatch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetV4Loader=DataLoader(datasetV4Instance,batch_size=5,num_workers=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-07 20:38:50,082 -179 - __getitem__ - DEBUG - allCombineTensorTrain.shape:torch.Size([10, 2, 250])\n",
      "2020-08-07 20:38:50,085 -180 - __getitem__ - DEBUG - allCombineTensorValid.shapetensor([[[0.2266, 0.5481, 0.2159,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0597, 0.0704, 0.0427,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2272, 0.5487, 0.2164,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0613, 0.0720, 0.0442,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2277, 0.5492, 0.2170,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0629, 0.0735, 0.0458,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2286, 0.5502, 0.2176,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0645, 0.0751, 0.0474,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2286, 0.5509, 0.2182,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0661, 0.0766, 0.0490,  ..., 0.0000, 0.0000, 0.0000]]])\n",
      "2020-08-07 20:38:50,085 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([10, 2, 250])\n",
      "2020-08-07 20:38:53,547 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-07 20:38:53,547 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-07 20:38:53,858 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0025, 0.0166, 1.0000, 2.0000, 1.0000],\n",
      "        [0.2205, 0.0431, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-07 20:38:57,310 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-07 20:38:57,310 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-07 20:38:57,627 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0034, 0.0167, 1.0000, 2.0000, 1.0000],\n",
      "        [0.2212, 0.0449, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-07 20:39:01,123 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-07 20:39:01,123 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-07 20:39:01,433 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0049, 0.0168, 1.0000, 2.0000, 1.0000],\n",
      "        [0.2224, 0.0467, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-07 20:39:04,905 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-07 20:39:04,905 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-07 20:39:05,214 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0058, 0.0169, 1.0000, 2.0000, 1.0000],\n",
      "        [0.2232, 0.0485, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-07 20:39:08,724 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-07 20:39:08,724 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-07 20:39:09,035 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0066, 0.0170, 1.0000, 2.0000, 1.0000],\n",
      "        [0.2236, 0.0501, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-07 20:39:12,550 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-07 20:39:12,550 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-07 20:39:12,870 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0069, 0.0170, 1.0000, 2.0000, 1.0000],\n",
      "        [0.2237, 0.0518, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-07 20:39:16,381 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-07 20:39:16,382 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-07 20:39:16,690 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0078, 0.0170, 1.0000, 2.0000, 1.0000],\n",
      "        [0.2243, 0.0533, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-07 20:39:20,250 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-07 20:39:20,250 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-07 20:39:20,565 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0086, 0.0170, 1.0000, 2.0000, 1.0000],\n",
      "        [0.2248, 0.0549, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-07 20:39:24,075 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-07 20:39:24,076 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-07 20:39:24,387 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0094, 0.0170, 1.0000, 2.0000, 1.0000],\n",
      "        [0.2254, 0.0565, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-07 20:39:27,933 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-07 20:39:27,933 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-07 20:39:28,275 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0102, 0.0170, 1.0000, 2.0000, 1.0000],\n",
      "        [0.2260, 0.0581, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-07 20:39:28,283 -15 - differenceBetweenTwoFrameForTimeSteps - DEBUG - tensor([[[0.5481, 0.0704],\n",
      "         [0.2159, 0.0427],\n",
      "         [0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.5487, 0.0720],\n",
      "         [0.2164, 0.0442],\n",
      "         [0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.5492, 0.0735],\n",
      "         [0.2170, 0.0458],\n",
      "         [0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.5502, 0.0751],\n",
      "         [0.2176, 0.0474],\n",
      "         [0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.5509, 0.0766],\n",
      "         [0.2182, 0.0490],\n",
      "         [0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-07 20:39:28,285 -16 - differenceBetweenTwoFrameForTimeSteps - DEBUG - tensor([[[0.2266, 0.0597],\n",
      "         [0.5481, 0.0704],\n",
      "         [0.2159, 0.0427],\n",
      "         ...,\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2272, 0.0613],\n",
      "         [0.5487, 0.0720],\n",
      "         [0.2164, 0.0442],\n",
      "         ...,\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2277, 0.0629],\n",
      "         [0.5492, 0.0735],\n",
      "         [0.2170, 0.0458],\n",
      "         ...,\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2286, 0.0645],\n",
      "         [0.5502, 0.0751],\n",
      "         [0.2176, 0.0474],\n",
      "         ...,\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2286, 0.0661],\n",
      "         [0.5509, 0.0766],\n",
      "         [0.2182, 0.0490],\n",
      "         ...,\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "2020-08-07 20:39:28,286 -17 - differenceBetweenTwoFrameForTimeSteps - DEBUG - tensor([[[0.2266, 0.0597],\n",
      "         [0.5481, 0.0704],\n",
      "         [0.2159, 0.0427],\n",
      "         ...,\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2272, 0.0613],\n",
      "         [0.5487, 0.0720],\n",
      "         [0.2164, 0.0442],\n",
      "         ...,\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2277, 0.0629],\n",
      "         [0.5492, 0.0735],\n",
      "         [0.2170, 0.0458],\n",
      "         ...,\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2286, 0.0645],\n",
      "         [0.5502, 0.0751],\n",
      "         [0.2176, 0.0474],\n",
      "         ...,\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2286, 0.0661],\n",
      "         [0.5509, 0.0766],\n",
      "         [0.2182, 0.0490],\n",
      "         ...,\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "2020-08-07 20:39:28,287 -187 - __getitem__ - DEBUG - differenceLabels.shape:torch.Size([5, 249, 2])\n"
     ]
    }
   ],
   "source": [
    "itemList=datasetV4Instance.__getitem__(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-07 17:06:32,781 -2 - <module> - DEBUG - torch.Size([10, 2, 250])\n",
      "2020-08-07 17:06:32,782 -2 - <module> - DEBUG - torch.Size([5, 2, 250])\n",
      "2020-08-07 17:06:32,783 -2 - <module> - DEBUG - torch.Size([10, 5000, 4])\n",
      "2020-08-07 17:06:32,783 -2 - <module> - DEBUG - torch.Size([10, 5000])\n",
      "2020-08-07 17:06:32,783 -2 - <module> - DEBUG - torch.Size([5, 249, 2])\n"
     ]
    }
   ],
   "source": [
    "for item in itemList:\n",
    "    logging.debug(fromAllToStr(item.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "combineTensorTrain,combineTensorValid,combinedRelationTensors,combinedDiscountParameterTensors,\\\n",
    "differenceLabels=itemList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-07 20:37:09,029 -1 - <module> - DEBUG - combnedRelationTensors.shapetorch.Size([10, 5000, 4])\n",
      "2020-08-07 20:37:09,032 -3 - <module> - DEBUG - combinedRelationTensor, batch 0:tensor([[0.1286, 0.9613, 0.1286, 0.9613],\n",
      "        [0.1286, 0.9613, 0.1561, 0.8884],\n",
      "        [0.1286, 0.9613, 0.0000, 0.0000],\n",
      "        [0.1286, 0.9613, 0.0000, 0.0000],\n",
      "        [0.1286, 0.9613, 0.0000, 0.0000],\n",
      "        [0.1286, 0.9613, 0.0000, 0.0000],\n",
      "        [0.1286, 0.9613, 0.0000, 0.0000],\n",
      "        [0.1286, 0.9613, 0.0000, 0.0000],\n",
      "        [0.1286, 0.9613, 0.0000, 0.0000],\n",
      "        [0.1286, 0.9613, 0.0000, 0.0000],\n",
      "        [0.1286, 0.9613, 0.0000, 0.0000],\n",
      "        [0.1286, 0.9613, 0.0000, 0.0000],\n",
      "        [0.1286, 0.9613, 0.0000, 0.0000],\n",
      "        [0.1286, 0.9613, 0.0000, 0.0000],\n",
      "        [0.1286, 0.9613, 0.0000, 0.0000],\n",
      "        [0.1286, 0.9613, 0.0000, 0.0000],\n",
      "        [0.1286, 0.9613, 0.0000, 0.0000],\n",
      "        [0.1286, 0.9613, 0.0000, 0.0000],\n",
      "        [0.1286, 0.9613, 0.0000, 0.0000],\n",
      "        [0.1286, 0.9613, 0.0000, 0.0000],\n",
      "        [0.4382, 0.9210, 0.4382, 0.9210],\n",
      "        [0.4382, 0.9210, 0.4246, 0.8744],\n",
      "        [0.4382, 0.9210, 0.0000, 0.0000],\n",
      "        [0.4382, 0.9210, 0.0000, 0.0000],\n",
      "        [0.4382, 0.9210, 0.0000, 0.0000],\n",
      "        [0.4382, 0.9210, 0.0000, 0.0000],\n",
      "        [0.4382, 0.9210, 0.0000, 0.0000],\n",
      "        [0.4382, 0.9210, 0.0000, 0.0000],\n",
      "        [0.4382, 0.9210, 0.0000, 0.0000],\n",
      "        [0.4382, 0.9210, 0.0000, 0.0000],\n",
      "        [0.4382, 0.9210, 0.0000, 0.0000],\n",
      "        [0.4382, 0.9210, 0.0000, 0.0000],\n",
      "        [0.4382, 0.9210, 0.0000, 0.0000],\n",
      "        [0.4382, 0.9210, 0.0000, 0.0000],\n",
      "        [0.4382, 0.9210, 0.0000, 0.0000],\n",
      "        [0.4382, 0.9210, 0.0000, 0.0000],\n",
      "        [0.4382, 0.9210, 0.0000, 0.0000],\n",
      "        [0.4382, 0.9210, 0.0000, 0.0000],\n",
      "        [0.4382, 0.9210, 0.0000, 0.0000],\n",
      "        [0.4382, 0.9210, 0.0000, 0.0000],\n",
      "        [0.5899, 0.8718, 0.5899, 0.8718],\n",
      "        [0.5899, 0.8718, 0.5731, 0.8164],\n",
      "        [0.5899, 0.8718, 0.5801, 0.7959],\n",
      "        [0.5899, 0.8718, 0.0000, 0.0000],\n",
      "        [0.5899, 0.8718, 0.0000, 0.0000],\n",
      "        [0.5899, 0.8718, 0.0000, 0.0000],\n",
      "        [0.5899, 0.8718, 0.0000, 0.0000],\n",
      "        [0.5899, 0.8718, 0.0000, 0.0000],\n",
      "        [0.5899, 0.8718, 0.0000, 0.0000],\n",
      "        [0.5899, 0.8718, 0.0000, 0.0000]])\n",
      "2020-08-07 20:37:09,035 -3 - <module> - DEBUG - combinedRelationTensor, batch 1:tensor([[0.1285, 0.9643, 0.1285, 0.9643],\n",
      "        [0.1285, 0.9643, 0.1533, 0.8911],\n",
      "        [0.1285, 0.9643, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9643, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9643, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9643, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9643, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9643, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9643, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9643, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9643, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9643, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9643, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9643, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9643, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9643, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9643, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9643, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9643, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9643, 0.0000, 0.0000],\n",
      "        [0.4385, 0.9239, 0.4385, 0.9239],\n",
      "        [0.4385, 0.9239, 0.4257, 0.8773],\n",
      "        [0.4385, 0.9239, 0.0000, 0.0000],\n",
      "        [0.4385, 0.9239, 0.0000, 0.0000],\n",
      "        [0.4385, 0.9239, 0.0000, 0.0000],\n",
      "        [0.4385, 0.9239, 0.0000, 0.0000],\n",
      "        [0.4385, 0.9239, 0.0000, 0.0000],\n",
      "        [0.4385, 0.9239, 0.0000, 0.0000],\n",
      "        [0.4385, 0.9239, 0.0000, 0.0000],\n",
      "        [0.4385, 0.9239, 0.0000, 0.0000],\n",
      "        [0.4385, 0.9239, 0.0000, 0.0000],\n",
      "        [0.4385, 0.9239, 0.0000, 0.0000],\n",
      "        [0.4385, 0.9239, 0.0000, 0.0000],\n",
      "        [0.4385, 0.9239, 0.0000, 0.0000],\n",
      "        [0.4385, 0.9239, 0.0000, 0.0000],\n",
      "        [0.4385, 0.9239, 0.0000, 0.0000],\n",
      "        [0.4385, 0.9239, 0.0000, 0.0000],\n",
      "        [0.4385, 0.9239, 0.0000, 0.0000],\n",
      "        [0.4385, 0.9239, 0.0000, 0.0000],\n",
      "        [0.4385, 0.9239, 0.0000, 0.0000],\n",
      "        [0.5882, 0.8740, 0.5882, 0.8740],\n",
      "        [0.5882, 0.8740, 0.5728, 0.8186],\n",
      "        [0.5882, 0.8740, 0.5804, 0.7980],\n",
      "        [0.5882, 0.8740, 0.0000, 0.0000],\n",
      "        [0.5882, 0.8740, 0.0000, 0.0000],\n",
      "        [0.5882, 0.8740, 0.0000, 0.0000],\n",
      "        [0.5882, 0.8740, 0.0000, 0.0000],\n",
      "        [0.5882, 0.8740, 0.0000, 0.0000],\n",
      "        [0.5882, 0.8740, 0.0000, 0.0000],\n",
      "        [0.5882, 0.8740, 0.0000, 0.0000]])\n",
      "2020-08-07 20:37:09,037 -3 - <module> - DEBUG - combinedRelationTensor, batch 2:tensor([[0.1285, 0.9673, 0.1285, 0.9673],\n",
      "        [0.1285, 0.9673, 0.1505, 0.8937],\n",
      "        [0.1285, 0.9673, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9673, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9673, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9673, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9673, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9673, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9673, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9673, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9673, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9673, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9673, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9673, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9673, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9673, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9673, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9673, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9673, 0.0000, 0.0000],\n",
      "        [0.1285, 0.9673, 0.0000, 0.0000],\n",
      "        [0.4377, 0.9269, 0.4377, 0.9269],\n",
      "        [0.4377, 0.9269, 0.4269, 0.8802],\n",
      "        [0.4377, 0.9269, 0.0000, 0.0000],\n",
      "        [0.4377, 0.9269, 0.0000, 0.0000],\n",
      "        [0.4377, 0.9269, 0.0000, 0.0000],\n",
      "        [0.4377, 0.9269, 0.0000, 0.0000],\n",
      "        [0.4377, 0.9269, 0.0000, 0.0000],\n",
      "        [0.4377, 0.9269, 0.0000, 0.0000],\n",
      "        [0.4377, 0.9269, 0.0000, 0.0000],\n",
      "        [0.4377, 0.9269, 0.0000, 0.0000],\n",
      "        [0.4377, 0.9269, 0.0000, 0.0000],\n",
      "        [0.4377, 0.9269, 0.0000, 0.0000],\n",
      "        [0.4377, 0.9269, 0.0000, 0.0000],\n",
      "        [0.4377, 0.9269, 0.0000, 0.0000],\n",
      "        [0.4377, 0.9269, 0.0000, 0.0000],\n",
      "        [0.4377, 0.9269, 0.0000, 0.0000],\n",
      "        [0.4377, 0.9269, 0.0000, 0.0000],\n",
      "        [0.4377, 0.9269, 0.0000, 0.0000],\n",
      "        [0.4377, 0.9269, 0.0000, 0.0000],\n",
      "        [0.4377, 0.9269, 0.0000, 0.0000],\n",
      "        [0.5873, 0.8762, 0.5873, 0.8762],\n",
      "        [0.5873, 0.8762, 0.5721, 0.8208],\n",
      "        [0.5873, 0.8762, 0.5807, 0.8000],\n",
      "        [0.5873, 0.8762, 0.0000, 0.0000],\n",
      "        [0.5873, 0.8762, 0.0000, 0.0000],\n",
      "        [0.5873, 0.8762, 0.0000, 0.0000],\n",
      "        [0.5873, 0.8762, 0.0000, 0.0000],\n",
      "        [0.5873, 0.8762, 0.0000, 0.0000],\n",
      "        [0.5873, 0.8762, 0.0000, 0.0000],\n",
      "        [0.5873, 0.8762, 0.0000, 0.0000]])\n",
      "2020-08-07 20:37:09,040 -3 - <module> - DEBUG - combinedRelationTensor, batch 3:tensor([[0.1284, 0.9702, 0.1284, 0.9702],\n",
      "        [0.1284, 0.9702, 0.1478, 0.8963],\n",
      "        [0.1284, 0.9702, 0.0000, 0.0000],\n",
      "        [0.1284, 0.9702, 0.0000, 0.0000],\n",
      "        [0.1284, 0.9702, 0.0000, 0.0000],\n",
      "        [0.1284, 0.9702, 0.0000, 0.0000],\n",
      "        [0.1284, 0.9702, 0.0000, 0.0000],\n",
      "        [0.1284, 0.9702, 0.0000, 0.0000],\n",
      "        [0.1284, 0.9702, 0.0000, 0.0000],\n",
      "        [0.1284, 0.9702, 0.0000, 0.0000],\n",
      "        [0.1284, 0.9702, 0.0000, 0.0000],\n",
      "        [0.1284, 0.9702, 0.0000, 0.0000],\n",
      "        [0.1284, 0.9702, 0.0000, 0.0000],\n",
      "        [0.1284, 0.9702, 0.0000, 0.0000],\n",
      "        [0.1284, 0.9702, 0.0000, 0.0000],\n",
      "        [0.1284, 0.9702, 0.0000, 0.0000],\n",
      "        [0.1284, 0.9702, 0.0000, 0.0000],\n",
      "        [0.1284, 0.9702, 0.0000, 0.0000],\n",
      "        [0.1284, 0.9702, 0.0000, 0.0000],\n",
      "        [0.1284, 0.9702, 0.0000, 0.0000],\n",
      "        [0.4365, 0.9299, 0.4365, 0.9299],\n",
      "        [0.4365, 0.9299, 0.4281, 0.8831],\n",
      "        [0.4365, 0.9299, 0.0000, 0.0000],\n",
      "        [0.4365, 0.9299, 0.0000, 0.0000],\n",
      "        [0.4365, 0.9299, 0.0000, 0.0000],\n",
      "        [0.4365, 0.9299, 0.0000, 0.0000],\n",
      "        [0.4365, 0.9299, 0.0000, 0.0000],\n",
      "        [0.4365, 0.9299, 0.0000, 0.0000],\n",
      "        [0.4365, 0.9299, 0.0000, 0.0000],\n",
      "        [0.4365, 0.9299, 0.0000, 0.0000],\n",
      "        [0.4365, 0.9299, 0.0000, 0.0000],\n",
      "        [0.4365, 0.9299, 0.0000, 0.0000],\n",
      "        [0.4365, 0.9299, 0.0000, 0.0000],\n",
      "        [0.4365, 0.9299, 0.0000, 0.0000],\n",
      "        [0.4365, 0.9299, 0.0000, 0.0000],\n",
      "        [0.4365, 0.9299, 0.0000, 0.0000],\n",
      "        [0.4365, 0.9299, 0.0000, 0.0000],\n",
      "        [0.4365, 0.9299, 0.0000, 0.0000],\n",
      "        [0.4365, 0.9299, 0.0000, 0.0000],\n",
      "        [0.4365, 0.9299, 0.0000, 0.0000],\n",
      "        [0.5880, 0.8785, 0.5880, 0.8785],\n",
      "        [0.5880, 0.8785, 0.5713, 0.8230],\n",
      "        [0.5880, 0.8785, 0.5810, 0.8021],\n",
      "        [0.5880, 0.8785, 0.0000, 0.0000],\n",
      "        [0.5880, 0.8785, 0.0000, 0.0000],\n",
      "        [0.5880, 0.8785, 0.0000, 0.0000],\n",
      "        [0.5880, 0.8785, 0.0000, 0.0000],\n",
      "        [0.5880, 0.8785, 0.0000, 0.0000],\n",
      "        [0.5880, 0.8785, 0.0000, 0.0000],\n",
      "        [0.5880, 0.8785, 0.0000, 0.0000]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-07 20:37:09,041 -3 - <module> - DEBUG - combinedRelationTensor, batch 4:tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4357, 0.9328, 0.4357, 0.9328],\n",
      "        [0.4357, 0.9328, 0.4293, 0.8860],\n",
      "        [0.4357, 0.9328, 0.0000, 0.0000],\n",
      "        [0.4357, 0.9328, 0.0000, 0.0000],\n",
      "        [0.4357, 0.9328, 0.0000, 0.0000],\n",
      "        [0.4357, 0.9328, 0.0000, 0.0000],\n",
      "        [0.4357, 0.9328, 0.0000, 0.0000],\n",
      "        [0.4357, 0.9328, 0.0000, 0.0000],\n",
      "        [0.4357, 0.9328, 0.0000, 0.0000],\n",
      "        [0.4357, 0.9328, 0.0000, 0.0000],\n",
      "        [0.4357, 0.9328, 0.0000, 0.0000],\n",
      "        [0.4357, 0.9328, 0.0000, 0.0000],\n",
      "        [0.4357, 0.9328, 0.0000, 0.0000],\n",
      "        [0.4357, 0.9328, 0.0000, 0.0000],\n",
      "        [0.4357, 0.9328, 0.0000, 0.0000],\n",
      "        [0.4357, 0.9328, 0.0000, 0.0000],\n",
      "        [0.4357, 0.9328, 0.0000, 0.0000],\n",
      "        [0.4357, 0.9328, 0.0000, 0.0000],\n",
      "        [0.4357, 0.9328, 0.0000, 0.0000],\n",
      "        [0.4357, 0.9328, 0.0000, 0.0000],\n",
      "        [0.5890, 0.8809, 0.5890, 0.8809],\n",
      "        [0.5890, 0.8809, 0.5706, 0.8251],\n",
      "        [0.5890, 0.8809, 0.5813, 0.8041],\n",
      "        [0.5890, 0.8809, 0.0000, 0.0000],\n",
      "        [0.5890, 0.8809, 0.0000, 0.0000],\n",
      "        [0.5890, 0.8809, 0.0000, 0.0000],\n",
      "        [0.5890, 0.8809, 0.0000, 0.0000],\n",
      "        [0.5890, 0.8809, 0.0000, 0.0000],\n",
      "        [0.5890, 0.8809, 0.0000, 0.0000],\n",
      "        [0.5890, 0.8809, 0.0000, 0.0000]])\n",
      "2020-08-07 20:37:09,044 -3 - <module> - DEBUG - combinedRelationTensor, batch 5:tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4345, 0.9357, 0.4345, 0.9357],\n",
      "        [0.4345, 0.9357, 0.4305, 0.8889],\n",
      "        [0.4345, 0.9357, 0.0000, 0.0000],\n",
      "        [0.4345, 0.9357, 0.0000, 0.0000],\n",
      "        [0.4345, 0.9357, 0.0000, 0.0000],\n",
      "        [0.4345, 0.9357, 0.0000, 0.0000],\n",
      "        [0.4345, 0.9357, 0.0000, 0.0000],\n",
      "        [0.4345, 0.9357, 0.0000, 0.0000],\n",
      "        [0.4345, 0.9357, 0.0000, 0.0000],\n",
      "        [0.4345, 0.9357, 0.0000, 0.0000],\n",
      "        [0.4345, 0.9357, 0.0000, 0.0000],\n",
      "        [0.4345, 0.9357, 0.0000, 0.0000],\n",
      "        [0.4345, 0.9357, 0.0000, 0.0000],\n",
      "        [0.4345, 0.9357, 0.0000, 0.0000],\n",
      "        [0.4345, 0.9357, 0.0000, 0.0000],\n",
      "        [0.4345, 0.9357, 0.0000, 0.0000],\n",
      "        [0.4345, 0.9357, 0.0000, 0.0000],\n",
      "        [0.4345, 0.9357, 0.0000, 0.0000],\n",
      "        [0.4345, 0.9357, 0.0000, 0.0000],\n",
      "        [0.4345, 0.9357, 0.0000, 0.0000],\n",
      "        [0.5910, 0.8833, 0.5910, 0.8833],\n",
      "        [0.5910, 0.8833, 0.5698, 0.8272],\n",
      "        [0.5910, 0.8833, 0.5816, 0.8061],\n",
      "        [0.5910, 0.8833, 0.0000, 0.0000],\n",
      "        [0.5910, 0.8833, 0.0000, 0.0000],\n",
      "        [0.5910, 0.8833, 0.0000, 0.0000],\n",
      "        [0.5910, 0.8833, 0.0000, 0.0000],\n",
      "        [0.5910, 0.8833, 0.0000, 0.0000],\n",
      "        [0.5910, 0.8833, 0.0000, 0.0000],\n",
      "        [0.5910, 0.8833, 0.0000, 0.0000]])\n",
      "2020-08-07 20:37:09,046 -3 - <module> - DEBUG - combinedRelationTensor, batch 6:tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9385, 0.4336, 0.9385],\n",
      "        [0.4336, 0.9385, 0.4309, 0.8918],\n",
      "        [0.4336, 0.9385, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9385, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9385, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9385, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9385, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9385, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9385, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9385, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9385, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9385, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9385, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9385, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9385, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9385, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9385, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9385, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9385, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9385, 0.0000, 0.0000],\n",
      "        [0.5921, 0.8857, 0.5921, 0.8857],\n",
      "        [0.5921, 0.8857, 0.5689, 0.8294],\n",
      "        [0.5921, 0.8857, 0.5819, 0.8082],\n",
      "        [0.5921, 0.8857, 0.0000, 0.0000],\n",
      "        [0.5921, 0.8857, 0.0000, 0.0000],\n",
      "        [0.5921, 0.8857, 0.0000, 0.0000],\n",
      "        [0.5921, 0.8857, 0.0000, 0.0000],\n",
      "        [0.5921, 0.8857, 0.0000, 0.0000],\n",
      "        [0.5921, 0.8857, 0.0000, 0.0000],\n",
      "        [0.5921, 0.8857, 0.0000, 0.0000]])\n",
      "2020-08-07 20:37:09,048 -3 - <module> - DEBUG - combinedRelationTensor, batch 7:tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4334, 0.9413, 0.4334, 0.9413],\n",
      "        [0.4334, 0.9413, 0.4307, 0.8947],\n",
      "        [0.4334, 0.9413, 0.0000, 0.0000],\n",
      "        [0.4334, 0.9413, 0.0000, 0.0000],\n",
      "        [0.4334, 0.9413, 0.0000, 0.0000],\n",
      "        [0.4334, 0.9413, 0.0000, 0.0000],\n",
      "        [0.4334, 0.9413, 0.0000, 0.0000],\n",
      "        [0.4334, 0.9413, 0.0000, 0.0000],\n",
      "        [0.4334, 0.9413, 0.0000, 0.0000],\n",
      "        [0.4334, 0.9413, 0.0000, 0.0000],\n",
      "        [0.4334, 0.9413, 0.0000, 0.0000],\n",
      "        [0.4334, 0.9413, 0.0000, 0.0000],\n",
      "        [0.4334, 0.9413, 0.0000, 0.0000],\n",
      "        [0.4334, 0.9413, 0.0000, 0.0000],\n",
      "        [0.4334, 0.9413, 0.0000, 0.0000],\n",
      "        [0.4334, 0.9413, 0.0000, 0.0000],\n",
      "        [0.4334, 0.9413, 0.0000, 0.0000],\n",
      "        [0.4334, 0.9413, 0.0000, 0.0000],\n",
      "        [0.4334, 0.9413, 0.0000, 0.0000],\n",
      "        [0.4334, 0.9413, 0.0000, 0.0000],\n",
      "        [0.5930, 0.8882, 0.5930, 0.8882],\n",
      "        [0.5930, 0.8882, 0.5682, 0.8315],\n",
      "        [0.5930, 0.8882, 0.5822, 0.8105],\n",
      "        [0.5930, 0.8882, 0.0000, 0.0000],\n",
      "        [0.5930, 0.8882, 0.0000, 0.0000],\n",
      "        [0.5930, 0.8882, 0.0000, 0.0000],\n",
      "        [0.5930, 0.8882, 0.0000, 0.0000],\n",
      "        [0.5930, 0.8882, 0.0000, 0.0000],\n",
      "        [0.5930, 0.8882, 0.0000, 0.0000],\n",
      "        [0.5930, 0.8882, 0.0000, 0.0000]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-07 20:37:09,050 -3 - <module> - DEBUG - combinedRelationTensor, batch 8:tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9442, 0.4336, 0.9442],\n",
      "        [0.4336, 0.9442, 0.4308, 0.8977],\n",
      "        [0.4336, 0.9442, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9442, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9442, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9442, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9442, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9442, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9442, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9442, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9442, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9442, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9442, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9442, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9442, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9442, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9442, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9442, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9442, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9442, 0.0000, 0.0000],\n",
      "        [0.5940, 0.8907, 0.5940, 0.8907],\n",
      "        [0.5940, 0.8907, 0.5679, 0.8337],\n",
      "        [0.5940, 0.8907, 0.5833, 0.8129],\n",
      "        [0.5940, 0.8907, 0.0000, 0.0000],\n",
      "        [0.5940, 0.8907, 0.0000, 0.0000],\n",
      "        [0.5940, 0.8907, 0.0000, 0.0000],\n",
      "        [0.5940, 0.8907, 0.0000, 0.0000],\n",
      "        [0.5940, 0.8907, 0.0000, 0.0000],\n",
      "        [0.5940, 0.8907, 0.0000, 0.0000],\n",
      "        [0.5940, 0.8907, 0.0000, 0.0000]])\n",
      "2020-08-07 20:37:09,053 -3 - <module> - DEBUG - combinedRelationTensor, batch 9:tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9472, 0.4336, 0.9472],\n",
      "        [0.4336, 0.9472, 0.4312, 0.9006],\n",
      "        [0.4336, 0.9472, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9472, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9472, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9472, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9472, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9472, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9472, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9472, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9472, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9472, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9472, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9472, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9472, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9472, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9472, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9472, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9472, 0.0000, 0.0000],\n",
      "        [0.4336, 0.9472, 0.0000, 0.0000],\n",
      "        [0.5949, 0.8931, 0.5949, 0.8931],\n",
      "        [0.5949, 0.8931, 0.5682, 0.8359],\n",
      "        [0.5949, 0.8931, 0.5879, 0.8154],\n",
      "        [0.5949, 0.8931, 0.0000, 0.0000],\n",
      "        [0.5949, 0.8931, 0.0000, 0.0000],\n",
      "        [0.5949, 0.8931, 0.0000, 0.0000],\n",
      "        [0.5949, 0.8931, 0.0000, 0.0000],\n",
      "        [0.5949, 0.8931, 0.0000, 0.0000],\n",
      "        [0.5949, 0.8931, 0.0000, 0.0000],\n",
      "        [0.5949, 0.8931, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "logging.debug(fromAllToStr('combnedRelationTensors.shape',combinedRelationTensors.shape))\n",
    "for i in range(combinedRelationTensors.shape[0]):\n",
    "    logging.debug(fromAllToStr('combinedRelationTensor, batch ', i, ':',combinedRelationTensors[i,0:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-02 23:51:29,184 -1 - <module> - DEBUG - relationInAllTimeStep.shape:torch.Size([10, 5000, 12])\n",
      "2020-08-02 23:51:29,185 -2 - <module> - DEBUG - discountInAllTimeStep,shape:torch.Size([10, 5000])\n"
     ]
    }
   ],
   "source": [
    "logging.debug(fromAllToStr(\"relationInAllTimeStep.shape:\",relationInAllTimeStep.shape))\n",
    "logging.debug(fromAllToStr(\"discountInAllTimeStep,shape:\",discountInAllTimeStep.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-07 21:13:18,776 -3 - <module> - DEBUG - tensorAtensor([[[-1.2679, -0.3436,  0.1848,  ..., -0.1706,  1.4801,  0.8613],\n",
      "         [-0.1130,  0.1196,  0.0445,  ...,  1.0908, -1.5229,  0.6241],\n",
      "         [ 0.5252,  0.4766, -2.2360,  ..., -0.9246,  1.8065, -1.5535],\n",
      "         ...,\n",
      "         [ 0.5641, -1.3842,  0.1798,  ..., -0.5461, -0.1726, -0.5205],\n",
      "         [ 0.9509, -0.0464,  0.5659,  ...,  0.8986, -0.1388,  0.9641],\n",
      "         [-0.4017,  0.8724,  1.1265,  ..., -0.5525,  1.7868, -0.5844]],\n",
      "\n",
      "        [[-0.3541,  0.9536, -0.3846,  ..., -1.1574,  0.6295,  1.3755],\n",
      "         [-1.2854, -0.6289, -0.2576,  ..., -1.1033,  0.1218, -0.1330],\n",
      "         [-2.8292, -0.4509,  0.7004,  ..., -0.4257, -0.0187, -0.9838],\n",
      "         ...,\n",
      "         [-0.1586,  0.6247, -1.7399,  ..., -0.6534, -0.2968,  0.6929],\n",
      "         [ 0.8698,  0.4013,  1.1303,  ...,  0.1937,  2.0308, -0.5198],\n",
      "         [ 1.4512, -0.6343,  1.3178,  ...,  0.6048,  0.9052,  1.0082]],\n",
      "\n",
      "        [[ 0.5913,  0.0437, -1.2241,  ...,  0.0385, -1.1434, -1.5887],\n",
      "         [ 1.0662, -0.3668, -0.8867,  ..., -2.1011, -0.1921, -0.7629],\n",
      "         [ 0.1207, -0.8443, -1.7325,  ...,  1.9769,  0.0136, -0.3032],\n",
      "         ...,\n",
      "         [ 0.5421, -1.0612, -0.5992,  ..., -2.2347, -1.0842,  0.9395],\n",
      "         [ 2.1583,  0.2405, -0.4205,  ..., -0.0336, -0.8275, -2.1012],\n",
      "         [-0.4397,  1.8076, -0.5380,  ..., -0.3238, -1.7609, -1.4183]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.2302, -0.7330,  0.5062,  ..., -0.1389, -1.4071,  0.8259],\n",
      "         [-0.0287, -0.0371, -0.2545,  ...,  0.2189,  0.5280, -0.1784],\n",
      "         [-0.4184, -1.1517,  0.4541,  ..., -1.2365, -0.2920, -2.1214],\n",
      "         ...,\n",
      "         [-0.1459,  0.3903, -0.8558,  ..., -0.4051, -1.7389,  0.4492],\n",
      "         [ 0.7660,  0.3033,  0.5300,  ...,  0.2932,  2.3871, -0.1993],\n",
      "         [ 1.5930,  0.3688,  2.1101,  ...,  1.6644, -0.7127,  0.6272]],\n",
      "\n",
      "        [[-0.8249, -1.0761,  0.2677,  ..., -0.5324,  1.8954, -0.2564],\n",
      "         [-0.7788, -0.4501, -0.0186,  ..., -0.7427, -0.3654, -1.5461],\n",
      "         [ 0.1166,  0.4484, -1.1094,  ..., -0.1974,  1.2448, -0.8315],\n",
      "         ...,\n",
      "         [ 0.4157,  1.3975,  0.0798,  ..., -1.9595, -0.3805, -1.4938],\n",
      "         [-0.4903,  0.6520,  0.8183,  ..., -0.1541, -0.2894,  0.9820],\n",
      "         [ 0.0483,  1.3964,  0.6249,  ..., -1.3766,  1.4403, -0.0457]],\n",
      "\n",
      "        [[ 1.0081,  1.0569,  0.3638,  ...,  1.6559,  1.2216, -0.8158],\n",
      "         [-1.7623,  0.5769,  0.4564,  ..., -1.3571, -0.4095,  1.0057],\n",
      "         [ 0.5019,  1.0339,  0.6412,  ..., -0.1873,  0.5318, -0.2553],\n",
      "         ...,\n",
      "         [-0.5740, -2.0021, -2.9472,  ...,  0.3314, -0.9110, -0.0117],\n",
      "         [ 1.4013, -0.4980,  0.2365,  ..., -0.6446, -0.0843, -0.6208],\n",
      "         [ 0.2449, -0.4820,  2.0501,  ..., -0.7119, -0.8229, -1.3839]]])\n",
      "2020-08-07 21:13:18,778 -4 - <module> - DEBUG - tensorBtensor([[[-0.6240],\n",
      "         [-0.1925],\n",
      "         [ 0.4158],\n",
      "         [ 1.7772],\n",
      "         [-0.9274],\n",
      "         [-0.7140],\n",
      "         [ 1.2060],\n",
      "         [ 0.9316],\n",
      "         [-0.0524],\n",
      "         [ 0.3103]],\n",
      "\n",
      "        [[ 1.5688],\n",
      "         [-0.0585],\n",
      "         [ 0.6066],\n",
      "         [ 0.3398],\n",
      "         [-0.7935],\n",
      "         [-1.5805],\n",
      "         [ 0.4011],\n",
      "         [ 0.1775],\n",
      "         [-0.5102],\n",
      "         [-0.1846]],\n",
      "\n",
      "        [[ 2.6584],\n",
      "         [-0.2906],\n",
      "         [-1.1788],\n",
      "         [-0.2390],\n",
      "         [ 0.4042],\n",
      "         [ 0.3812],\n",
      "         [ 0.3626],\n",
      "         [ 0.3813],\n",
      "         [-0.3742],\n",
      "         [-0.2176]],\n",
      "\n",
      "        [[ 1.1456],\n",
      "         [ 0.2722],\n",
      "         [ 0.9370],\n",
      "         [-0.5049],\n",
      "         [ 1.0294],\n",
      "         [ 0.7589],\n",
      "         [-1.3092],\n",
      "         [ 1.2583],\n",
      "         [-0.0145],\n",
      "         [ 0.4879]],\n",
      "\n",
      "        [[ 0.3674],\n",
      "         [-1.4147],\n",
      "         [ 2.0974],\n",
      "         [-1.0798],\n",
      "         [ 1.1527],\n",
      "         [-0.3895],\n",
      "         [-0.3609],\n",
      "         [ 0.6599],\n",
      "         [ 1.1486],\n",
      "         [-0.0313]],\n",
      "\n",
      "        [[-1.5127],\n",
      "         [ 0.7777],\n",
      "         [ 0.6520],\n",
      "         [-1.1501],\n",
      "         [-1.0883],\n",
      "         [-0.4670],\n",
      "         [ 1.3897],\n",
      "         [-0.3469],\n",
      "         [-0.6719],\n",
      "         [ 0.0671]],\n",
      "\n",
      "        [[ 0.8527],\n",
      "         [ 0.5032],\n",
      "         [-0.6354],\n",
      "         [-0.4119],\n",
      "         [-1.1092],\n",
      "         [ 1.1311],\n",
      "         [ 2.0336],\n",
      "         [-1.5781],\n",
      "         [-1.0911],\n",
      "         [-0.4064]],\n",
      "\n",
      "        [[ 0.3479],\n",
      "         [-0.3234],\n",
      "         [-1.1337],\n",
      "         [ 0.2847],\n",
      "         [-1.4634],\n",
      "         [-0.7305],\n",
      "         [-0.2574],\n",
      "         [ 1.1026],\n",
      "         [-1.6574],\n",
      "         [ 0.4387]],\n",
      "\n",
      "        [[ 2.8148],\n",
      "         [ 0.3350],\n",
      "         [-0.4366],\n",
      "         [-1.6808],\n",
      "         [-0.5779],\n",
      "         [ 0.1395],\n",
      "         [ 2.2929],\n",
      "         [ 0.7071],\n",
      "         [ 0.9707],\n",
      "         [ 0.4133]],\n",
      "\n",
      "        [[-0.9502],\n",
      "         [ 0.2795],\n",
      "         [ 0.9528],\n",
      "         [ 0.0203],\n",
      "         [-0.0297],\n",
      "         [-0.6175],\n",
      "         [ 0.2287],\n",
      "         [ 0.6434],\n",
      "         [ 0.4102],\n",
      "         [ 0.4811]]])\n",
      "2020-08-07 21:13:18,782 -6 - <module> - DEBUG - tensorAmBtensor([[[ 7.9113e-01,  2.1442e-01, -1.1533e-01,  ...,  1.0644e-01,\n",
      "          -9.2350e-01, -5.3740e-01],\n",
      "         [ 2.1740e-02, -2.3018e-02, -8.5622e-03,  ..., -2.0994e-01,\n",
      "           2.9310e-01, -1.2011e-01],\n",
      "         [ 2.1839e-01,  1.9818e-01, -9.2978e-01,  ..., -3.8447e-01,\n",
      "           7.5119e-01, -6.4599e-01],\n",
      "         ...,\n",
      "         [ 5.2556e-01, -1.2895e+00,  1.6755e-01,  ..., -5.0879e-01,\n",
      "          -1.6076e-01, -4.8496e-01],\n",
      "         [-4.9867e-02,  2.4327e-03, -2.9674e-02,  ..., -4.7125e-02,\n",
      "           7.2779e-03, -5.0560e-02],\n",
      "         [-1.2463e-01,  2.7068e-01,  3.4953e-01,  ..., -1.7143e-01,\n",
      "           5.5440e-01, -1.8134e-01]],\n",
      "\n",
      "        [[-5.5556e-01,  1.4961e+00, -6.0333e-01,  ..., -1.8157e+00,\n",
      "           9.8764e-01,  2.1579e+00],\n",
      "         [ 7.5132e-02,  3.6759e-02,  1.5058e-02,  ...,  6.4486e-02,\n",
      "          -7.1212e-03,  7.7767e-03],\n",
      "         [-1.7161e+00, -2.7351e-01,  4.2486e-01,  ..., -2.5823e-01,\n",
      "          -1.1359e-02, -5.9674e-01],\n",
      "         ...,\n",
      "         [-2.8146e-02,  1.1086e-01, -3.0880e-01,  ..., -1.1596e-01,\n",
      "          -5.2673e-02,  1.2297e-01],\n",
      "         [-4.4372e-01, -2.0473e-01, -5.7665e-01,  ..., -9.8827e-02,\n",
      "          -1.0361e+00,  2.6521e-01],\n",
      "         [-2.6795e-01,  1.1711e-01, -2.4332e-01,  ..., -1.1167e-01,\n",
      "          -1.6713e-01, -1.8615e-01]],\n",
      "\n",
      "        [[ 1.5718e+00,  1.1610e-01, -3.2542e+00,  ...,  1.0228e-01,\n",
      "          -3.0395e+00, -4.2233e+00],\n",
      "         [-3.0985e-01,  1.0660e-01,  2.5769e-01,  ...,  6.1061e-01,\n",
      "           5.5823e-02,  2.2172e-01],\n",
      "         [-1.4226e-01,  9.9528e-01,  2.0421e+00,  ..., -2.3303e+00,\n",
      "          -1.6060e-02,  3.5742e-01],\n",
      "         ...,\n",
      "         [ 2.0673e-01, -4.0467e-01, -2.2848e-01,  ..., -8.5217e-01,\n",
      "          -4.1344e-01,  3.5825e-01],\n",
      "         [-8.0774e-01, -8.9993e-02,  1.5736e-01,  ...,  1.2579e-02,\n",
      "           3.0968e-01,  7.8635e-01],\n",
      "         [ 9.5651e-02, -3.9324e-01,  1.1705e-01,  ...,  7.0449e-02,\n",
      "           3.8308e-01,  3.0854e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.2796e-01, -2.5501e-01,  1.7609e-01,  ..., -4.8320e-02,\n",
      "          -4.8952e-01,  2.8734e-01],\n",
      "         [ 9.2933e-03,  1.1987e-02,  8.2302e-02,  ..., -7.0798e-02,\n",
      "          -1.7076e-01,  5.7694e-02],\n",
      "         [ 4.7433e-01,  1.3057e+00, -5.1485e-01,  ...,  1.4019e+00,\n",
      "           3.3101e-01,  2.4050e+00],\n",
      "         ...,\n",
      "         [-1.6092e-01,  4.3031e-01, -9.4361e-01,  ..., -4.4672e-01,\n",
      "          -1.9173e+00,  4.9526e-01],\n",
      "         [-1.2696e+00, -5.0261e-01, -8.7843e-01,  ..., -4.8602e-01,\n",
      "          -3.9564e+00,  3.3037e-01],\n",
      "         [ 6.9877e-01,  1.6177e-01,  9.2559e-01,  ...,  7.3010e-01,\n",
      "          -3.1261e-01,  2.7511e-01]],\n",
      "\n",
      "        [[-2.3220e+00, -3.0290e+00,  7.5363e-01,  ..., -1.4985e+00,\n",
      "           5.3351e+00, -7.2165e-01],\n",
      "         [-2.6087e-01, -1.5077e-01, -6.2380e-03,  ..., -2.4878e-01,\n",
      "          -1.2238e-01, -5.1789e-01],\n",
      "         [-5.0907e-02, -1.9580e-01,  4.8441e-01,  ...,  8.6210e-02,\n",
      "          -5.4354e-01,  3.6304e-01],\n",
      "         ...,\n",
      "         [ 2.9395e-01,  9.8818e-01,  5.6399e-02,  ..., -1.3855e+00,\n",
      "          -2.6901e-01, -1.0563e+00],\n",
      "         [-4.7594e-01,  6.3287e-01,  7.9430e-01,  ..., -1.4961e-01,\n",
      "          -2.8096e-01,  9.5327e-01],\n",
      "         [ 1.9962e-02,  5.7713e-01,  2.5828e-01,  ..., -5.6895e-01,\n",
      "           5.9527e-01, -1.8880e-02]],\n",
      "\n",
      "        [[-9.5783e-01, -1.0042e+00, -3.4570e-01,  ..., -1.5733e+00,\n",
      "          -1.1607e+00,  7.7510e-01],\n",
      "         [-4.9257e-01,  1.6124e-01,  1.2757e-01,  ..., -3.7932e-01,\n",
      "          -1.1445e-01,  2.8111e-01],\n",
      "         [ 4.7818e-01,  9.8511e-01,  6.1097e-01,  ..., -1.7848e-01,\n",
      "           5.0671e-01, -2.4324e-01],\n",
      "         ...,\n",
      "         [-3.6931e-01, -1.2882e+00, -1.8962e+00,  ...,  2.1324e-01,\n",
      "          -5.8612e-01, -7.5173e-03],\n",
      "         [ 5.7486e-01, -2.0429e-01,  9.7018e-02,  ..., -2.6445e-01,\n",
      "          -3.4584e-02, -2.5469e-01],\n",
      "         [ 1.1784e-01, -2.3193e-01,  9.8637e-01,  ..., -3.4250e-01,\n",
      "          -3.9590e-01, -6.6585e-01]]])\n"
     ]
    }
   ],
   "source": [
    "tensorA=torch.randn(10,10,100)\n",
    "tensorB=torch.randn(10,10,1)\n",
    "logging.debug(fromAllToStr('tensorA',tensorA))\n",
    "logging.debug(fromAllToStr('tensorB',tensorB))\n",
    "tensorAmB=torch.mul(tensorA,tensorB)\n",
    "logging.debug(fromAllToStr('tensorAmB',tensorAmB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-02 22:52:35,562 -3 - <module> - DEBUG - toTestDifferenceItem[0]:tensor([0.2609, 0.3732, 0.2600, 0.1253, 0.2766, 0.4081, 0.2603, 0.0877, 0.1010,\n",
      "        0.3945, 0.0981, 0.2555, 0.4153, 0.0874, 0.5983, 0.3963, 0.5847, 0.2504,\n",
      "        0.7671, 0.1082, 0.4188, 0.7289, 0.2566, 0.7379, 0.3865, 0.5530, 0.0989,\n",
      "        0.2716, 0.5814, 0.0974, 0.2384, 0.4232, 0.5597, 0.7003, 0.2451, 0.3901,\n",
      "        0.5692, 0.7398, 0.7114, 0.1005, 0.4156, 0.7429, 0.1141, 0.2707, 0.4059,\n",
      "        0.5494, 0.5665, 0.6981, 0.2740, 0.5297, 0.2423, 0.2305, 0.6526, 0.4134,\n",
      "        0.5797, 0.0745, 0.4274, 0.7192, 0.5536, 0.2522, 0.0932, 0.4223, 0.7164,\n",
      "        0.2602, 0.0877, 0.5855, 0.7187, 0.0980, 0.5927, 0.3995, 0.2363, 0.7187,\n",
      "        0.0515, 0.4247, 0.1640, 0.2656, 0.5564, 0.7128, 0.2588, 0.4174, 0.5691,\n",
      "        0.1410, 0.1012, 0.7484, 0.2568, 0.4133, 0.5571, 0.7290, 0.2833, 0.0737,\n",
      "        0.5728, 0.7163, 0.4280, 0.5840, 0.2535, 0.0793, 0.4096, 0.7199, 0.2609,\n",
      "        0.5589, 0.5537, 0.3944, 0.1324, 0.2456, 0.5348, 0.7722, 0.6881, 0.0362,\n",
      "        0.2501, 0.3976, 0.5255, 0.7094, 0.7278, 0.3886, 0.1171, 0.2656, 0.5509,\n",
      "        0.3946, 0.8537, 0.0799, 0.7130, 0.8859, 0.2755, 0.4141, 0.5664, 0.7083,\n",
      "        0.4158, 0.7110, 0.1194, 0.5781, 0.4207, 0.2413, 0.7033, 0.3979, 0.1073,\n",
      "        0.5528, 0.2527, 0.7157, 0.5636, 0.4010, 0.1180, 0.0925, 0.4027, 0.2655,\n",
      "        0.2315, 0.5713, 0.7185, 0.0799, 0.3992, 0.2331, 0.7225, 0.1016, 0.3808,\n",
      "        0.2439, 0.0806, 0.1259, 0.3944, 0.5576, 0.6943, 0.0932, 0.2046, 0.2425,\n",
      "        0.5288, 0.3487, 0.0794, 0.5565, 0.3834, 0.5247, 0.5447, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "2020-08-02 22:52:35,581 -14 - differenceBetweenTwoFrameForBatch - DEBUG - tensor([[[[2.6061e-01, 3.7780e-01, 2.6149e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.2796e-01, 9.2535e-01, 8.9642e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.9765e-03, 3.8460e-03, 1.5285e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.1311e-01, 2.8518e-01, 1.5865e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.1960e-03, 1.2377e-02, 9.6343e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.7586e-01, 9.1777e-01, 9.9995e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[2.6005e-01, 3.8390e-01, 2.6390e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.2891e-01, 9.2662e-01, 8.9715e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.0256e-03, 3.9976e-03, 1.6444e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.1909e-01, 2.9210e-01, 1.6925e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.8306e-03, 9.1026e-03, 7.5686e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.3881e-01, 6.6512e-01, 7.7898e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[2.5994e-01, 3.8959e-01, 2.6593e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.2988e-01, 9.2791e-01, 8.9791e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.0546e-03, 4.0861e-03, 1.6977e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.2255e-01, 2.9462e-01, 1.7355e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.4896e-03, 7.0143e-03, 5.2315e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.9462e-01, 5.0575e-01, 5.3480e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.5802e-01, 4.1255e-01, 2.7417e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.3377e-01, 9.3304e-01, 9.0081e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.1257e-03, 4.1774e-03, 1.6150e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.3294e-01, 2.8601e-01, 1.6064e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.7034e-03, 1.7994e-03, 5.3315e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [8.4416e-01, 1.2320e-01, 5.3033e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[2.5818e-01, 4.1783e-01, 2.7672e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.3481e-01, 9.3427e-01, 9.0150e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.1764e-03, 4.0764e-03, 1.6458e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.3860e-01, 2.7594e-01, 1.6232e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.2667e-03, 0.0000e+00, 7.0425e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.8702e-01, 0.0000e+00, 6.9461e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[2.5780e-01, 4.2160e-01, 2.7884e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.3588e-01, 9.3544e-01, 9.0221e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.1678e-03, 3.9110e-03, 1.7117e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.3829e-01, 2.6272e-01, 1.6767e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.8144e-03, 0.0000e+00, 7.4007e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.0936e-01, 0.0000e+00, 7.2496e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.2712e-01, 1.0105e-01, 8.9364e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.2999e-01, 8.3467e-01, 7.8005e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.4314e-03, 2.6425e-03, 2.0473e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.6022e-01, 6.6106e-01, 5.4113e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.0674e-03, 0.0000e+00, 1.6637e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.5803e-01, 0.0000e+00, 4.3973e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[1.2595e-01, 9.8428e-02, 8.9241e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.3329e-01, 8.3750e-01, 7.8240e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.3813e-03, 2.5075e-03, 2.0341e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.5875e-01, 6.4627e-01, 5.3998e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.8442e-03, 0.0000e+00, 1.6833e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.1384e-01, 0.0000e+00, 4.4687e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[1.2478e-01, 9.4644e-02, 8.9105e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.3657e-01, 8.4028e-01, 7.8473e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.3330e-03, 2.3587e-03, 2.0304e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.5760e-01, 6.3441e-01, 5.4144e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.0426e-03, 3.4191e-04, 2.3304e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.6428e-01, 9.1964e-02, 6.2142e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.2468e-01, 9.5257e-02, 9.3583e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.4977e-01, 8.5129e-01, 7.9437e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.3080e-03, 2.4438e-03, 2.2315e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.6295e-01, 6.6107e-01, 5.7345e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.1079e-03, 3.6968e-03, 3.0992e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.8616e-01, 9.9999e-01, 7.9642e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[1.2568e-01, 9.8741e-02, 9.3991e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.5309e-01, 8.5419e-01, 7.9687e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.3161e-03, 2.5867e-03, 2.2650e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.6138e-01, 6.7722e-01, 5.8142e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.6955e-03, 3.8195e-03, 3.3652e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.8928e-01, 9.9999e-01, 8.6383e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[1.2573e-01, 1.0259e-01, 9.3733e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.5640e-01, 8.5717e-01, 7.9941e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.2884e-03, 2.7215e-03, 2.2904e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.5739e-01, 6.8814e-01, 5.9150e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.1649e-03, 3.2292e-03, 3.8221e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.6830e-01, 8.1651e-01, 9.8705e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]]],\n",
      "\n",
      "\n",
      "        [[[8.3525e-02, 7.3726e-02, 1.2355e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.6886e-01, 9.5018e-01, 8.7855e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.9422e-03, 1.7470e-03, 3.0202e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.8216e-01, 6.8174e-01, 6.5047e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.4236e-03, 1.2767e-03, 3.2378e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0000e-01, 4.9821e-01, 6.9731e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[0.0000e+00, 7.3712e-02, 1.2071e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 9.5314e-01, 8.8138e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.7420e-03, 2.9639e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 6.8205e-01, 6.5550e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.3284e-03, 3.3730e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0000e-01, 5.2009e-01, 7.4597e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[0.0000e+00, 7.3712e-02, 1.1823e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 9.5609e-01, 8.8424e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.7447e-03, 2.9156e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 6.8520e-01, 6.6043e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.8074e-03, 3.0409e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0000e-01, 7.0982e-01, 6.8883e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 7.3508e-02, 1.0744e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 9.6818e-01, 8.9578e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.7347e-03, 2.6064e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 6.9181e-01, 6.5823e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.2537e-03, 1.0430e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0000e-01, 5.0000e-01, 2.6339e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 1.0476e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 8.9862e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 2.5220e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 6.5529e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 1.5274e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0000e-01, 5.0000e-01, 3.9687e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 1.0259e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 9.0144e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 2.4663e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 6.5634e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 2.5599e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0000e-01, 5.0000e-01, 6.8125e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]]],\n",
      "\n",
      "\n",
      "        [[[2.8638e-01, 2.7089e-01, 4.5267e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.6933e-01, 9.3139e-01, 9.4721e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.8659e-03, 3.5275e-03, 4.9679e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.9620e-01, 3.6724e-01, 3.1476e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.8785e-03, 4.8025e-03, 7.8907e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [4.9998e-01, 4.9998e-01, 4.9994e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[0.0000e+00, 2.7032e-01, 4.5267e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 9.3299e-01, 9.4857e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 3.5141e-03, 4.9607e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 3.6724e-01, 3.1476e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 4.7842e-03, 7.8793e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0000e-01, 4.9998e-01, 4.9994e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[0.0000e+00, 2.6977e-01, 4.5268e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 9.3459e-01, 9.4994e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 3.4878e-03, 4.9538e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 3.6588e-01, 3.1476e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 3.9065e-03, 7.8682e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0000e-01, 4.0980e-01, 4.9994e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 2.6850e-01, 4.5267e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 9.4085e-01, 9.5540e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 3.4198e-03, 4.9269e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 3.6284e-01, 3.1486e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 6.3069e-03, 7.9697e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0000e-01, 6.6917e-01, 5.0931e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[0.0000e+00, 2.6850e-01, 4.5267e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 9.4244e-01, 9.5677e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 3.4426e-03, 4.9248e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 3.6588e-01, 3.1518e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 5.5570e-03, 8.0908e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0000e-01, 5.9060e-01, 5.1779e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[0.0000e+00, 2.6849e-01, 4.5266e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 9.4404e-01, 9.5814e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 3.4494e-03, 4.9225e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 3.6725e-01, 3.1549e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 4.6962e-03, 7.9397e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0000e-01, 4.9998e-01, 5.0887e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.2142e-01, 7.4239e-01, 5.8688e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.6386e-01, 8.9175e-01, 9.3306e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.0566e-03, 1.5844e-02, 1.3171e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.3473e-01, 5.7628e-01, 6.3407e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.0801e-03, 1.4502e-02, 3.5232e-03,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0000e-01, 5.2748e-01, 1.6961e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[1.1454e-01, 7.4054e-01, 5.8567e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.6705e-01, 8.9428e-01, 9.3577e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.8717e-03, 1.5614e-02, 1.3093e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.3473e-01, 5.7093e-01, 6.3344e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.9543e-03, 3.0999e-03, 1.2860e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0000e-01, 1.1335e-01, 6.2219e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[1.1446e-01, 7.4017e-01, 5.8420e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.7024e-01, 8.9673e-01, 9.3851e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.8626e-03, 1.5198e-02, 1.3203e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.3473e-01, 5.5751e-01, 6.4226e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.9480e-03, 0.0000e+00, 2.0553e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0000e-01, 0.0000e+00, 9.9979e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000e+00, 7.3899e-01, 5.8504e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 9.0627e-01, 9.5016e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.5372e-02, 1.3871e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 5.7083e-01, 6.8213e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 2.4540e-02, 1.0129e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0000e-01, 9.1128e-01, 4.9811e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[0.0000e+00, 7.3809e-01, 5.8504e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 9.0881e-01, 9.5312e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.5471e-02, 1.3830e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 5.7681e-01, 6.8223e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.3490e-02, 1.0134e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0000e-01, 5.0294e-01, 4.9990e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]],\n",
      "\n",
      "         [[0.0000e+00, 7.3722e-01, 5.8504e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 9.1131e-01, 9.5608e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.5413e-02, 1.3794e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 5.7692e-01, 6.8255e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 1.3354e-02, 1.0572e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0000e-01, 4.9982e-01, 5.2311e-01,  ..., 5.0000e-01,\n",
      "           5.0000e-01, 5.0000e-01]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-02 22:52:35,598 -15 - differenceBetweenTwoFrameForBatch - DEBUG - tensor([[[[0.2609, 0.3732, 0.2600,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9271, 0.9241, 0.8958,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2065, 0.2732, 0.1412,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7759, 1.0000, 1.0000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.2606, 0.3778, 0.2615,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9280, 0.9253, 0.8964,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0020, 0.0038, 0.0015,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2131, 0.2852, 0.1586,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0072, 0.0124, 0.0096,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7759, 0.9178, 1.0000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.2600, 0.3839, 0.2639,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9289, 0.9266, 0.8971,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0020, 0.0040, 0.0016,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2191, 0.2921, 0.1692,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0068, 0.0091, 0.0076,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7388, 0.6651, 0.7790,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.2587, 0.4066, 0.2720,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9328, 0.9318, 0.9001,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0021, 0.0042, 0.0016,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2269, 0.2923, 0.1624,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0066, 0.0050, 0.0032,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7241, 0.3437, 0.3254,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.2580, 0.4125, 0.2742,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9338, 0.9330, 0.9008,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0021, 0.0042, 0.0016,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2329, 0.2860, 0.1606,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0077, 0.0018, 0.0053,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.8442, 0.1232, 0.5303,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.2582, 0.4178, 0.2767,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9348, 0.9343, 0.9015,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0022, 0.0041, 0.0016,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2386, 0.2759, 0.1623,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0063, 0.0000, 0.0070,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.6870, 0.0000, 0.6946,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.1283, 0.1032, 0.0895,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9267, 0.8318, 0.7777,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7602, 0.6732, 0.5421,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5406, 0.0804, 0.4929,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.1271, 0.1011, 0.0894,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9300, 0.8347, 0.7801,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0034, 0.0026, 0.0020,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7602, 0.6611, 0.5411,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0021, 0.0000, 0.0017,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.4580, 0.0000, 0.4397,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.1259, 0.0984, 0.0892,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9333, 0.8375, 0.7824,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0034, 0.0025, 0.0020,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7588, 0.6463, 0.5400,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0018, 0.0000, 0.0017,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.4138, 0.0000, 0.4469,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.1242, 0.0929, 0.0924,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9465, 0.8485, 0.7919,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0033, 0.0023, 0.0022,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7621, 0.6447, 0.5653,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0025, 0.0036, 0.0034,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5839, 1.0000, 0.8732,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.1247, 0.0953, 0.0936,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9498, 0.8513, 0.7944,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0033, 0.0024, 0.0022,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7630, 0.6611, 0.5734,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0021, 0.0037, 0.0031,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.4862, 1.0000, 0.7964,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.1257, 0.0987, 0.0940,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9531, 0.8542, 0.7969,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0033, 0.0026, 0.0023,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7614, 0.6772, 0.5814,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0017, 0.0038, 0.0034,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.3893, 1.0000, 0.8638,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.0836, 0.0737, 0.1262,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9659, 0.9472, 0.8757,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.6822, 0.6818, 0.6477,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.4884, 0.5500,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.0835, 0.0737, 0.1236,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9689, 0.9502, 0.8785,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0019, 0.0017, 0.0030,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.6822, 0.6817, 0.6505,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0014, 0.0013, 0.0032,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.4982, 0.6973,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.0000, 0.0737, 0.1207,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9531, 0.8814,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0017, 0.0030,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.6821, 0.6555,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0013, 0.0034,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5201, 0.7460,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.0736, 0.1101,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9652, 0.8929,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0017, 0.0027,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.6918, 0.6627,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0013, 0.0014,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5000, 0.3531,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.0000, 0.0735, 0.1074,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9682, 0.8958,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0017, 0.0026,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.6918, 0.6582,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0013, 0.0010,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5000, 0.2634,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.1048,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.8986,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0025,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.6553,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0015,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5000, 0.3969,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.2864, 0.2715, 0.4527,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9675, 0.9298, 0.9458,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.3962, 0.3673, 0.3148,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.2864, 0.2709, 0.4527,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9693, 0.9314, 0.9472,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0039, 0.0035, 0.0050,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.3962, 0.3672, 0.3148,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0049, 0.0048, 0.0079,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5000, 0.4999,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.0000, 0.2703, 0.4527,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9330, 0.9486,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0035, 0.0050,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.3672, 0.3148,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0048, 0.0079,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5000, 0.4999,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.2685, 0.4527,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9393, 0.9540,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0034, 0.0049,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.3607, 0.3148,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0055, 0.0078,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5808, 0.4999,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.0000, 0.2685, 0.4527,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9409, 0.9554,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0034, 0.0049,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.3628, 0.3149,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0063, 0.0080,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.6692, 0.5093,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.0000, 0.2685, 0.4527,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9424, 0.9568,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0034, 0.0049,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.3659, 0.3152,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0056, 0.0081,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5906, 0.5178,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.1214, 0.7455, 0.5879,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9607, 0.8892, 0.9303,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7347, 0.5753, 0.6411,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.4906, 0.5616, 0.1929,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.1214, 0.7424, 0.5869,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9639, 0.8917, 0.9331,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0031, 0.0158, 0.0132,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7347, 0.5763, 0.6341,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0021, 0.0145, 0.0035,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5275, 0.1696,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.1145, 0.7405, 0.5857,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9670, 0.8943, 0.9358,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0029, 0.0156, 0.0131,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7347, 0.5709, 0.6334,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0020, 0.0031, 0.0129,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.1134, 0.6222,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.7403, 0.5850,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9038, 0.9472,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0151, 0.0139,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.5571, 0.6808,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0270, 0.0122,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.9996, 0.5959,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.0000, 0.7390, 0.5850,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9063, 0.9502,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0154, 0.0139,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.5708, 0.6821,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0245, 0.0101,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.9113, 0.4981,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.0000, 0.7381, 0.5850,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9088, 0.9531,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0155, 0.0138,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.5768, 0.6822,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0135, 0.0101,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5029, 0.4999,  ..., 0.5000, 0.5000, 0.5000]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-02 22:52:35,614 -16 - differenceBetweenTwoFrameForBatch - DEBUG - tensor([[[[0.2609, 0.3732, 0.2600,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9271, 0.9241, 0.8958,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2065, 0.2732, 0.1412,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7759, 1.0000, 1.0000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.2606, 0.3778, 0.2615,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9280, 0.9253, 0.8964,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0020, 0.0038, 0.0015,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2131, 0.2852, 0.1586,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0072, 0.0124, 0.0096,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7759, 0.9178, 1.0000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.2600, 0.3839, 0.2639,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9289, 0.9266, 0.8971,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0020, 0.0040, 0.0016,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2191, 0.2921, 0.1692,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0068, 0.0091, 0.0076,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7388, 0.6651, 0.7790,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.2580, 0.4125, 0.2742,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9338, 0.9330, 0.9008,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0021, 0.0042, 0.0016,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2329, 0.2860, 0.1606,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0077, 0.0018, 0.0053,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.8442, 0.1232, 0.5303,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.2582, 0.4178, 0.2767,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9348, 0.9343, 0.9015,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0022, 0.0041, 0.0016,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2386, 0.2759, 0.1623,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0063, 0.0000, 0.0070,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.6870, 0.0000, 0.6946,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.2578, 0.4216, 0.2788,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9359, 0.9354, 0.9022,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0022, 0.0039, 0.0017,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2383, 0.2627, 0.1677,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0028, 0.0000, 0.0074,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.3094, 0.0000, 0.7250,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.1283, 0.1032, 0.0895,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9267, 0.8318, 0.7777,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7602, 0.6732, 0.5421,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5406, 0.0804, 0.4929,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.1271, 0.1011, 0.0894,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9300, 0.8347, 0.7801,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0034, 0.0026, 0.0020,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7602, 0.6611, 0.5411,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0021, 0.0000, 0.0017,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.4580, 0.0000, 0.4397,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.1259, 0.0984, 0.0892,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9333, 0.8375, 0.7824,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0034, 0.0025, 0.0020,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7588, 0.6463, 0.5400,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0018, 0.0000, 0.0017,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.4138, 0.0000, 0.4469,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.1247, 0.0953, 0.0936,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9498, 0.8513, 0.7944,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0033, 0.0024, 0.0022,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7630, 0.6611, 0.5734,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0021, 0.0037, 0.0031,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.4862, 1.0000, 0.7964,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.1257, 0.0987, 0.0940,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9531, 0.8542, 0.7969,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0033, 0.0026, 0.0023,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7614, 0.6772, 0.5814,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0017, 0.0038, 0.0034,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.3893, 1.0000, 0.8638,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.1257, 0.1026, 0.0937,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9564, 0.8572, 0.7994,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0033, 0.0027, 0.0023,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7574, 0.6881, 0.5915,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0012, 0.0032, 0.0038,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2683, 0.8165, 0.9870,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.0836, 0.0737, 0.1262,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9659, 0.9472, 0.8757,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.6822, 0.6818, 0.6477,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.4884, 0.5500,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.0835, 0.0737, 0.1236,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9689, 0.9502, 0.8785,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0019, 0.0017, 0.0030,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.6822, 0.6817, 0.6505,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0014, 0.0013, 0.0032,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.4982, 0.6973,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.0000, 0.0737, 0.1207,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9531, 0.8814,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0017, 0.0030,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.6821, 0.6555,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0013, 0.0034,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5201, 0.7460,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.0735, 0.1074,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9682, 0.8958,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0017, 0.0026,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.6918, 0.6582,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0013, 0.0010,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5000, 0.2634,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.1048,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.8986,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0025,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.6553,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0015,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5000, 0.3969,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.1026,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.9014,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0025,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.6563,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0026,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5000, 0.6812,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.2864, 0.2715, 0.4527,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9675, 0.9298, 0.9458,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.3962, 0.3673, 0.3148,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.2864, 0.2709, 0.4527,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9693, 0.9314, 0.9472,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0039, 0.0035, 0.0050,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.3962, 0.3672, 0.3148,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0049, 0.0048, 0.0079,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5000, 0.4999,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.0000, 0.2703, 0.4527,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9330, 0.9486,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0035, 0.0050,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.3672, 0.3148,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0048, 0.0079,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5000, 0.4999,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.2685, 0.4527,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9409, 0.9554,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0034, 0.0049,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.3628, 0.3149,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0063, 0.0080,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.6692, 0.5093,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.0000, 0.2685, 0.4527,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9424, 0.9568,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0034, 0.0049,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.3659, 0.3152,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0056, 0.0081,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5906, 0.5178,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.0000, 0.2685, 0.4527,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9440, 0.9581,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0034, 0.0049,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.3672, 0.3155,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0047, 0.0079,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5000, 0.5089,  ..., 0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.1214, 0.7455, 0.5879,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9607, 0.8892, 0.9303,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7347, 0.5753, 0.6411,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.4906, 0.5616, 0.1929,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.1214, 0.7424, 0.5869,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9639, 0.8917, 0.9331,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0031, 0.0158, 0.0132,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7347, 0.5763, 0.6341,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0021, 0.0145, 0.0035,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5275, 0.1696,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.1145, 0.7405, 0.5857,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9670, 0.8943, 0.9358,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0029, 0.0156, 0.0131,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7347, 0.5709, 0.6334,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0020, 0.0031, 0.0129,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.1134, 0.6222,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0000, 0.7390, 0.5850,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9063, 0.9502,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0154, 0.0139,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.5708, 0.6821,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0245, 0.0101,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.9113, 0.4981,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.0000, 0.7381, 0.5850,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9088, 0.9531,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0155, 0.0138,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.5768, 0.6822,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0135, 0.0101,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.5029, 0.4999,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "\n",
      "         [[0.0000, 0.7372, 0.5850,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.9113, 0.9561,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0154, 0.0138,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.5769, 0.6825,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0134, 0.0106,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.5000, 0.4998, 0.5231,  ..., 0.5000, 0.5000, 0.5000]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-02 22:52:35,615 -6 - <module> - DEBUG - differenceSeries.shape:torch.Size([5, 9, 6, 250])toTestDifferenceItem.shape:torch.Size([5, 10, 6, 250])\n"
     ]
    }
   ],
   "source": [
    "loaderIter=iter(datasetV3Loader)\n",
    "toTestDifferenceItem, toTestDifferenceLabel=loaderIter.__next__()\n",
    "logging.debug(fromAllToStr(\"toTestDifferenceItem[0]:\",toTestDifferenceItem[0][0][0]))\n",
    "differenceSeries=differenceBetweenTwoFrameForBatch(toTestDifferenceItem)\n",
    "logging.debug(fromAllToStr('differenceSeries.shape:',differenceSeries.shape,'toTestDifferenceItem.shape:',\\\n",
    "                          toTestDifferenceItem.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-21 15:04:42,320 -1 - <module> - INFO - test\n",
      "2020-07-21 15:04:42,322 -3 - <module> - DEBUG - tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "logging.info('test')\n",
    "logTensor=torch.zeros(3,3)\n",
    "logging.debug(str(logTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-21 15:04:42,328 -2 - <module> - DEBUG - tensor([0.0164, 0.6609, 0.1991, 0.0609, 0.6587, 0.5410])\n",
      "2020-07-21 15:04:42,330 -3 - <module> - DEBUG - tensor([[0.0164, 0.6609, 0.1991, 0.0609, 0.6587, 0.5410],\n",
      "        [0.0164, 0.6609, 0.1991, 0.0609, 0.6587, 0.5410],\n",
      "        [0.0164, 0.6609, 0.1991, 0.0609, 0.6587, 0.5410]])\n"
     ]
    }
   ],
   "source": [
    "testTensor=torch.rand((6))\n",
    "logging.debug(testTensor)\n",
    "logging.debug(testTensor.expand(3,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test seq2seq relation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#test code\n",
    "if runSeq2SeqRelationModel:\n",
    "    outputTimeFrame=5\n",
    "    RelationLSTMSeq2SeqModel=RelationLSTMSeq2Seq(outputTimeFrame=outputTimeFrame)\n",
    "    datasetV3Instance=tensorsDatasetV3(trajectoryFileList,lableTensorEachBatch=outputTimeFrame)\n",
    "    datasetV3Loader=DataLoader(datasetV3Instance,batch_size=2)\n",
    "    V3iter=iter(datasetV3Loader)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#test code\n",
    "if runSeq2SeqRelationModel:\n",
    "    RelationLSTMSeq2SeqModel=RelationLSTMSeq2Seq(outputTimeFrame=outputTimeFrame)\n",
    "    inputs, labels=V3iter.__next__()\n",
    "    inputs=fromObjectsToRelationPairsBatchAndTimestepVersion(inputs)\n",
    "    outputs=RelationLSTMSeq2SeqModel(inputs)\n",
    "    print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading model and dataset\n",
    "if runSeq2SeqRelationModel:\n",
    "    epochs=500\n",
    "    itersInEachEpoch=100\n",
    "    outputTimeFrame=5\n",
    "    relationLSTMSeq2SeqModel=RelationLSTMSeq2Seq(outputTimeFrame=outputTimeFrame)\n",
    "    datasetV3Instance=tensorsDatasetV3(trajectoryFileList,lableTensorEachBatch=outputTimeFrame)\n",
    "    datasetV3Loader=DataLoader(datasetV3Instance,batch_size=5,num_workers=4)\n",
    "    V3iter=iter(datasetV3Loader)\n",
    "    if useGpu:\n",
    "        relationLSTMSeq2SeqModel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runSeq2SeqRelationModel:\n",
    "    if not isTest:\n",
    "        learningRate=1e-3\n",
    "        lossFn=elementWeightedLoss(100,0.1,0.1)\n",
    "        lambdaWholeNet=lambda epoch: 0.5**(epoch//30)\n",
    "        optim=torch.optim.RMSprop([{'params':relationLSTMSeq2SeqModel.parameters(),'initial_lr':learningRate}],lr=learningRate)\n",
    "        lrSchedule=torch.optim.lr_scheduler.LambdaLR(optim,lambdaWholeNet,last_epoch=10)\n",
    "        relationLSTMSeq2SeqModel.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training seq2seqRelation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runSeq2SeqRelationModel:\n",
    "    if not isTest:\n",
    "        for epoch in range(epochs):\n",
    "            for iteration in range(itersInEachEpoch):\n",
    "                try:\n",
    "                    inputs, labels=V3iter.__next__()\n",
    "                except StopIteration:\n",
    "                    V3iter=iter(datasetV3Loader)\n",
    "                    inputs, labels=V3iter.__next__()\n",
    "                inputs=fromObjectsToRelationPairsBatchAndTimestepVersion(inputs)\n",
    "                labels=labels.permute(0,1,3,2)\n",
    "                if useGpu:\n",
    "                    inputs=Variable(inputs.cuda())\n",
    "                    labels=Variable(labels.cuda())\n",
    "                outputs=relationLSTMSeq2SeqModel(inputs)\n",
    "                print('compare the shape of outputs and labels:',outputs.shape, labels.shape)\n",
    "                loss=lossFn(outputs,labels)\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                print('loss in opoch ',epoch,',iteration',iteration,':',loss)\n",
    "            lrSchedule.step()\n",
    "            if epoch%10==0:\n",
    "                torch.save(relationLSTMSeq2SeqModel.state_dict(),\\\n",
    "                           'relationLSTMSeq2SeqMode_in_epoch_weightedLoss_'+str(epoch)+'.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing seq2seqRelation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetV3Loader=DataLoader(datasetV3Instance,batch_size=2,num_workers=4)\n",
    "V3iter=iter(datasetV3Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 6, 250]) torch.Size([5, 5, 6, 250])\n",
      "torch.Size([5, 10, 62250, 12])\n",
      "in seq2seq, inputs shape: torch.Size([5, 10, 62250, 12])\n",
      "torch.Size([5, 5, 250, 6])\n"
     ]
    }
   ],
   "source": [
    "if isTest:\n",
    "    relationLSTMSeq2SeqModel.eval()\n",
    "    with torch.no_grad():\n",
    "        relationLSTMSeq2SeqModel.load_state_dict(torch.load('relationLSTMSeq2SeqMode_in_epoch_weightedLoss_80.pt'))\n",
    "#         inputs,labels=V3iter.__next__()\n",
    "        itemIndex=8000\n",
    "        inputs,labels=datasetV3Instance.__getitem__(itemIndex)\n",
    "        inputs=inputs.unsqueeze(0)\n",
    "        labels=labels.unsqueeze(0)\n",
    "        for ii in range(4):\n",
    "            newInput, newLabel=datasetV3Instance.__getitem__(itemIndex+ii)\n",
    "            newInput=newInput.unsqueeze(0)\n",
    "            newLabel=newLabel.unsqueeze(0)\n",
    "            inputs=torch.cat((inputs,newInput),0)\n",
    "            labels=torch.cat((labels,newLabel),0)\n",
    "            \n",
    "        print(inputs.shape,labels.shape)\n",
    "\n",
    "        inputs=fromObjectsToRelationPairsBatchAndTimestepVersion(inputs)\n",
    "        print(inputs.shape)\n",
    "        labels=labels.permute(0,1,3,2)\n",
    "        outputs=relationLSTMSeq2SeqModel(inputs)\n",
    "        print(outputs.shape)\n",
    "        normalizationDict=datasetV3Instance.getNormalizationDict()\n",
    "        for i in range(labels.shape[1]):\n",
    "            resultImage=visualizeTensorData(outputs[0,i,:,0],outputs[0,i,:,1],normalizationDict=normalizationDict)\n",
    "            fileName='./predictWithRelationSeq2Seq/'+str(i)+'.png'\n",
    "            cv2.imwrite(fileName,resultImage)\n",
    "            resultImage=visualizeTensorData(labels[0,i,:,0],labels[0,i,:,1],normalizationDict=normalizationDict)\n",
    "            fileName='./predictWithRelationSeq2Seq/'+'l'+str(i)+'.png'\n",
    "            cv2.imwrite(fileName,resultImage)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test lstm relation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start test lstm relation model\n"
     ]
    }
   ],
   "source": [
    "print('start test lstm relation model')\n",
    "if runRelationLSTM:\n",
    "    datasetV3Instance=tensorsDatasetV3(trajectoryFileList)\n",
    "    datasetV3Loader=DataLoader(datasetV3Instance,batch_size=2)\n",
    "    V3iter=iter(datasetV3Loader)\n",
    "    relationLSTMInstance=RelationLSTM()\n",
    "    if useGpu:\n",
    "        relationLSTMInstance.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "def calculateXandN(x,n):\n",
    "    return (1+x)/(n+1+2*x)\n",
    "ns=[]\n",
    "xs=[]\n",
    "for i in range(0,100):\n",
    "    xs.append(i)\n",
    "for i in range(0,10):\n",
    "    ns.append(i)\n",
    "lines=[]\n",
    "for i in range(20):\n",
    "    lines.append([])\n",
    "for x in xs:\n",
    "    for n in ns:\n",
    "        lines[n].append(calculateXandN(x,n))\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(241)\n",
    "plt.plot(xs,lines[0],'b')\n",
    "plt.plot(xs,lines[1],'g')\n",
    "plt.plot(xs,lines[2],'k')\n",
    "plt.plot(xs,lines[3],'y')\n",
    "plt.plot(xs,lines[4],'m')\n",
    "plt.plot(xs,lines[5],'-')\n",
    "plt.subplot(242)\n",
    "plt.plot(ns,lines[0],'b')\n",
    "plt.subplot(243)\n",
    "plt.plot(ns,lines[1],'b')\n",
    "plt.subplot(244)\n",
    "plt.plot(ns,lines[2],'b')\n",
    "plt.subplot(245)\n",
    "plt.plot(ns,lines[3],'b')\n",
    "plt.subplot(246)\n",
    "plt.plot(ns,lines[4],'b')\n",
    "plt.subplot(247)\n",
    "plt.plot(ns,lines[5],'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training relation lstm\n",
    "if runRelationLSTM:\n",
    "    if not isTest:\n",
    "        learningRate=1e-3\n",
    "        MSELoss=nn.MSELoss()\n",
    "        lambdaWholeNet=lambda epoch: 0.5**(epoch//30)\n",
    "        optim=torch.optim.RMSprop([{'params':relationLSTMInstance.parameters(),'initial_lr':learningRate}],lr=learningRate)\n",
    "        lrSchedule=torch.optim.lr_scheduler.LambdaLR(optim,lambdaWholeNet,last_epoch=10)\n",
    "        relationLSTMInstance.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "label.shape torch.Size([2, 10, 6, 250])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangyuchen/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/wangyuchen/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "torch.Size([2, 10, 62250, 12])\n",
      "output.shape torch.Size([2, 250, 6])\n",
      "epoch  0  i 1  loss tensor(0.0382, grad_fn=<MseLossBackward>)\n",
      "label.shape torch.Size([2, 10, 6, 250])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "torch.Size([2, 10, 62250, 12])\n",
      "output.shape torch.Size([2, 250, 6])\n",
      "epoch  0  i 2  loss tensor(0.0286, grad_fn=<MseLossBackward>)\n",
      "label.shape torch.Size([2, 10, 6, 250])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "torch.Size([2, 10, 62250, 12])\n",
      "output.shape torch.Size([2, 250, 6])\n",
      "epoch  0  i 3  loss tensor(0.0229, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-c7320c2e96b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#             outputView=output.reshape((7,6,250)).cpu()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if runRelationLSTM:\n",
    "    #training relation lstm\n",
    "    if not runOnG814:\n",
    "        %matplotlib inline\n",
    "    from IPython.display import clear_output\n",
    "    normalizationDict=datasetV3Instance.getNormalizationDict()\n",
    "    optim.zero_grad()\n",
    "    if not isTest:  \n",
    "        losses=[]\n",
    "        iterInEpoch=50\n",
    "        for epoch in range(5):\n",
    "            print(epoch)\n",
    "            i=0\n",
    "            for inputs,label in V3iter:\n",
    "                i=i+1\n",
    "                if i>iterInEpoch*(epoch+1):\n",
    "                    break\n",
    "        #         print(i)\n",
    "                inputs=fromObjectsToRelationPairsBatchAndTimestepVersion(inputs)\n",
    "                print('label.shape',label.shape)\n",
    "                label=label[:,0,:,:].squeeze()\n",
    "                label=label.permute(0,2,1)\n",
    "#                 label=label[:,tupleForEachVehicle,0:6]\n",
    "                if useGpu:\n",
    "                    inputs=Variable(inputs.cuda())\n",
    "                    label=Variable(label.cuda())\n",
    "                output=relationLSTMInstance(inputs)\n",
    "\n",
    "        #         print(output[0,0:10,:],secondObjects[0,0:10,:])\n",
    "                print('output.shape',output.shape)\n",
    "                loss=MSELoss(output,label)\n",
    "                if i<5:\n",
    "                    print('epoch ',epoch, ' i', i,' loss',loss)\n",
    "        #         print(loss)\n",
    "                losses.append(loss.item())\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "    #             outputView=output.reshape((7,6,250)).cpu()\n",
    "    #             for j in range(10):\n",
    "    #                 inputs=inputs.cpu()\n",
    "    #                 resultImage=visualizeTensorData(inputs[0,j,0,:],inputs[0,j,1,:],normalizationDict=normalizationDict)\n",
    "    #                 fileName='./predictWithRelationLSTM/'+str((epoch+1)*10000000+i*100000+j)+'.png'\n",
    "    #                 cv2.imwrite(fileName,resultImage)\n",
    "    #             resultImage=visualizeTensorData(outputView[0,0,:],outputView[0,1,:],normalizationDict=normalizationDict)\n",
    "    #             fileName='./predictWithLSTMOnly/'+str((epoch+1)*10000000+i*100000+50)+'.png' #the predicted image is named with string which last two number is 50(because j < 50)\n",
    "    #             cv2.imwrite(fileName,resultImage)\n",
    "            lrSchedule.step()\n",
    "        plt.figure(figsize=(30,30))\n",
    "        plt.plot(losses)\n",
    "        plt.savefig('./losses.png')\n",
    "        torch.save(relationLSTMInstance.state_dict(),'./relationLSTM.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test relation-object model over a period of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runObjectRelationNet:\n",
    "    normalizationDict=datasetV2.getNormalizationDict()\n",
    "\n",
    "    datas=[]\n",
    "    for i in range(0,6):\n",
    "        break\n",
    "        datas.append([])\n",
    "    for ii in range(0,2000):\n",
    "        break\n",
    "        theInput,second=datasetV2.__getitem__(ii)\n",
    "        theInput=theInput.unsqueeze(0)\n",
    "        second=second.unsqueeze(0)\n",
    "        #         print(i)\n",
    "        #         theInput,second=item\n",
    "        if useGpu:\n",
    "            theInput=Variable(theInput.cuda())\n",
    "            second=Variable(second.cuda())\n",
    "        inputObjects=theInput[:,tupleForEachVehicle,0:6]\n",
    "        secondObjects=second[:,tupleForEachVehicle,0:6]\n",
    "        for i in range(0,6):\n",
    "            datas[i].append(inputObjects[0,0,i])\n",
    "    #     print('inputObjects.shape',inputObjects.shape)\n",
    "    #     resultImage=visualizeTensorData(inputObjects[0,:,0].cpu(),inputObjects[0,:,1].cpu(),normalizationDict=normalizationDict)\n",
    "    #     fileName='./resultImage/'+str(ii)+'.png'\n",
    "    #     cv2.imwrite(fileName,resultImage)\n",
    "    timeStamp=int(time.time())\n",
    "    dirName='resultImage'+str(timeStamp)\n",
    "    os.mkdir(dirName)\n",
    "    if isTest:\n",
    "        with torch.no_grad():\n",
    "            wholeNet.eval()\n",
    "            theInput,second=datasetV2.__getitem__(5000)\n",
    "            theInput=theInput.unsqueeze(0)\n",
    "            second=second.unsqueeze(0)\n",
    "        #         print(i)\n",
    "    #         theInput,second=item\n",
    "            if useGpu:\n",
    "                theInput=Variable(theInput.cuda())\n",
    "                second=Variable(second.cuda())\n",
    "            inputObjects=theInput[:,tupleForEachVehicle,0:6]\n",
    "            secondObjects=second[:,tupleForEachVehicle,0:6]\n",
    "            print('inputObjects.shape',inputObjects.shape)\n",
    "            resultImage=visualizeTensorData(inputObjects[0,:,0].cpu(),inputObjects[0,:,1].cpu(),normalizationDict=normalizationDict)\n",
    "            fileName='./resultImage/'+'0000000000000000'+'.png'\n",
    "            cv2.imwrite(fileName,resultImage)\n",
    "            stepInput=fromObjectsToRelationPairs(inputObjects[0].permute(1,0)).unsqueeze(0)\n",
    "        #             output=wholeNet(theInput)\n",
    "            print(stepInput.shape)\n",
    "        #             print(output.shape)\n",
    "            #predict step by step\n",
    "            for step in range(500):\n",
    "                output=wholeNet(stepInput)\n",
    "                print('step: ',step)\n",
    "                for ii in range(output.shape[1]):\n",
    "                    print(output[0,ii])\n",
    "    #             break\n",
    "    #             for j in range(10):\n",
    "    #                 print(stepInput[:,tupleForEachVehicle,0:6][0,j,:])\n",
    "    #                 print(output[0,j,:])\n",
    "    #                 print()\n",
    "                stepInput=fromObjectsToRelationPairs(output[0].permute(1,0)).unsqueeze(0)\n",
    "    #             print('outputShape',output.shape)\n",
    "    #             print('outputshape[0]',output[0].shape)\n",
    "                resultImage=visualizeTensorData(output[0,:,0].cpu(),output[0,:,1].cpu(),normalizationDict=normalizationDict)\n",
    "\n",
    "                import os\n",
    "                fileName='./'+dirName+'/'+str(1000000+step)+'.png'\n",
    "                cv2.imwrite(fileName,resultImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training and testing process for 'fromRelationToObjectnetwork'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runObjectRelationNet:\n",
    "    #generate a tuple in which each element is the index of a vehicle\n",
    "    #the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "    listForEachVehicle=[]\n",
    "    for i in range(maxMatrixIndex):\n",
    "        listForEachVehicle.append(i*(maxMatrixIndex-1))\n",
    "    tupleForEachVehicle=tuple(listForEachVehicle)\n",
    "\n",
    "    dataloaderV2=DataLoader(datasetV2,batch_size=1,shuffle=True)\n",
    "\n",
    "\n",
    "    wholeNet=fromRelationToObjectNetwork()\n",
    "    if isTest:\n",
    "        wholeNet.load_state_dict(torch.load(modelPath))\n",
    "\n",
    "\n",
    "    if useGpu:\n",
    "        wholeNet.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runObjectRelationNet:\n",
    "    if not isTest:\n",
    "        learningRate=1e-3\n",
    "        MSELoss=nn.MSELoss()\n",
    "        lambdaWholeNet=lambda epoch: 0.5**(epoch//30)\n",
    "        optim=torch.optim.RMSprop([{'params':wholeNet.parameters(),'initial_lr':learningRate}],lr=learningRate)\n",
    "        lrSchedule=torch.optim.lr_scheduler.LambdaLR(optim,lambdaWholeNet,last_epoch=10)\n",
    "        wholeNet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if runObjectRelationNet:\n",
    "    if not runOnG814:\n",
    "        %matplotlib inline\n",
    "    from IPython.display import clear_output\n",
    "    if not isTest:  \n",
    "        losses=[]\n",
    "        iterInEpoch=50\n",
    "        for epoch in range(300):\n",
    "            print(epoch)\n",
    "            for i,item in enumerate(dataloaderV2):\n",
    "                if i>iterInEpoch:\n",
    "                    break\n",
    "        #         print(i)\n",
    "                theInput,second=item\n",
    "                if useGpu:\n",
    "                    theInput=Variable(theInput.cuda())\n",
    "                    second=Variable(second.cuda())\n",
    "                secondObjects=second[:,tupleForEachVehicle,0:6]\n",
    "\n",
    "                output=wholeNet(theInput)\n",
    "        #         print(output[0,0:10,:],secondObjects[0,0:10,:])\n",
    "                loss=MSELoss(output,secondObjects)\n",
    "                if i<5:\n",
    "                    print('epoch ',epoch, ' i', i,' loss',loss)\n",
    "        #         print(loss)\n",
    "                losses.append(loss.item())\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "            lrSchedule.step()\n",
    "        plt.figure(figsize=(30,30))\n",
    "        plt.plot(losses)\n",
    "        plt.savefig('./losses.png')\n",
    "        torch.save(wholeNet.state_dict(),'./wholeNet_300epoch_50perEpoch.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training simple LSTM module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runLSTM:\n",
    "    #lstm version \n",
    "    if not isTest:\n",
    "        learningRate=1e-3\n",
    "        MSELoss=nn.MSELoss()\n",
    "        lambdaWholeNet=lambda epoch: 0.5**(epoch//30)\n",
    "        optim=torch.optim.RMSprop([{'params':lstmModel.parameters(),'initial_lr':learningRate}],lr=learningRate)\n",
    "        lrSchedule=torch.optim.lr_scheduler.LambdaLR(optim,lambdaWholeNet,last_epoch=10)\n",
    "        lstmModel.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if runLSTM:\n",
    "    #lstm version\n",
    "    if not runOnG814:\n",
    "        %matplotlib inline\n",
    "    from IPython.display import clear_output\n",
    "    normalizationDict=datasetV3.getNormalizationDict()\n",
    "    if not isTest:  \n",
    "        losses=[]\n",
    "        iterInEpoch=50\n",
    "        for epoch in range(5):\n",
    "            print(epoch)\n",
    "            i=0\n",
    "            for inputs,label in iterV3:\n",
    "                i=i+1\n",
    "                if i>iterInEpoch*(epoch+1):\n",
    "                    break\n",
    "        #         print(i)\n",
    "                if useGpu:\n",
    "                    inputs=Variable(inputs.cuda())\n",
    "                    label=Variable(label.cuda())\n",
    "                output=lstmModel(inputs.reshape((inputs.shape[0],inputs.shape[1],-1)))\n",
    "\n",
    "        #         print(output[0,0:10,:],secondObjects[0,0:10,:])\n",
    "                loss=MSELoss(output,label.squeeze().reshape((label.shape[0],-1)))\n",
    "                if i<5:\n",
    "                    print('epoch ',epoch, ' i', i,' loss',loss)\n",
    "        #         print(loss)\n",
    "                losses.append(loss.item())\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                outputView=output.reshape((7,6,250)).cpu()\n",
    "                for j in range(10):\n",
    "                    inputs=inputs.cpu()\n",
    "                    resultImage=visualizeTensorData(inputs[0,j,0,:],inputs[0,j,1,:],normalizationDict=normalizationDict)\n",
    "                    fileName='./predictWithLSTMOnly/'+str((epoch+1)*10000000+i*100000+j)+'.png'\n",
    "                    cv2.imwrite(fileName,resultImage)\n",
    "                resultImage=visualizeTensorData(outputView[0,0,:],outputView[0,1,:],normalizationDict=normalizationDict)\n",
    "                fileName='./predictWithLSTMOnly/'+str((epoch+1)*10000000+i*100000+50)+'.png' #the predicted image is named with string which last two number is 50(because j < 50)\n",
    "                cv2.imwrite(fileName,resultImage)\n",
    "            lrSchedule.step()\n",
    "        plt.figure(figsize=(30,30))\n",
    "        plt.plot(losses)\n",
    "        plt.savefig('./losses.png')\n",
    "        torch.save(wholeNet.state_dict(),'./wholeNet_300epoch_50perEpoch.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#draw properties of a single tensor over time\n",
    "#output results step by step\n",
    "plt.subplot(321)\n",
    "plt.plot(datas[0])\n",
    "plt.subplot(322)\n",
    "plt.plot(datas[1])\n",
    "plt.subplot(323)\n",
    "plt.plot(datas[2])\n",
    "plt.subplot(324)\n",
    "plt.plot(datas[3])\n",
    "plt.subplot(325)\n",
    "plt.plot(datas[4])\n",
    "plt.subplot(326)\n",
    "plt.plot(datas[5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
