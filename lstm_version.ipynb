{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import threading\n",
    "from multiprocessing import Process\n",
    "from multiprocessing import Manager\n",
    "from tensorboardX import SummaryWriter\n",
    "#global variable\n",
    "doNormalization=True\n",
    "useGpu=True\n",
    "runOnG814=False\n",
    "isTest=True\n",
    "modelPath='/home/wangyuchen/wholeNet_300epoch_50perEpoch.pt'\n",
    "maxMatrixIndex=250\n",
    "runRelationLSTM=False\n",
    "runObjectRelationNet=False\n",
    "runSeq2SeqRelationModel=False\n",
    "runLSTM=False\n",
    "runDifferenceLSTMModel=True\n",
    "\n",
    "\n",
    "\n",
    "maxRelationsNumberGlobal=20 # the maximum nubmer of relation in the \"relation within the given range\" version \n",
    "\n",
    "if useGpu:\n",
    "    import os\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fromAllToStr(*args):\n",
    "    returnedStr=str()\n",
    "    for eachItem in args:\n",
    "        returnedStr=returnedStr+str(eachItem)\n",
    "    return returnedStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename='logging.txt',level=logging.DEBUG, format='%(asctime)s -%(lineno)d - %(funcName)s - %(levelname)s - %(message)s',)\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s -%(lineno)d - %(funcName)s - %(levelname)s - %(message)s')\n",
    "console.setFormatter(formatter)\n",
    "logging.getLogger('').addHandler(console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a tuple in which each element is the index of a vehicle\n",
    "#the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "listForEachVehicle=[]\n",
    "for i in range(maxMatrixIndex):\n",
    "    listForEachVehicle.append(i*(maxMatrixIndex-1))\n",
    "tupleForEachVehicle=tuple(listForEachVehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def getValueByLable(lableList,valueList):\n",
    "    \"\"\"\n",
    "    For instance, given a lable list ['Local_X','Local_Y'] and a value list [2.0, 24.0, 437.0, 1118846981300.0, 16.254, \n",
    "    79.349, 6451167.199, 1873312.382, 14.5, 4.9, 2.0, 39.14, -5.73, 2.0, 0.0, 13.0, 0.0, 0.0] which values sorted by the \n",
    "    order of allLableList below, the function return a value Dict {'Local_X':16.254, 'Local_Y':79.349}\n",
    "    Args:\n",
    "        lableList: the list of lables you've required, such as['Vehicle_ID', 'Total_Frames','Global_Time']\n",
    "        valueList: the list contains all legally value, sorted by:['Vehicle_ID', 'Frame_ID','Total_Frames','Global_Time','Local_X','Local_Y','Global_X','Global_Y',\\\n",
    "                      'v_Length','v_Width','v_Class','v_Vel','v_Acc','Lane_ID','Preceding','Following','Space_Headway',\\\n",
    "                      'Time_Headway']\n",
    "    Returns: \n",
    "        value dict of the input lables\n",
    "    For instance, given a lable list ['Local_X','Local_Y'] and a value list [2.0, 24.0, 437.0, 1118846981300.0, 16.254, \n",
    "    79.349, 6451167.199, 1873312.382, 14.5, 4.9, 2.0, 39.14, -5.73, 2.0, 0.0, 13.0, 0.0, 0.0] which values sorted by the \n",
    "    order of allLableList above, the function return a value List [16.254, 79.349]\n",
    "\n",
    "    \"\"\"\n",
    "    allLableList=['Vehicle_ID', 'Frame_ID','Total_Frames','Global_Time','Local_X','Local_Y','Global_X','Global_Y',\\\n",
    "                  'v_Length','v_Width','v_Class','v_Vel','v_Acc','Lane_ID','Preceding','Following','Space_Headway',\\\n",
    "                  'Time_Headway']\n",
    "    valueDictReturn={}\n",
    "    for lableItem in lableList:\n",
    "        valueDictReturn[lableItem]=valueList[allLableList.index(lableItem)]\n",
    "    return valueDictReturn\n",
    "\n",
    "def rearrangeDataByGlobalTime(allValueLists):\n",
    "    '''\n",
    "    Args:\n",
    "        allValueLists: all values have been read from a txt file which have already been converted to a list\n",
    "    Returns:\n",
    "        dict have been arranged by global time. One single global time generally contains several value lists.\n",
    "    '''\n",
    "    valueDict={}\n",
    "    for valueList in allValueLists:\n",
    "        dictKey=getValueByLable(['Global_Time'],valueList)['Global_Time']\n",
    "        if dictKey in valueDict:\n",
    "            # if dictKey already there, then add valueList to the list of the key\n",
    "            valueDict[dictKey].append(valueList)\n",
    "        else:\n",
    "            #else, create a list and append valueList on it\n",
    "            valueDict[dictKey]=[valueList]\n",
    "    return valueDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def readFirstFrame(matrixIndexAndVehicleIDRecordDictParam, valueLists):\n",
    "    \"\"\"\n",
    "    To generate the first set of tensors from the first frame\n",
    "    Args:\n",
    "        matrixIndexAndVehicleIDRecordDictParam: just as its name\n",
    "        valueLists: a list consists of all valuelist at one time\n",
    "    Returns:\n",
    "        several tensors arranged by: positionTensor, speedTensor, accTensor, angleTensor,newVehicleList(type:list)\n",
    "    \n",
    "    \"\"\"\n",
    "    maxMatrixIndex=matrixIndexAndVehicleIDRecordDictParam.keys().__len__()-1\n",
    "    #tensors initialize\n",
    "    positionTensor=torch.zeros(2,maxMatrixIndex)\n",
    "    speedTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    accTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    angleTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    newVehicleIDList=[]\n",
    "    curMatrixIndex=0\n",
    "    matrixIndexAndVehicleIDRecordDictParam['time']=getValueByLable([\"Global_Time\"],valueLists[0])['Global_Time']\n",
    "    #fill out all tensors\n",
    "    for eachValueList in valueLists:\n",
    "        #get values from eachValueList, generate dict\n",
    "        returnedEachValueDict=getValueByLable(['Vehicle_ID','Local_X','Local_Y','v_Vel','v_Acc'],eachValueList)\n",
    "        #assign to the curMatrixIndex-th row of corresponding tensor\n",
    "        #angle Tensor assignment is not neeed for the initial value of each element in it is already zero\n",
    "        positionTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['Local_X'],returnedEachValueDict['Local_Y']))\n",
    "        speedTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Vel']))\n",
    "        accTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Acc']))\n",
    "        #then handle the record matrix\n",
    "        matrixIndexAndVehicleIDRecordDictParam[curMatrixIndex]['Vehicle_ID']=returnedEachValueDict['Vehicle_ID']\n",
    "        matrixIndexAndVehicleIDRecordDictParam[curMatrixIndex]['refresh']=0\n",
    "        newVehicleIDList.append(copy.deepcopy(returnedEachValueDict['Vehicle_ID']))\n",
    "        curMatrixIndex=curMatrixIndex+1\n",
    "    return positionTensor,speedTensor,accTensor,angleTensor,newVehicleIDList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMatrixIndexByVehicleID(matrixIndexAndVehicleIDRecordDictParam, vehicle_ID):\n",
    "    for i in range(0, len(matrixIndexAndVehicleIDRecordDictParam)-1):\n",
    "        if matrixIndexAndVehicleIDRecordDictParam[i]['Vehicle_ID']==vehicle_ID:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def findEmptyMatrixIndex(matrixIndexAndVehicleIDRecordDictParam):\n",
    "    for i in range(0, len(matrixIndexAndVehicleIDRecordDictParam)-1):\n",
    "        if matrixIndexAndVehicleIDRecordDictParam[i]['Vehicle_ID']==-1:\n",
    "            #Vehicle_ID=-1 when there is no existed vehicle ID bounding to the index\n",
    "            return i\n",
    "    raise Exception(\"NO EMPTY ELEMENT IN MATRIX\")\n",
    "\n",
    "def readGeneralFrame(matrixIndexAndVehicleIDRecordDictParam, valueLists, prePositionTensor):\n",
    "    \"\"\"\n",
    "    To generate the first set of tensors from the general frame that have a preceding one.\n",
    "    In this version, we ignore the new vehicle appeared among a serial of frame.\n",
    "    Args:\n",
    "        matrixIndexAndVehicleIDRecordDictParam: just as its name\n",
    "        valueLists: a list consists of all valuelist at one time\n",
    "        prePositionTensor: positionTensor from the preceding frame, which is used to calculate angle tensor\n",
    "    Returns:\n",
    "        everal tensors arranged by: positionTensor, speedTensor, accTensor, angleTensor,newVehicleList(type:list),\n",
    "        vanishedVehicleList(type:list)\n",
    "    \n",
    "    \"\"\"\n",
    "    #tensors initialize\n",
    "    maxMatrixIndex=matrixIndexAndVehicleIDRecordDictParam.keys().__len__()-1\n",
    "    positionTensor=torch.zeros(2,maxMatrixIndex)\n",
    "    speedTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    accTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    angleTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    newVehicleIDList=[]\n",
    "    vanishedVehicleList=[]\n",
    "    curMatrixIndex=0\n",
    "    matrixIndexAndVehicleIDRecordDictParam['time']=getValueByLable([\"Global_Time\"],valueLists[0])['Global_Time']\n",
    "    #fill out all tensors\n",
    "    for eachValueList in valueLists:\n",
    "        #get values from eachValueList, generate dict\n",
    "        returnedEachValueDict=getValueByLable(['Vehicle_ID','Local_X','Local_Y','v_Vel','v_Acc'],eachValueList)\n",
    "        indexOfVehicle=findMatrixIndexByVehicleID(matrixIndexAndVehicleIDRecordDictParam,returnedEachValueDict['Vehicle_ID'])\n",
    "        if indexOfVehicle!=-1:\n",
    "        #if index exist then the vehicle already existed in the preceded frame\n",
    "            matrixIndexAndVehicleIDRecordDictParam[indexOfVehicle]['refresh']=1\n",
    "            curMatrixIndex=indexOfVehicle\n",
    "            #assign to the curMatrixIndex-th row of corresponding tensor\n",
    "            positionTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['Local_X'],returnedEachValueDict['Local_Y']))\n",
    "            speedTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Vel']))\n",
    "            accTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Acc']))\n",
    "            angleTensor[:,curMatrixIndex]=math.atan2(positionTensor[0,curMatrixIndex]-\\\n",
    "                                                     prePositionTensor[0,curMatrixIndex],\\\n",
    "                                                    positionTensor[1,curMatrixIndex]-prePositionTensor[1,curMatrixIndex])\n",
    "        else:\n",
    "            pass #ignore new vehicleID\n",
    "        #a new vehicle ID\n",
    "#             newVehicleIDList.append(copy.deepcopy(returnedEachValueDict['Vehicle_ID']))\n",
    "#             curMatrixIndex=findEmptyMatrixIndex(matrixIndexAndVehicleIDRecordDictParam)\n",
    "#             matrixIndexAndVehicleIDRecordDictParam[curMatrixIndex]['Vehicle_ID']=copy.deepcopy(returnedEachValueDict['Vehicle_ID'])\n",
    "#             matrixIndexAndVehicleIDRecordDictParam[curMatrixIndex]['refresh']=1\n",
    "#             #assign to the curMatrixIndex-th row of corresponding tensor\n",
    "#             positionTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['Local_X'],returnedEachValueDict['Local_Y']))\n",
    "#             speedTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Vel']))\n",
    "#             accTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Acc']))\n",
    "#             angleTensor[:,curMatrixIndex]=math.atan2(positionTensor[0,curMatrixIndex]-\\\n",
    "#                                                      prePositionTensor[0,curMatrixIndex],\\\n",
    "#                                                     positionTensor[1,curMatrixIndex]-prePositionTensor[1,curMatrixIndex])\n",
    "    for i in range(0,maxMatrixIndex):\n",
    "    #find vanished vehicle and remove from dict\n",
    "        if matrixIndexAndVehicleIDRecordDictParam[i]['refresh']==0:\n",
    "            #if refresh=0 then the corresponding vehicle ID was not found in this frame\n",
    "            vanishedVehicleList.append(copy.deepcopy(matrixIndexAndVehicleIDRecordDictParam[i]['Vehicle_ID']))\n",
    "            matrixIndexAndVehicleIDRecordDictParam[i]['refresh']=-1\n",
    "            matrixIndexAndVehicleIDRecordDictParam[i]['Vehicle_ID']=-1\n",
    "    \n",
    "    for i in range(0,maxMatrixIndex):\n",
    "    #set all refrshed which equivalent to 1 to 0 to prepare for the next frame\n",
    "        if matrixIndexAndVehicleIDRecordDictParam[i]['refresh']==1:\n",
    "                #if refresh=0 then the corresponding vehicle ID was not found in this frame\n",
    "                matrixIndexAndVehicleIDRecordDictParam[i]['refresh']=0\n",
    "\n",
    "    return positionTensor,speedTensor,accTensor,angleTensor,newVehicleIDList,vanishedVehicleList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as utils\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "if not runOnG814:\n",
    "    %matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fromDirGenerateDict(trajectoryDir):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        valueDict: the key is global time, and the value of each key contain SEVERAL LIST of properties, \n",
    "                   each list consist of all property of a single vehicle at one time.\n",
    "    \"\"\"\n",
    "    trajectoryDataFile=open(trajectoryDir)\n",
    "    count=0\n",
    "    allLineList=[]\n",
    "    count=0\n",
    "    for count,line in enumerate(trajectoryDataFile):\n",
    "        #read a single line, remove space and enter\n",
    "        lineList=line.split(' ')\n",
    "        try:\n",
    "            while True:\n",
    "                lineList.remove('')\n",
    "        except:\n",
    "            try:\n",
    "                lineList.remove('\\n')\n",
    "            except:\n",
    "                pass\n",
    "            pass\n",
    "        for i in range(0,lineList.__len__()):\n",
    "            # convert string to float\n",
    "            lineList[i]=float(lineList[i])\n",
    "        allLineList.append(lineList)\n",
    "    valueDict=rearrangeDataByGlobalTime(allLineList)\n",
    "    return valueDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxAndMinValueFromValueDict(valueDict,lableList):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        valueDict: each key in dict is global time, the value of each key is a list of all value at one time\n",
    "        lableList: lables from which you want to get the max and min value. the type of each value in the list \n",
    "                    is str.\n",
    "    Returns:\n",
    "        a dict, which has keys keys from the input lable list and the value of each key is a dict which formed\n",
    "        as 'max':value, 'min':value\n",
    "    \"\"\"\n",
    "    maxAndMinDict={}\n",
    "    keys=list(valueDict.keys())\n",
    "    for lable in lableList:\n",
    "        max=0\n",
    "        min=0 #speed,  positon are all from 0 to max, accelerate from - to +\n",
    "        for eachKey in keys:\n",
    "            valueLists=valueDict[eachKey]\n",
    "            for valueList in valueLists:\n",
    "                value=getValueByLable([lable],valueList)[lable]\n",
    "                if value>max:\n",
    "                    max=value\n",
    "                if value<min:\n",
    "                    min=value\n",
    "        maxAndMinDict[lable]={'max':max,'min':min}\n",
    "    return maxAndMinDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test function of finding the max and min value: block 1, get valueDict for saving time from file reaidng\n",
    "# valueDict=fromDirGenerateDict(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function of finding the max and min value: block 1, get valueDict for saving time from file reaidng\n",
    "# getMaxAndMinValueFromValueDict(valueDict,['Local_X','Local_Y','v_Acc','v_Vel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valueDict=fromDirGenerateDict(1)\n",
    "# theKey=list(valueDict.keys())[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeTensorData(xTensor,yTensor, maxLength=2500,maxWidth=100,blocksize=10,normalizationDict=False):\n",
    "    \"\"\"\n",
    "    visualize a frame on an white image\n",
    "    Args:\n",
    "        valueVisualize: a list of values, each item in the list can be obtained by function \n",
    "        getValueByLable\n",
    "    Returns:\n",
    "        the image of the input frame\n",
    "    \"\"\"\n",
    "    image=np.ones((maxLength,maxWidth,3),dtype=np.int8)\n",
    "    #set background to white\n",
    "    image=image*255\n",
    "#     figure=plt.figure(figsize=(10,50))\n",
    "#     axe=figure.add_subplot(1,1,1)\n",
    "    xLength=xTensor.shape[0] #the length of y is equivalent to x's\n",
    "#     print('length:',xLength)\n",
    "#     print('xTensor.shape',xTensor.shape)\n",
    "    if doNormalization&(normalizationDict is not False):\n",
    "        originalXTensor=torch.zeros(xLength)\n",
    "        originalYTensor=torch.zeros(xLength) #originalX and Y tensor share the same length\n",
    "        originalXTensor=torch.add(\\\n",
    "                                  torch.mul(xTensor,normalizationDict['positionXMax']-normalizationDict['positionXMin']),\\\n",
    "                                  torch.add(originalXTensor,normalizationDict['positionXMin'])\n",
    "                                 )\n",
    "        originalYTensor=torch.add(\\\n",
    "                                  torch.mul(yTensor,normalizationDict['positionYMax']-normalizationDict['positionYMin']),\\\n",
    "                                  torch.add(originalYTensor,normalizationDict['positionYMin'])\n",
    "                                 )\n",
    "        for i in range(xLength):\n",
    "            x=int(originalXTensor[i])\n",
    "            y=int(originalYTensor[i])\n",
    "            colorR=int((i*17+29)%255)\n",
    "            colorG=int((i*9++93)%255)\n",
    "            colorB=int((i*13+111)%255)\n",
    "            cv2.circle(image,(x,y),int(blocksize/2),(colorB,colorG,colorR),-1) #\n",
    "    #     axe.imshow(image)\n",
    "        return image\n",
    "        \n",
    "    \n",
    "    \n",
    "    for i in range(xLength):\n",
    "        x=int(xTensor[i])\n",
    "        y=int(yTensor[i])\n",
    "        colorR=int((i*17+29)%255)\n",
    "        colorG=int((i*9++93)%255)\n",
    "        colorB=int((i*13+111)%255)\n",
    "        cv2.circle(image,(x,y),int(blocksize/2),(colorB,colorG,colorR),-1) #\n",
    "#     axe.imshow(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeTrajectory(inputTensor, maxLength=2500, maxWidth=100,radius=5,thickness=2,normalizationDict=None, vehicleList=None):\n",
    "    \"\"\"\n",
    "    to visualize the trajectory of all or selected vehicles\n",
    "    Args:\n",
    "        inputTensor: Tensor to be visualized. The dimension of the tensor is supposed to be (batch, timestep, vehicles, properties)\n",
    "        vehicleList: If vehicleList is not none, visualize all vehicles; if not, then only visualize vehicles of the given number.\n",
    "    Returns:\n",
    "        imageList: the visualized results.\n",
    "    \"\"\"\n",
    "    imageList=[]\n",
    "    for image_i in range(inputTensor.shape[0]):\n",
    "        # set the horizontal image\n",
    "        image=np.ones((maxWidth,maxLength,3),dtype=np.int8)\n",
    "        #set background to white\n",
    "        image=image*255\n",
    "        imageList.append(image)\n",
    "    \n",
    "    if doNormalization&(normalizationDict is not False):\n",
    "        newInputTensor=torch.zeros(inputTensor.shape)\n",
    "        #To compute de-normalized x tensors\n",
    "        newInputTensor[:,:,:,0]=torch.add(\\\n",
    "                                  torch.mul(inputTensor[:,:,:,0],normalizationDict['positionXMax']-normalizationDict['positionXMin']),\\\n",
    "                                  normalizationDict['positionXMin']\n",
    "                                 )\n",
    "        newInputTensor[:,:,:,1]=torch.add(\\\n",
    "                                  torch.mul(inputTensor[:,:,:,1],normalizationDict['positionYMax']-normalizationDict['positionYMin']),\\\n",
    "                                  normalizationDict['positionYMin']\n",
    "                                 )\n",
    "        inputTensor=newInputTensor\n",
    "        \n",
    "    if vehicleList is None:\n",
    "        #vehicleList is none then visualize all vehicle\n",
    "        vehicleList=list(range(inputTensor.shape[2]))\n",
    "        \n",
    "    for batch_I in range(inputTensor.shape[0]):\n",
    "        for timestep_I in range(inputTensor.shape[1]):\n",
    "            for vehicle_I in vehicleList:\n",
    "                currentX=inputTensor[batch_I,timestep_I,vehicle_I,0]\n",
    "                currentY=inputTensor[batch_I,timestep_I,vehicle_I,1]\n",
    "                colorR=int((vehicle_I*17+29)%255)\n",
    "                colorG=int((vehicle_I*9++93)%255)\n",
    "                colorB=int((vehicle_I*13+111)%255)\n",
    "                cv2.circle(imageList[batch_I],(currentY,currentX),radius,(colorB,colorG,colorR),-1)\n",
    "                if timestep_I==0:\n",
    "                    continue\n",
    "                else:\n",
    "                    preX=inputTensor[batch_I,timestep_I-1,vehicle_I,0]\n",
    "                    preY=inputTensor[batch_I,timestep_I-1,vehicle_I,1]\n",
    "                    cv2.line(imageList[batch_I],(preY,preX),(currentY,currentX),(colorB, colorG, colorR),thickness=thickness)\n",
    "    return imageList  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "15\n",
      "<class 'list'>\n",
      "12983721908371293\n"
     ]
    }
   ],
   "source": [
    "test=list(range(20))\n",
    "print(test)\n",
    "print(test[15])\n",
    "print(type(test))\n",
    "\n",
    "test=None\n",
    "if test is None:\n",
    "    print(12983721908371293)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeTensorDataHorizontal(xTensor,yTensor, maxLength=2500,maxWidth=100,blocksize=10,normalizationDict=False):\n",
    "    \"\"\"\n",
    "    visualize a frame on an white image\n",
    "    Args:\n",
    "        valueVisualize: a list of values, each item in the list can be obtained by function \n",
    "        getValueByLable\n",
    "    Returns:\n",
    "        the image of the input frame\n",
    "    \"\"\"\n",
    "    image=np.ones((maxWidth,maxLength,3),dtype=np.int8)\n",
    "    #set background to white\n",
    "    image=image*255\n",
    "#     figure=plt.figure(figsize=(10,50))\n",
    "#     axe=figure.add_subplot(1,1,1)\n",
    "    xLength=xTensor.shape[0] #the length of y is equivalent to x's\n",
    "#     print('length:',xLength)\n",
    "#     print('xTensor.shape',xTensor.shape)\n",
    "    if doNormalization&(normalizationDict is not False):\n",
    "        originalXTensor=torch.zeros(xLength)\n",
    "        originalYTensor=torch.zeros(xLength) #originalX and Y tensor share the same length\n",
    "        originalXTensor=torch.add(\\\n",
    "                                  torch.mul(xTensor,normalizationDict['positionXMax']-normalizationDict['positionXMin']),\\\n",
    "                                  torch.add(originalXTensor,normalizationDict['positionXMin'])\n",
    "                                 )\n",
    "        originalYTensor=torch.add(\\\n",
    "                                  torch.mul(yTensor,normalizationDict['positionYMax']-normalizationDict['positionYMin']),\\\n",
    "                                  torch.add(originalYTensor,normalizationDict['positionYMin'])\n",
    "                                 )\n",
    "        for i in range(xLength):\n",
    "            x=int(originalXTensor[i])\n",
    "            y=int(originalYTensor[i])\n",
    "            colorR=int((i*17+29)%255)\n",
    "            colorG=int((i*9++93)%255)\n",
    "            colorB=int((i*13+111)%255)\n",
    "            cv2.circle(image,(y,x),int(blocksize/2),(colorB,colorG,colorR),-1) #\n",
    "    #     axe.imshow(image)\n",
    "        return image\n",
    "        \n",
    "    \n",
    "    \n",
    "    for i in range(xLength):\n",
    "        x=int(xTensor[i])\n",
    "        y=int(yTensor[i])\n",
    "        colorR=int((i*17+29)%255)\n",
    "        colorG=int((i*9++93)%255)\n",
    "        colorB=int((i*13+111)%255)\n",
    "        cv2.circle(image,(y,x),int(blocksize/2),(colorB,colorG,colorR),-1) #\n",
    "#     axe.imshow(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "if not runOnG814:\n",
    "    %matplotlib inline\n",
    "from IPython import display\n",
    "def visualizeData(valueVisualize, maxLength=1000,maxWidth=100,blocksize=10):\n",
    "    \"\"\"\n",
    "    visualize a frame on an white image\n",
    "    Args:\n",
    "        valueVisualize: a list of values, each item in the list can be obtained by function \n",
    "        getValueByLable\n",
    "    Returns:\n",
    "        the image of the input frame\n",
    "    \"\"\"\n",
    "    image=np.ones((maxLength,maxWidth,3),dtype=np.int8)\n",
    "    image=image*255\n",
    "#     figure=plt.figure(figsize=(10,50))\n",
    "#     axe=figure.add_subplot(1,1,1)\n",
    "    \n",
    "    for item in valueVisualize:\n",
    "        infoList=getValueByLable(['Vehicle_ID','Local_X','Local_Y'],item)\n",
    "        vehicleID=infoList['Vehicle_ID']\n",
    "        x=int(infoList['Local_X'])\n",
    "        y=int(infoList['Local_Y'])\n",
    "        colorR=int((vehicleID+100)%255)\n",
    "        colorG=int((vehicleID+150)%255)\n",
    "        colorB=int((vehicleID+200)%255)\n",
    "        cv2.circle(image,(x,y),int(blocksize/2),(colorB,colorG,colorR),-1) #\n",
    "#     axe.imshow(image)\n",
    "    return image\n",
    "# visualizeData(valueDict[theKey])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalEvaluation(resultTensor,labelTensor,normalizedDict=None,maxMatrixIndex=maxMatrixIndex):\n",
    "    \"\"\"\n",
    "    numericla evalution for models\n",
    "    REMOVE VELOCITY AND ACCELERATE FROM THE INPUT TENSOR IF THEY EXISTS IN THE INPUT TENSORS!!!\n",
    "    Args:\n",
    "        resultTensor: the predicted tensor of model, which dimension is (batch, timestep, vehicles, properties)\n",
    "        labelTensor: the label tensor from dataset, which dimension is (batch, timestep, vehicles, properties)\n",
    "        normalizedDict: the dict of normalization\n",
    "    Returns:\n",
    "        differenceEachVehicleEachFrame: the difference of each vehicle in each single frame\n",
    "        differenceEachVehicleAllFrame: the difference of each vehicle in all frame\n",
    "        averageDifferenceAllVehicleEachFrame: the average difference of all vehicle in each singel frame\n",
    "        averageDifferenceAllVehicleAllFrame: the average difference of all vehicle in over all frame\n",
    "    \"\"\"\n",
    "    differenceEachVehicleEachFrame=torch.abs(resultTensor-labelTensor)\n",
    "    differenceEachVehicleAllFrame=torch.sum(differenceEachVehicleEachFrame,dim=1,keepdim=True)\n",
    "    averageDifferenceAllVehicleEachFrame=torch.sum(differenceEachVehicleEachFrame,dim=2, keepdim=True)\n",
    "    averageDifferenceAllVehicleEachFrame=torch.div(averageDifferenceAllVehicleEachFrame,resultTensor.shape[2])\n",
    "    averageDifferenceAllVehicleAllFrame=torch.sum(averageDifferenceAllVehicleEachFrame,dim=1,keepdim=True)\n",
    "    return differenceEachVehicleEachFrame,differenceEachVehicleAllFrame,averageDifferenceAllVehicleEachFrame,\\\n",
    "            averageDifferenceAllVehicleAllFrame\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discountParameterByExponentialWithDistance(relationTensors, xfactor=1, yfactor=1, w1=1,w2=2,w3=1):\n",
    "    \"\"\"\n",
    "    to calculate a discount parameter matrix from the relations matrix of several vehicl pairs.\n",
    "    Args:\n",
    "        relationTensors: a vehicle pair is a \"relation\" in which two vehilce properties are of the same kind and order,\n",
    "        the relationTensors consists of many vehicle pairs. An extra dimension should be added to the a single vehicle pair\n",
    "        tensor if this function only take as a single vehicle pair. Generally, the relationTensors has to dimension:\n",
    "        the dimension of pairs, the properties of each pair.\n",
    "        xfactor,yfactor:  the weight of x part and y part\n",
    "        w1, w2,w3: facor in exponential operation, w1 and w2 relate to x and w3 relate to y\n",
    "    \"\"\"\n",
    "    vehiclePairDimension=relationTensors.shape[1] #the second dimension of relationTensors is the properties of each vehicle pair\n",
    "    relationsDimension=relationTensors.shape[0]\n",
    "    computationTensor=torch.zeros((relationsDimension,5)) #save the xDifference and yDifference for further computation\n",
    "    secondVehiclePropertyStartIndex=int((vehiclePairDimension)/2 )\n",
    "    logging.debug('secondVehiclePropertyStartIndex'+str(secondVehiclePropertyStartIndex))\n",
    "    \n",
    "    discountTensor=torch.zeros(relationsDimension)\n",
    "    for i in range(relationsDimension):\n",
    "        x1,y1,x2,y2=relationTensors[i][0],relationTensors[i][1],\\\n",
    "                    relationTensors[i][secondVehiclePropertyStartIndex],relationTensors[i][secondVehiclePropertyStartIndex+1]\n",
    "        if y2>=y1: #the second vehilce is in front of the first vehicle\n",
    "            yDifference=y2-y1\n",
    "            wy=w1\n",
    "        else: #the second vehicle is after the fist vehicle\n",
    "            yDifference=y1-y2\n",
    "            wy=w2\n",
    "        xDifference=abs(x1-x2)\n",
    "        wx=w3\n",
    "        computationTensor[i][0]=xDifference\n",
    "        computationTensor[i][1]=yDifference\n",
    "        computationTensor[i][2]=wx\n",
    "        computationTensor[i][3]=wy\n",
    "        if (x1==0 and y1==0)or(x2==0 and y2==0):\n",
    "            computationTensor[i][4]=0\n",
    "        else:\n",
    "            computationTensor[i][4]=1\n",
    "#         discountTensor[i]=(xfactor/math.exp(wx*(xDifference)))*(yfactor/math.exp(wx*(yDifference)))\n",
    "    logging.debug(fromAllToStr('computationTensor:\\n',computationTensor))\n",
    "    discountTensor=torch.mul(torch.mul((xfactor/torch.exp(torch.mul(computationTensor[:,0],computationTensor[:,2]))),\\\n",
    "                             (yfactor/torch.exp(torch.mul(computationTensor[:,1],computationTensor[:,3])))),\n",
    "                             computationTensor[:,4])\n",
    "    return discountTensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: property tensors, target vehicle ID\n",
    "#output: relations, distances between target vehicle and other vehicles which inside the range\n",
    "def relationCalculateWithRange(propertyTensors, distanceRange, targetVehicleId, maxRelationsNumber=maxRelationsNumberGlobal):\n",
    "    \"\"\"\n",
    "    NOTICE:THE PROPERTIES AND DISTANCE RANGE SHOULD BOTH BE NORMALIZED OR UNNORMALIZED!!!\n",
    "    Args:\n",
    "        propertyTensors:property tensors of all vehicles, at position 0 and 1 are the x and y positon of the \n",
    "        corresponding vehicle\n",
    "        distanceRange: the distance on which we decide to take other vehicles into account\n",
    "        targetVehicleId: the center vehicle which we are going to calculate\n",
    "    \"\"\"\n",
    "    propertyTensorsCopy=copy.deepcopy(propertyTensors)\n",
    "    propertiesDimension=propertyTensorsCopy.shape[0]\n",
    "    reservedIndexes=[]\n",
    "    reservedIndexDistanceDict={}\n",
    "    for i in range(maxMatrixIndex):\n",
    "        reservedIndexes.append(i)\n",
    "    #remove vehicles which position are out-of-range\n",
    "    for i in range(propertiesDimension):\n",
    "        #simply remove the out-of-ranged vehicles by comparing y-axis before computing the distance.\n",
    "        #since most vehicles are out of the given range, this would reduce time cost\n",
    "        if abs(propertyTensorsCopy[i][1]-propertyTensors[targetVehicleId][1])>distanceRange:\n",
    "            reservedIndexes.remove(i)\n",
    "        #to compute if vehicle in the range\n",
    "        else:\n",
    "            distance=((propertyTensorsCopy[i][0]-propertyTensors[targetVehicleId][0])**2+\\\n",
    "                (propertyTensorsCopy[i][1]-propertyTensors[targetVehicleId][1])**2)**0.5\n",
    "            if distance>distanceRange:\n",
    "                reservedIndexes.remove(i)\n",
    "            else:\n",
    "                reservedIndexDistanceDict[i]=distance\n",
    "    #sort dict by value, not by key\n",
    "    sortedReservedIndexDistanceDict=sorted(reservedIndexDistanceDict.items(),key=lambda item:(item[1],item[0]))\n",
    "    #keep the top 'maxRelationsNumber' nearest vehicles in the generated relations\n",
    "    if(sortedReservedIndexDistanceDict.__len__()>maxRelationsNumber):\n",
    "        for i in range(maxRelationsNumber,sortedReservedIndexDistanceDict.__len__()):\n",
    "            reservedIndexes.remove(sortedReservedIndexDistanceDict[i][0])\n",
    "    #the final properties tensor is:\n",
    "    finalPropertiesTensor=propertyTensorsCopy[reservedIndexes]\n",
    "    if(sortedReservedIndexDistanceDict.__len__()<maxRelationsNumber):\n",
    "        #make sure the length of all relation are equanl to the value of maxRelationNumber\n",
    "        zeroTensor=torch.zeros((maxRelationsNumber-finalPropertiesTensor.shape[0],finalPropertiesTensor.shape[1]))\n",
    "        finalPropertiesTensor=torch.cat((finalPropertiesTensor,\\\n",
    "                                         zeroTensor))\n",
    "    \n",
    "#     logging.debug('targetVehicleId'+str(targetVehicleId))\n",
    "#     logging.debug('reservedIndexes.__len__()'+str(reservedIndexes.__len__()))\n",
    "#     logging.debug('propertyTensors[targetVehicleId].shape[0]'+str(propertyTensors[targetVehicleId].shape[0]))\n",
    "    expandedTargetVehicleTensor=propertyTensors[targetVehicleId].expand(maxRelationsNumber,propertyTensors[targetVehicleId].shape[0])\n",
    "    relationTensor=torch.cat((expandedTargetVehicleTensor,finalPropertiesTensor),1)\n",
    "#     logging.debug('expandedTargetVehicleTensor:'+str(expandedTargetVehicleTensor))\n",
    "#     logging.debug('relationTensor:'+str(relationTensor))\n",
    "    return relationTensor\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: property tensors, target vehicle ID\n",
    "#output: relations, distances between target vehicle and other vehicles which inside the range\n",
    "def relationCalculateWithRangeInModel(propertyTensors, distanceRange, targetVehicleId, maxRelationsNumber=maxRelationsNumberGlobal):\n",
    "    \"\"\"\n",
    "    NOTICE:THE PROPERTIES AND DISTANCE RANGE SHOULD BOTH BE NORMALIZED OR UNNORMALIZED!!!\n",
    "    this function is employed in model computation, especially for cuda version\n",
    "    Args:\n",
    "        propertyTensors:property tensors of all vehicles, at position 0 and 1 are the x and y positon of the \n",
    "        corresponding vehicle\n",
    "        distanceRange: the distance on which we decide to take other vehicles into account\n",
    "        targetVehicleId: the center vehicle which we are going to calculate\n",
    "    \"\"\"\n",
    "    #edit tag: convert this function to cuda version and convert the relation and discount computation function to cuda version(or say the compute-in-model version)\n",
    "    propertyTensorsCopy=copy.deepcopy(propertyTensors)\n",
    "    propertiesDimension=propertyTensorsCopy.shape[0]\n",
    "    reservedIndexes=[]\n",
    "    reservedIndexDistanceDict={}\n",
    "    for i in range(maxMatrixIndex):\n",
    "        reservedIndexes.append(i)\n",
    "    #remove vehicles which position are out-of-range\n",
    "    for i in range(propertiesDimension):\n",
    "        #simply remove the out-of-ranged vehicles by comparing y-axis before computing the distance.\n",
    "        #since most vehicles are out of the given range, this would reduce time cost\n",
    "        if abs(propertyTensorsCopy[i][1]-propertyTensors[targetVehicleId][1])>distanceRange:\n",
    "            reservedIndexes.remove(i)\n",
    "        #to compute if vehicle in the range\n",
    "        else:\n",
    "            distance=((propertyTensorsCopy[i][0]-propertyTensors[targetVehicleId][0])**2+\\\n",
    "                (propertyTensorsCopy[i][1]-propertyTensors[targetVehicleId][1])**2)**0.5\n",
    "            if distance>distanceRange:\n",
    "                reservedIndexes.remove(i)\n",
    "            else:\n",
    "                reservedIndexDistanceDict[i]=distance\n",
    "    #sort dict by value, not by key\n",
    "    sortedReservedIndexDistanceDict=sorted(reservedIndexDistanceDict.items(),key=lambda item:(item[1],item[0]))\n",
    "    #keep the top 'maxRelationsNumber' nearest vehicles in the generated relations\n",
    "    if(sortedReservedIndexDistanceDict.__len__()>maxRelationsNumber):\n",
    "        for i in range(maxRelationsNumber,sortedReservedIndexDistanceDict.__len__()):\n",
    "            reservedIndexes.remove(sortedReservedIndexDistanceDict[i][0])\n",
    "    #the final properties tensor is:\n",
    "    finalPropertiesTensor=propertyTensorsCopy[reservedIndexes]\n",
    "    if(sortedReservedIndexDistanceDict.__len__()<maxRelationsNumber):\n",
    "        #make sure the length of all relation are equanl to the value of maxRelationNumber\n",
    "        zeroTensor=torch.zeros((maxRelationsNumber-finalPropertiesTensor.shape[0],finalPropertiesTensor.shape[1]))\n",
    "        finalPropertiesTensor=torch.cat((finalPropertiesTensor,\\\n",
    "                                         zeroTensor))\n",
    "    \n",
    "#     logging.debug('targetVehicleId'+str(targetVehicleId))\n",
    "#     logging.debug('reservedIndexes.__len__()'+str(reservedIndexes.__len__()))\n",
    "#     logging.debug('propertyTensors[targetVehicleId].shape[0]'+str(propertyTensors[targetVehicleId].shape[0]))\n",
    "    expandedTargetVehicleTensor=propertyTensors[targetVehicleId].expand(maxRelationsNumber,propertyTensors[targetVehicleId].shape[0])\n",
    "    relationTensor=torch.cat((expandedTargetVehicleTensor,finalPropertiesTensor),1)\n",
    "#     logging.debug('expandedTargetVehicleTensor:'+str(expandedTargetVehicleTensor))\n",
    "#     logging.debug('relationTensor:'+str(relationTensor))\n",
    "    return relationTensor\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeRelationAndAllTheOtherTensorsWithDistance(inputFrameTensor,theGivenRange,maxRelationsNumber=20):\n",
    "    '''\n",
    "        to generate relation tensors, discount parameter tensor with relations and the relation quantity tensor\n",
    "    of each vehicle\n",
    "    Args:\n",
    "        inputFrameTensor: vehicle properties graph, which dimension are (timestep, property, vehicle).\n",
    "        To illustrate the meaning of dimensions, supposing we have a inputFrameTensor which \n",
    "        timestep is 10, all vehicle have 6 properties and there are 250 vehicles, then the dimension of the \n",
    "        input tensor are(10, 6, 250)\n",
    "        theGivenRange: only take vehicle pairs which distance are inside the given range into account.\n",
    "    Returns:\n",
    "        relationTensor: the relation tensors of each vehicle pairs in the given range\n",
    "        discountParameterTensor: the discount tensor of each relation, computed by the distance between vehicle pairs\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    #circulation for batch list\n",
    "    logging.debug(fromAllToStr('inputFrameTensor.shape:',inputFrameTensor.shape))\n",
    "    timeStepSize=inputFrameTensor.shape[0]\n",
    "    for timeStepCount in range(0,timeStepSize):\n",
    "        for vehicleId in range(0, inputFrameTensor.shape[2]):\n",
    "            relationTensor=relationCalculateWithRange(inputFrameTensor[timeStepCount].permute(1,0),\n",
    "                                                      theGivenRange,vehicleId,maxRelationsNumber=maxRelationsNumber)\n",
    "            if vehicleId==0:\n",
    "                relationTensorInOneTimeStep=relationTensor\n",
    "            elif vehicleId>0:\n",
    "                relationTensorInOneTimeStep=torch.cat((relationTensorInOneTimeStep,relationTensor),dim=0)\n",
    "        logging.debug(fromAllToStr('relationTensorInOneTimeStep.shape:\\n',relationTensorInOneTimeStep.shape))\n",
    "        discountParameterTensorInOneTimeStep=discountParameterByExponentialWithDistance(relationTensorInOneTimeStep)\n",
    "        if timeStepCount==0:\n",
    "            relationTensorOfAllTimeSteps=relationTensorInOneTimeStep.unsqueeze(0)\n",
    "            discountParameterTensorofAllTimeSteps=discountParameterTensorInOneTimeStep.unsqueeze(0)\n",
    "        else:\n",
    "            relationTensorOfAllTimeSteps=\\\n",
    "            torch.cat((relationTensorOfAllTimeSteps,relationTensorInOneTimeStep.unsqueeze(0)),dim=0)\n",
    "            discountParameterTensorofAllTimeSteps=\\\n",
    "            torch.cat((discountParameterTensorofAllTimeSteps,discountParameterTensorInOneTimeStep.unsqueeze(0)),dim=0)\n",
    "    return relationTensorOfAllTimeSteps,discountParameterTensorofAllTimeSteps\n",
    "    \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1=torch.rand((6))\n",
    "tensor2=torch.rand((6))\n",
    "tensor3=torch.rand((6))\n",
    "tensor4=torch.stack((tensor1,tensor2,tensor3),dim=0)\n",
    "logging.debug(tensor1)\n",
    "logging.debug(tensor2)\n",
    "logging.debug(tensor3)\n",
    "logging.debug(tensor4)\n",
    "tensor5=torch.cat((tensor1.unsqueeze(0),tensor4),dim=0)\n",
    "logging.debug(tensor5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differenceBetweenTwoFrame(frameSeries):\n",
    "    \"\"\"\n",
    "    Given a series of frame, return the difference series of those frame. Since this function \n",
    "    compute diffrences by the gap between two adjacent frames, the quantity of frame in difference \n",
    "    series is one less than the input frame series\n",
    "    Args:\n",
    "        frameSeries: input frames, which dimension is (vehicleQuantity, vehicleProperties)\n",
    "    Returns:\n",
    "        the difference series, which first dimension (quantity dimension) is one less than input frame series.\n",
    "    \"\"\"\n",
    "    frameSeriesWithoutTheFirstFrame=frameSeries[1:]\n",
    "    frameSeriesWithoutTheLastFrame=frameSeries[0:-1]\n",
    "    logging.debug(str(frameSeriesWithoutTheFirstFrame))\n",
    "    logging.debug(str(frameSeriesWithoutTheLastFrame))\n",
    "    logging.debug(str(frameSeries))\n",
    "    differenceSeries=frameSeriesWithoutTheFirstFrame-frameSeriesWithoutTheLastFrame\n",
    "    return differenceSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differenceBetweenTwoFrameForTimeSteps(frameSeries):\n",
    "    \"\"\"\n",
    "    Given several time stpes of series of frame, return the difference series of all those frames. Since this function \n",
    "    compute diffrences by the gap between two adjacent frames, the quantity of frame in difference \n",
    "    series is one less than the input frame series\n",
    "    Args:\n",
    "        frameSeries: input frames, which dimension is (timeSteps,vehicleQuantity, vehicleProperties)\n",
    "    Returns:\n",
    "        differenceSeries:the difference series, which second dimension (quantity dimension) is one less than input frame series,\n",
    "        and the dimension of differenceSeries is (timeSteps, vehicleQuantity, vehiclePropertiesDifference)\n",
    "    \"\"\"\n",
    "    \n",
    "    frameSeriesWithoutTheFirstFrame=frameSeries[1:]\n",
    "    frameSeriesWithoutTheLastFrame=frameSeries[0:-1]\n",
    "    logging.debug(str(frameSeriesWithoutTheFirstFrame.shape))\n",
    "    logging.debug(str(frameSeriesWithoutTheLastFrame.shape))\n",
    "    logging.debug(str(frameSeries.shape))\n",
    "    differenceSeries=frameSeriesWithoutTheFirstFrame-frameSeriesWithoutTheLastFrame\n",
    "    return differenceSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputTensor=torch.rand((5,5))\n",
    "logging.debug(inputTensor)\n",
    "differenceBetweenTwoFrame(inputTensor)\n",
    "logging.debug(fromAllToStr('shapesize',inputTensor.shape.__len__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testExpand=torch.tensor(((1,2,3),(3,4,5))).expand(2,6)\n",
    "# print(testExpand)\n",
    "# theList=[1,2,3,5,7]\n",
    "# theList.remove(7)\n",
    "# d = {'lilee':25, 'wangyan':21, 'liqun':32, 'age':19}\n",
    "# print(d)\n",
    "# d=sorted(d.items(), key=lambda item:item[1])\n",
    "# print(d.__len__())\n",
    "# print(theList)\n",
    "# testTensor=torch.rand(10,10)\n",
    "# print(testTensor)\n",
    "# print(testTensor[[1,4,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save visulized images\n",
    "# for key in list(valueDict.keys())[1:10000]:\n",
    "#     image=visualizeData(valueDict[key])\n",
    "#     cv2.imwrite('visualizeFolder/image'+str(key)+'.png',image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tensorsDataset(Dataset):\n",
    "    def __init__(self, trajectoryFileList, numberOfTensorsEachBatch=100,lableTensorEachBatch=2):\n",
    "        if(numberOfTensorsEachBatch<5):\n",
    "            raise Exception(\"THE NUMBER OF TENSORS IN EACH BATCH IS TOO SMALL\")\n",
    "        self.valueDictList=[]\n",
    "        self.sizeList=[]\n",
    "        self.numberOfTensorsEachBatch=numberOfTensorsEachBatch\n",
    "        self.lableTensorEachBatch=lableTensorEachBatch\n",
    "        self.allTensorsEachBatch=numberOfTensorsEachBatch+lableTensorEachBatch\n",
    "        self.keysList=[]\n",
    "        for eachFile in trajectoryFileList:\n",
    "            valueDict=fromDirGenerateDict(eachFile)\n",
    "            self.valueDictList.append(copy.deepcopy(valueDict))\n",
    "            self.sizeList.append(valueDict.keys().__len__()-self.allTensorsEachBatch)\n",
    "            sortedKeys=list(valueDict.keys())\n",
    "            sortedKeys.sort()\n",
    "            self.keysList.append(copy.deepcopy(sortedKeys))\n",
    "\n",
    "    def __len__(self):\n",
    "        allLen=0\n",
    "        for length in self.sizeList:\n",
    "            allLen=allLen+length\n",
    "        return allLen\n",
    "    \n",
    "    def fromIdxMapToList(self,idx):\n",
    "        \"\"\"\n",
    "        since there are several lists,we have to know which list shoud we use and the ture index in the list\n",
    "        Return:\n",
    "            the trueIndex, listIndex\n",
    "        \"\"\"\n",
    "        countSection=0\n",
    "        for i in range(0,self.sizeList.__len__()):\n",
    "            countSection+=self.sizeList[i]\n",
    "            if(idx<countSection):\n",
    "                return idx-countSection+self.sizeList[i],i\n",
    "            \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        #initialize trueIndex, listIndex\n",
    "        #\n",
    "        #this dict record the relation between matrix index and vehicle ID in the last frame\n",
    "        matrixIndexAndVehicleIDRecordDict={}\n",
    "        #initialize dict above\n",
    "        for i in range(0,maxMatrixIndex):\n",
    "            matrixIndexAndVehicleIDRecordDict[i]={'Vehicle_ID':-1,'refresh':-1}\n",
    "        matrixIndexAndVehicleIDRecordDict['time']=-1\n",
    "        trueIndex,listIndex=self.fromIdxMapToList(idx)\n",
    "        itemDict={'positionTensorList':[],'speedTensorList':[],'accTensorList':[],'angleTensorList':[],'time':[]}\n",
    "        valueDict=self.valueDictList[listIndex] #valueDict is the Dict of many frames\n",
    "        dictKeys=self.keysList[listIndex]\n",
    "        #generate tensors of first frame\n",
    "        positionTensor,speedTensor,accTensor,angleTensor,newVehicleList\\\n",
    "        =readFirstFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[trueIndex]])\n",
    "        angleSinTensor=torch.sin(angleTensor)\n",
    "        angleCosTensor=torch.cos(angleTensor)\n",
    "        combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                 speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                 accTensor.mul(angleCosTensor)),0)\n",
    "        allCombineTensorTrain=combinedTensor.unsqueeze(0)\n",
    "        allCombineTensorValid=0\n",
    "#         itemDict['positionTensorList'].append(positionTensor)\n",
    "#         itemDict['speedTensorList'].append(speedTensor)\n",
    "#         itemDict['accTensorList'].append(accTensor)\n",
    "#         itemDict['angleTensorList'].append(angleTensor)\n",
    "#         time=getValueByLable(['Global_Time'],valueDict[dictKeys[trueIndex]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]][0]\n",
    "#         itemDict['time'].append(time)\n",
    "        \n",
    "        for i in range(trueIndex+1,trueIndex+self.allTensorsEachBatch):\n",
    "            #generate tensor from general frame\n",
    "            positionTensor,speedTensor,accTensor,angleTensor,newVehicleList,vanishedVehicleList\\\n",
    "            =readGeneralFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[i]],positionTensor)\n",
    "            angleSinTensor=torch.sin(angleTensor)\n",
    "            angleCosTensor=torch.cos(angleTensor)\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "            if i<self.numberOfTensorsEachBatch+trueIndex:\n",
    "                allCombineTensorTrain=torch.cat((allCombineTensorTrain,combinedTensor.unsqueeze(0)),0)\n",
    "            elif i==self.numberOfTensorsEachBatch+trueIndex:\n",
    "                allCombineTensorValid=combinedTensor.unsqueeze(0)\n",
    "            else:\n",
    "                allCombineTensorValid=torch.cat((allCombineTensorValid,combinedTensor.unsqueeze(0)),0)\n",
    "#             itemDict['positionTensorList'].append(positionTensor)\n",
    "#             itemDict['speedTensorList'].append(speedTensor)\n",
    "#             itemDict['accTensorList'].append(accTensor)\n",
    "#             itemDict['angleTensorList'].append(angleTensor)\n",
    "#             time=getValueByLable(['Global_Time'],valueDict[dictKeys[i]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]]\n",
    "#             itemDict['time'].append(time)\n",
    "        return allCombineTensorTrain,allCombineTensorValid\n",
    "# trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0805am-0820am/trajectories-0805am-0820am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0820am-0835am/trajectories-0820am-0835am.txt']\n",
    "trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class tensorsDatasetV2(Dataset):\n",
    "    \"\"\"\n",
    "    dataset for relation model\n",
    "    \"\"\"\n",
    "    def __init__(self, trajectoryFileList, numberOfTensorsEachBatch=1,lableTensorEachBatch=1):\n",
    "        if(numberOfTensorsEachBatch!=1 or lableTensorEachBatch!=1):\n",
    "            raise Exception(\"BOTH TRAIN AND VALID TENSOR NUMBERS SHOULD BE ONE!\")\n",
    "        self.valueDictList=[]\n",
    "        self.sizeList=[]\n",
    "        self.numberOfTensorsEachBatch=numberOfTensorsEachBatch\n",
    "        self.lableTensorEachBatch=lableTensorEachBatch\n",
    "        self.allTensorsEachBatch=numberOfTensorsEachBatch+lableTensorEachBatch\n",
    "        self.keysList=[]\n",
    "        if doNormalization:\n",
    "            self.positionXMax=0\n",
    "            self.positionXMin=999999\n",
    "            self.positionYMax=0\n",
    "            self.positionYMin=99999\n",
    "            self.speedMax=-100\n",
    "            self.speedMin=999999\n",
    "            self.accMax=-100\n",
    "            self.accMin=9999\n",
    "        for eachFile in trajectoryFileList:\n",
    "            valueDict=fromDirGenerateDict(eachFile)\n",
    "            if doNormalization:\n",
    "                #get the max and min value for normalization\n",
    "                maxAndMinDict=getMaxAndMinValueFromValueDict(valueDict,['Local_X','Local_Y','v_Vel','v_Acc'])\n",
    "                #position X\n",
    "                if self.positionXMax<maxAndMinDict['Local_X']['max']:\n",
    "                    self.positionXMax=maxAndMinDict['Local_X']['max']\n",
    "                if self.positionXMin>maxAndMinDict['Local_X']['min']:\n",
    "                    self.positionXMin=maxAndMinDict['Local_X']['min']\n",
    "                #position Y\n",
    "                if self.positionYMax<maxAndMinDict['Local_Y']['max']:\n",
    "                    self.positionYMax=maxAndMinDict['Local_Y']['max']\n",
    "                if self.positionYMin>maxAndMinDict['Local_Y']['min']:\n",
    "                    self.positionYMin=maxAndMinDict['Local_Y']['min']\n",
    "                #speed\n",
    "                if self.speedMax<maxAndMinDict['v_Vel']['max']:\n",
    "                    self.speedMax=maxAndMinDict['v_Vel']['max']\n",
    "                if self.speedMin>maxAndMinDict['v_Vel']['min']:\n",
    "                    self.speedMin=maxAndMinDict['v_Vel']['min']\n",
    "                #acc\n",
    "                if self.accMax<maxAndMinDict['v_Acc']['max']:\n",
    "                    self.accMax=maxAndMinDict['v_Acc']['max']\n",
    "                if self.accMin>maxAndMinDict['v_Acc']['min']:\n",
    "                    self.accMin=maxAndMinDict['v_Acc']['min']\n",
    "            self.valueDictList.append(copy.deepcopy(valueDict))\n",
    "            self.sizeList.append(valueDict.keys().__len__()-self.allTensorsEachBatch)\n",
    "            sortedKeys=list(valueDict.keys())\n",
    "            sortedKeys.sort()\n",
    "            self.keysList.append(copy.deepcopy(sortedKeys))\n",
    "\n",
    "    def getNormalizationDict(self):\n",
    "        '''\n",
    "        Returns:\n",
    "            a dict:{'positionXMax':self.positionXMax,'positonYMax':self.self.positionYMax,\\\n",
    "               'positionXMin':self.positionXMin,'positionYMin':self.positionYMin,\\\n",
    "               'speedMax':self.speedMax,'speedMin':speedMin,\\\n",
    "               'accMax':self.accMax,'accMax':self.accMin}\n",
    "        '''\n",
    "        if not doNormalization:\n",
    "            raise Exception('NORMALIZATION IS NOT APPLIED')\n",
    "        return {'positionXMax':self.positionXMax,'positionYMax':self.positionYMax,\\\n",
    "               'positionXMin':self.positionXMin,'positionYMin':self.positionYMin,\\\n",
    "               'speedMax':self.speedMax,'speedMin':self.speedMin,\\\n",
    "               'accMax':self.accMax,'accMin':self.accMin}\n",
    "    \n",
    "    def __len__(self):\n",
    "        allLen=0\n",
    "        for length in self.sizeList:\n",
    "            allLen=allLen+length\n",
    "        return allLen\n",
    "    \n",
    "    def fromIdxMapToList(self,idx):\n",
    "        \"\"\"\n",
    "        since there are several lists,we have to know which list shoud we use and the ture index in the list\n",
    "        Return:\n",
    "            the trueIndex, listIndex\n",
    "        \"\"\"\n",
    "        countSection=0\n",
    "        for i in range(0,self.sizeList.__len__()):\n",
    "            countSection+=self.sizeList[i]\n",
    "            if(idx<countSection):\n",
    "                return idx-countSection+self.sizeList[i],i\n",
    "            \n",
    "    \n",
    "            \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        #initialize trueIndex, listIndex\n",
    "        #\n",
    "        #this dict record the relation between matrix index and vehicle ID in the last frame\n",
    "        matrixIndexAndVehicleIDRecordDict={}\n",
    "        #initialize dict above\n",
    "        for i in range(0,maxMatrixIndex):\n",
    "            matrixIndexAndVehicleIDRecordDict[i]={'Vehicle_ID':-1,'refresh':-1}\n",
    "        matrixIndexAndVehicleIDRecordDict['time']=-1\n",
    "        trueIndex,listIndex=self.fromIdxMapToList(idx)\n",
    "        itemDict={'positionTensorList':[],'speedTensorList':[],'accTensorList':[],'angleTensorList':[],'time':[]}\n",
    "        valueDict=self.valueDictList[listIndex] #valueDict is the Dict of many frames\n",
    "        dictKeys=self.keysList[listIndex]\n",
    "        #generate tensors of first frame\n",
    "        positionTensor,speedTensor,accTensor,angleTensor,newVehicleList\\\n",
    "        =readFirstFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[trueIndex]])\n",
    "        angleSinTensor=torch.sin(angleTensor)\n",
    "        angleCosTensor=torch.cos(angleTensor)\n",
    "        #first frame normalization\n",
    "        if doNormalization:\n",
    "#             print('before nomalization')\n",
    "#             print(positionTensor.shape,speedTensor.shape,accTensor.shape)\n",
    "            positionTensor=torch.cat((torch.div(torch.sub(positionTensor[0,:],self.positionXMin),self.positionXMax-self.positionXMin).unsqueeze(0),\\\n",
    "                                     torch.div(torch.sub(positionTensor[1,:],self.positionYMin,),self.positionYMax-self.positionYMin).unsqueeze(0)),0)\n",
    "            speedTensor=torch.div(torch.sub(speedTensor,self.speedMin),self.speedMax-self.speedMin)\n",
    "            accTensor=torch.div(torch.sub(accTensor,self.accMin),self.accMax-self.accMin)\n",
    "#             print('after normalization')\n",
    "#             print(positionTensor.shape,speedTensor.shape,accTensor.shape)\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "        else:\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "        #generate relation tensor for all vehicle pairs\n",
    "        print('in getitem, combinedTensor shape: ',combinedTensor.shape)\n",
    "        relationTensorLeft=combinedTensor[:,0].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])\n",
    "        relationTensorRight=torch.transpose(torch.cat((combinedTensor[:,:0],combinedTensor[:,1:]),1),0,1)\n",
    "        print('in getitem, relation tensorleft shape:',relationTensorLeft.shape)\n",
    "        print('in getitem, relationtensorright shape',relationTensorRight.shape)\n",
    "#         print(relationTensorRight.shape,relationTensorRight.shape)\n",
    "        for i in range(1,combinedTensor.shape[1]):\n",
    "            relationTensorLeft=torch.cat((relationTensorLeft,\\\n",
    "                                          combinedTensor[:,i].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])),0)\n",
    "            relationTensorRight=torch.cat((relationTensorRight,\\\n",
    "                                           torch.transpose(torch.cat((combinedTensor[:,:i],combinedTensor[:,i+1:]),1),0,1)),0)\n",
    "#         print(relationTensorLeft.shape,relationTensorRight.shape)\n",
    "        combinedRelationTensor=torch.cat((relationTensorLeft,relationTensorRight),1)  \n",
    "        firstCombinedRelationTensor=combinedRelationTensor\n",
    "        \n",
    "        \n",
    "        allCombineTensorTrain=combinedTensor.unsqueeze(0)\n",
    "        allCombineTensorValid=0\n",
    "#         itemDict['positionTensorList'].append(positionTensor)\n",
    "#         itemDict['speedTensorList'].append(speedTensor)\n",
    "#         itemDict['accTensorList'].append(accTensor)\n",
    "#         itemDict['angleTensorList'].append(angleTensor)\n",
    "#         time=getValueByLable(['Global_Time'],valueDict[dictKeys[trueIndex]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]][0]\n",
    "#         itemDict['time'].append(time)\n",
    "        \n",
    "        for i in range(trueIndex+1,trueIndex+self.allTensorsEachBatch):\n",
    "            #generate tensor from general frame\n",
    "            positionTensor,speedTensor,accTensor,angleTensor,newVehicleList,vanishedVehicleList\\\n",
    "            =readGeneralFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[i]],positionTensor)\n",
    "            angleSinTensor=torch.sin(angleTensor)\n",
    "            angleCosTensor=torch.cos(angleTensor)\n",
    "            if doNormalization:\n",
    "                positionTensor=torch.cat((torch.div(torch.sub(positionTensor[0,:],self.positionXMin),self.positionXMax-self.positionXMin).unsqueeze(0),\\\n",
    "                                         torch.div(torch.sub(positionTensor[1,:],self.positionYMin,),self.positionYMax-self.positionYMin).unsqueeze(0)),0)\n",
    "                speedTensor=torch.div(torch.sub(speedTensor,self.speedMin),self.speedMax-self.speedMin)\n",
    "                accTensor=torch.div(torch.sub(accTensor,self.accMin),self.accMax-self.accMin)\n",
    "                combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                         speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                         accTensor.mul(angleCosTensor)),0)\n",
    "            else:\n",
    "                combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                         accTensor.mul(angleCosTensor)),0)\n",
    "            #generate relation tensor for all vehicle pairs\n",
    "            relationTensorLeft=combinedTensor[:,0].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])\n",
    "            relationTensorRight=torch.transpose(torch.cat((combinedTensor[:,:0],combinedTensor[:,1:]),1),0,1)\n",
    "#             print(relationTensorRight.shape,relationTensorRight.shape)\n",
    "            for j in range(1,combinedTensor.shape[1]):\n",
    "                relationTensorLeft=torch.cat((relationTensorLeft,\\\n",
    "                                              combinedTensor[:,j].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])),0)\n",
    "                relationTensorRight=torch.cat((relationTensorRight,\\\n",
    "                                               torch.transpose(torch.cat((combinedTensor[:,:j],combinedTensor[:,j+1:]),1),0,1)),0)\n",
    "#             print(relationTensorLeft.shape,relationTensorRight.shape)\n",
    "            combinedRelationTensor=torch.cat((relationTensorLeft,relationTensorRight),1)  \n",
    "            secondRelationTensor=combinedRelationTensor\n",
    "            #since we only need two tensors, which is input and output tensor respectively, we could return\n",
    "            #the two tensors in the first loop\n",
    "            #(ok I admit that the true reason is that I am lazy)\n",
    "            return firstCombinedRelationTensor,secondRelationTensor\n",
    "#             if i<self.numberOfTensorsEachBatch+trueIndex:\n",
    "#                 allCombineTensorTrain=torch.cat((allCombineTensorTrain,combinedTensor.unsqueeze(0)),0)\n",
    "#             elif i==self.numberOfTensorsEachBatch+trueIndex:\n",
    "#                 allCombineTensorValid=combinedTensor.unsqueeze(0)\n",
    "#             else:\n",
    "#                 allCombineTensorValid=torch.cat((allCombineTensorValid,combinedTensor.unsqueeze(0)),0)\n",
    "#             itemDict['positionTensorList'].append(positionTensor)\n",
    "#             itemDict['speedTensorList'].append(speedTensor)\n",
    "#             itemDict['accTensorList'].append(accTensor)\n",
    "#             itemDict['angleTensorList'].append(angleTensor)\n",
    "#             time=getValueByLable(['Global_Time'],valueDict[dictKeys[i]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]]\n",
    "#             itemDict['time'].append(time)\n",
    "        return allCombineTensorTrain,allCombineTensorValid\n",
    "# trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0805am-0820am/trajectories-0805am-0820am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0820am-0835am/trajectories-0820am-0835am.txt']\n",
    "trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n",
    "#run on 2080 in g814\n",
    "if runOnG814:\n",
    "    trajectoryFileList=['/home/wangyuchen/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fromObjectsToRelationPairsBatchAndTimestepVersion(batchAndTimestepCombinedTensor):\n",
    "    '''\n",
    "    This function based on the other function termed as 'fromObjectsToRelationPairs'. Instead of process a \n",
    "    single frame, this function takes batch and timestep(the other dimension) into consideration.\n",
    "    note: the dimension of combinedTensor is supposed to be (batchs, timesteps, properties, vehicles)\n",
    "    Args:\n",
    "        The input tensor should already be transposed if it is generated from the network's output\n",
    "    Returns:\n",
    "        Relation pairs\n",
    "    '''\n",
    "    #generate relation tensor for all vehicle pairs\n",
    "    batchSize=batchAndTimestepCombinedTensor.shape[0]\n",
    "    timesteps=batchAndTimestepCombinedTensor.shape[1]\n",
    "    for batch in range(batchSize):\n",
    "        for timestep in range(timesteps):\n",
    "            combinedTensor=batchAndTimestepCombinedTensor[batch,timestep,:,:]\n",
    "            relationTensorLeft=combinedTensor[:,0].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])\n",
    "            relationTensorRight=torch.transpose(torch.cat((combinedTensor[:,:0],combinedTensor[:,1:]),1),0,1)\n",
    "        #         print(relationTensorRight.shape,relationTensorRight.shape)\n",
    "            for i in range(1,combinedTensor.shape[1]):\n",
    "                relationTensorLeft=torch.cat((relationTensorLeft,\\\n",
    "                                              combinedTensor[:,i].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])),0)\n",
    "                relationTensorRight=torch.cat((relationTensorRight,\\\n",
    "                                               torch.transpose(torch.cat((combinedTensor[:,:i],combinedTensor[:,i+1:]),1),0,1)),0)\n",
    "        #         print(relationTensorLeft.shape,relationTensorRight.shape)\n",
    "            combinedRelationTensor=torch.cat((relationTensorLeft,relationTensorRight),1) \n",
    "            if timestep==0:\n",
    "                combineRelationTensorsTimeStep=combinedRelationTensor.unsqueeze(0)\n",
    "            else:\n",
    "                combineRelationTensorsTimeStep=torch.cat((combineRelationTensorsTimeStep,\\\n",
    "                                                          combinedRelationTensor.unsqueeze(0)),0)\n",
    "        if batch==0:\n",
    "            combinedRelationTensorsTimeStepAndBatch=combineRelationTensorsTimeStep.unsqueeze(0)\n",
    "        else:\n",
    "            combinedRelationTensorsTimeStepAndBatch=torch.cat((combinedRelationTensorsTimeStepAndBatch,\\\n",
    "                                                              combineRelationTensorsTimeStep.unsqueeze(0)),0)\n",
    "    return combinedRelationTensorsTimeStepAndBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the combined tensor and relation tensor i tensorsDataV2\n",
    "import math\n",
    "class tensorsDatasetV2Test(Dataset):\n",
    "    \"\"\"\n",
    "    dataset for relation model\n",
    "    \"\"\"\n",
    "    def __init__(self, trajectoryFileList, numberOfTensorsEachBatch=1,lableTensorEachBatch=1):\n",
    "        if(numberOfTensorsEachBatch!=1 or lableTensorEachBatch!=1):\n",
    "            raise Exception(\"BOTH TRAIN AND VALID TENSOR NUMBERS SHOULD BE ONE!\")\n",
    "        self.valueDictList=[]\n",
    "        self.sizeList=[]\n",
    "        self.numberOfTensorsEachBatch=numberOfTensorsEachBatch\n",
    "        self.lableTensorEachBatch=lableTensorEachBatch\n",
    "        self.allTensorsEachBatch=numberOfTensorsEachBatch+lableTensorEachBatch\n",
    "        self.keysList=[]\n",
    "        if doNormalization:\n",
    "            self.positionXMax=0\n",
    "            self.positionXMin=999999\n",
    "            self.positionYMax=0\n",
    "            self.positionYMin=99999\n",
    "            self.speedMax=-100\n",
    "            self.speedMin=999999\n",
    "            self.accMax=-100\n",
    "            self.accMin=9999\n",
    "        for eachFile in trajectoryFileList:\n",
    "            valueDict=fromDirGenerateDict(eachFile)\n",
    "            if doNormalization:\n",
    "                #get the max and min value for normalization\n",
    "                maxAndMinDict=getMaxAndMinValueFromValueDict(valueDict,['Local_X','Local_Y','v_Vel','v_Acc'])\n",
    "                #position X\n",
    "                if self.positionXMax<maxAndMinDict['Local_X']['max']:\n",
    "                    self.positionXMax=maxAndMinDict['Local_X']['max']\n",
    "                if self.positionXMin>maxAndMinDict['Local_X']['min']:\n",
    "                    self.positionXMin=maxAndMinDict['Local_X']['min']\n",
    "                #position Y\n",
    "                if self.positionYMax<maxAndMinDict['Local_Y']['max']:\n",
    "                    self.positionYMax=maxAndMinDict['Local_Y']['max']\n",
    "                if self.positionYMin>maxAndMinDict['Local_Y']['min']:\n",
    "                    self.positionYMin=maxAndMinDict['Local_Y']['min']\n",
    "                #speed\n",
    "                if self.speedMax<maxAndMinDict['v_Vel']['max']:\n",
    "                    self.speedMax=maxAndMinDict['v_Vel']['max']\n",
    "                if self.speedMin>maxAndMinDict['v_Vel']['min']:\n",
    "                    self.speedMin=maxAndMinDict['v_Vel']['min']\n",
    "                #acc\n",
    "                if self.accMax<maxAndMinDict['v_Acc']['max']:\n",
    "                    self.accMax=maxAndMinDict['v_Acc']['max']\n",
    "                if self.accMin>maxAndMinDict['v_Acc']['min']:\n",
    "                    self.accMin=maxAndMinDict['v_Acc']['min']\n",
    "            self.valueDictList.append(copy.deepcopy(valueDict))\n",
    "            self.sizeList.append(valueDict.keys().__len__()-self.allTensorsEachBatch)\n",
    "            sortedKeys=list(valueDict.keys())\n",
    "            sortedKeys.sort()\n",
    "            self.keysList.append(copy.deepcopy(sortedKeys))\n",
    "\n",
    "    def getNormalizationDict(self):\n",
    "        '''\n",
    "        Returns:\n",
    "            a dict:{'positionXMax':self.positionXMax,'positonYMax':self.self.positionYMax,\\\n",
    "               'positionXMin':self.positionXMin,'positionYMin':self.positionYMin,\\\n",
    "               'speedMax':self.speedMax,'speedMin':speedMin,\\\n",
    "               'accMax':self.accMax,'accMax':self.accMin}\n",
    "        '''\n",
    "        if not doNormalization:\n",
    "            raise Exception('NORMALIZATION IS NOT APPLIED')\n",
    "        return {'positionXMax':self.positionXMax,'positionYMax':self.positionYMax,\\\n",
    "               'positionXMin':self.positionXMin,'positionYMin':self.positionYMin,\\\n",
    "               'speedMax':self.speedMax,'speedMin':self.speedMin,\\\n",
    "               'accMax':self.accMax,'accMin':self.accMin}\n",
    "    \n",
    "    def __len__(self):\n",
    "        allLen=0\n",
    "        for length in self.sizeList:\n",
    "            allLen=allLen+length\n",
    "        return allLen\n",
    "    \n",
    "    def fromIdxMapToList(self,idx):\n",
    "        \"\"\"\n",
    "        since there are several lists,we have to know which list shoud we use and the ture index in the list\n",
    "        Return:\n",
    "            the trueIndex, listIndex\n",
    "        \"\"\"\n",
    "        countSection=0\n",
    "        for i in range(0,self.sizeList.__len__()):\n",
    "            countSection+=self.sizeList[i]\n",
    "            if(idx<countSection):\n",
    "                return idx-countSection+self.sizeList[i],i\n",
    "            \n",
    "    \n",
    "            \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        #initialize trueIndex, listIndex\n",
    "        #\n",
    "        #this dict record the relation between matrix index and vehicle ID in the last frame\n",
    "        matrixIndexAndVehicleIDRecordDict={}\n",
    "        #initialize dict above\n",
    "        for i in range(0,maxMatrixIndex):\n",
    "            matrixIndexAndVehicleIDRecordDict[i]={'Vehicle_ID':-1,'refresh':-1}\n",
    "        matrixIndexAndVehicleIDRecordDict['time']=-1\n",
    "        trueIndex,listIndex=self.fromIdxMapToList(idx)\n",
    "        itemDict={'positionTensorList':[],'speedTensorList':[],'accTensorList':[],'angleTensorList':[],'time':[]}\n",
    "        valueDict=self.valueDictList[listIndex] #valueDict is the Dict of many frames\n",
    "        dictKeys=self.keysList[listIndex]\n",
    "        #generate tensors of first frame\n",
    "        positionTensor,speedTensor,accTensor,angleTensor,newVehicleList\\\n",
    "        =readFirstFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[trueIndex]])\n",
    "        angleSinTensor=torch.sin(angleTensor)\n",
    "        angleCosTensor=torch.cos(angleTensor)\n",
    "        fileName='./'+'tensorFromGetitem'+'/'+str(10000000+idx)+'.png'\n",
    "        image=visualizeTensorData(positionTensor[0,:],positionTensor[1,:])\n",
    "        cv2.imwrite(fileName,image)\n",
    "        #first frame normalization\n",
    "        if doNormalization:\n",
    "#             print('before nomalization')\n",
    "#             print(positionTensor.shape,speedTensor.shape,accTensor.shape)\n",
    "            positionTensor=torch.cat((torch.div(torch.sub(positionTensor[0,:],self.positionXMin),self.positionXMax-self.positionXMin).unsqueeze(0),\\\n",
    "                                     torch.div(torch.sub(positionTensor[1,:],self.positionYMin,),self.positionYMax-self.positionYMin).unsqueeze(0)),0)\n",
    "            speedTensor=torch.div(torch.sub(speedTensor,self.speedMin),self.speedMax-self.speedMin)\n",
    "            accTensor=torch.div(torch.sub(accTensor,self.accMin),self.accMax-self.accMin)\n",
    "#             print('after normalization')\n",
    "#             print(positionTensor.shape,speedTensor.shape,accTensor.shape)\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "        else:\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "        #generate relation tensor for all vehicle pairs\n",
    "        print('in getitem, combinedTensor shape: ',combinedTensor.shape)\n",
    "        fileName='./'+'tensorFromGetitemAfterNormalization'+'/'+str(10000000+idx)+'.png'\n",
    "        image=visualizeTensorData(positionTensor[0,:],positionTensor[1,:],normalizationDict=self.getNormalizationDict())\n",
    "        cv2.imwrite(fileName,image)\n",
    "        relationTensorLeft=combinedTensor[:,0].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])\n",
    "        relationTensorRight=torch.transpose(torch.cat((combinedTensor[:,:0],combinedTensor[:,1:]),1),0,1)\n",
    "        print('in getitem, relation tensorleft shape:',relationTensorLeft.shape)\n",
    "        print('in getitem, relationtensorright shape',relationTensorRight.shape)\n",
    "#         print(relationTensorRight.shape,relationTensorRight.shape)\n",
    "        for i in range(1,combinedTensor.shape[1]):\n",
    "            relationTensorLeft=torch.cat((relationTensorLeft,\\\n",
    "                                          combinedTensor[:,i].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])),0)\n",
    "            relationTensorRight=torch.cat((relationTensorRight,\\\n",
    "                                           torch.transpose(torch.cat((combinedTensor[:,:i],combinedTensor[:,i+1:]),1),0,1)),0)\n",
    "#         print(relationTensorLeft.shape,relationTensorRight.shape)\n",
    "        combinedRelationTensor=torch.cat((relationTensorLeft,relationTensorRight),1)  \n",
    "        firstCombinedRelationTensor=combinedRelationTensor\n",
    "        firstCombinedTensor=combinedTensor\n",
    "        \n",
    "        \n",
    "        allCombineTensorTrain=combinedTensor.unsqueeze(0)\n",
    "        allCombineTensorValid=0\n",
    "#         itemDict['positionTensorList'].append(positionTensor)\n",
    "#         itemDict['speedTensorList'].append(speedTensor)\n",
    "#         itemDict['accTensorList'].append(accTensor)\n",
    "#         itemDict['angleTensorList'].append(angleTensor)\n",
    "#         time=getValueByLable(['Global_Time'],valueDict[dictKeys[trueIndex]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]][0]\n",
    "#         itemDict['time'].append(time)\n",
    "        \n",
    "        for i in range(trueIndex+1,trueIndex+self.allTensorsEachBatch):\n",
    "            #generate tensor from general frame\n",
    "            positionTensor,speedTensor,accTensor,angleTensor,newVehicleList,vanishedVehicleList\\\n",
    "            =readGeneralFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[i]],positionTensor)\n",
    "            angleSinTensor=torch.sin(angleTensor)\n",
    "            angleCosTensor=torch.cos(angleTensor)\n",
    "            if doNormalization:\n",
    "                positionTensor=torch.cat((torch.div(torch.sub(positionTensor[0,:],self.positionXMin),self.positionXMax-self.positionXMin).unsqueeze(0),\\\n",
    "                                         torch.div(torch.sub(positionTensor[1,:],self.positionYMin,),self.positionYMax-self.positionYMin).unsqueeze(0)),0)\n",
    "                speedTensor=torch.div(torch.sub(speedTensor,self.speedMin),self.speedMax-self.speedMin)\n",
    "                accTensor=torch.div(torch.sub(accTensor,self.accMin),self.accMax-self.accMin)\n",
    "                combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                         speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                         accTensor.mul(angleCosTensor)),0)\n",
    "            else:\n",
    "                combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                         accTensor.mul(angleCosTensor)),0)\n",
    "            #generate relation tensor for all vehicle pairs\n",
    "            relationTensorLeft=combinedTensor[:,0].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])\n",
    "            relationTensorRight=torch.transpose(torch.cat((combinedTensor[:,:0],combinedTensor[:,1:]),1),0,1)\n",
    "#             print(relationTensorRight.shape,relationTensorRight.shape)\n",
    "            for j in range(1,combinedTensor.shape[1]):\n",
    "                relationTensorLeft=torch.cat((relationTensorLeft,\\\n",
    "                                              combinedTensor[:,j].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])),0)\n",
    "                relationTensorRight=torch.cat((relationTensorRight,\\\n",
    "                                               torch.transpose(torch.cat((combinedTensor[:,:j],combinedTensor[:,j+1:]),1),0,1)),0)\n",
    "#             print(relationTensorLeft.shape,relationTensorRight.shape)\n",
    "            combinedRelationTensor=torch.cat((relationTensorLeft,relationTensorRight),1)  \n",
    "            secondRelationTensor=combinedRelationTensor\n",
    "            secondCombinedTensor=combinedTensor\n",
    "            #since we only need two tensors, which is input and output tensor respectively, we could return\n",
    "            #the two tensors in the first loop\n",
    "            #(ok I admit that the true reason is that I am lazy)\n",
    "            return firstCombinedTensor,secondCombinedTensor\n",
    "            return firstCombinedRelationTensor,secondRelationTensor\n",
    "#             if i<self.numberOfTensorsEachBatch+trueIndex:\n",
    "#                 allCombineTensorTrain=torch.cat((allCombineTensorTrain,combinedTensor.unsqueeze(0)),0)\n",
    "#             elif i==self.numberOfTensorsEachBatch+trueIndex:\n",
    "#                 allCombineTensorValid=combinedTensor.unsqueeze(0)\n",
    "#             else:\n",
    "#                 allCombineTensorValid=torch.cat((allCombineTensorValid,combinedTensor.unsqueeze(0)),0)\n",
    "#             itemDict['positionTensorList'].append(positionTensor)\n",
    "#             itemDict['speedTensorList'].append(speedTensor)\n",
    "#             itemDict['accTensorList'].append(accTensor)\n",
    "#             itemDict['angleTensorList'].append(angleTensor)\n",
    "#             time=getValueByLable(['Global_Time'],valueDict[dictKeys[i]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]]\n",
    "#             itemDict['time'].append(time)\n",
    "        return allCombineTensorTrain,allCombineTensorValid\n",
    "# trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0805am-0820am/trajectories-0805am-0820am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0820am-0835am/trajectories-0820am-0835am.txt']\n",
    "trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n",
    "#run on 2080 in g814\n",
    "if runOnG814:\n",
    "    trajectoryFileList=['/home/wangyuchen/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datasetV2Test=tensorsDatasetV2Test(trajectoryFileList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(datasetV2Test.getNormalizationDict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "firstCombined,secondCombined=datasetV2Test.__getitem__(40)\n",
    "print(firstCombined.shape,secondCombined.shape)\n",
    "image=visualizeTensorData(firstCombined[0,:],firstCombined[1,:],normalizationDict=datasetV2Test.getNormalizationDict())\n",
    "dirName='combinedTensorFolder'+str(int(time.time()))\n",
    "os.mkdir(dirName)\n",
    "for i in range(0,2000):\n",
    "    fileName='./'+dirName+'/'+str(10000000+i)+'.png'\n",
    "    firstCombined,secondCombined=datasetV2Test.__getitem__(i)\n",
    "    image=visualizeTensorData(firstCombined[0,:],firstCombined[1,:],normalizationDict=datasetV2Test.getNormalizationDict())\n",
    "    cv2.imwrite(fileName,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class tensorsDatasetV3(Dataset):\n",
    "    \"\"\"\n",
    "    dataset for relation lstm model\n",
    "    \"\"\"\n",
    "    def __init__(self, trajectoryFileList, numberOfTensorsEachBatch=10,lableTensorEachBatch=10):\n",
    "\n",
    "        self.valueDictList=[]\n",
    "        self.sizeList=[]\n",
    "        self.numberOfTensorsEachBatch=numberOfTensorsEachBatch\n",
    "        self.lableTensorEachBatch=lableTensorEachBatch\n",
    "        self.allTensorsEachBatch=numberOfTensorsEachBatch+lableTensorEachBatch\n",
    "        self.keysList=[]\n",
    "        if doNormalization:\n",
    "            self.positionXMax=0\n",
    "            self.positionXMin=999999\n",
    "            self.positionYMax=0\n",
    "            self.positionYMin=99999\n",
    "            self.speedMax=-100\n",
    "            self.speedMin=999999\n",
    "            self.accMax=-100\n",
    "            self.accMin=9999\n",
    "        for eachFile in trajectoryFileList:\n",
    "            valueDict=fromDirGenerateDict(eachFile)\n",
    "            if doNormalization:\n",
    "                #get the max and min value for normalization\n",
    "                maxAndMinDict=getMaxAndMinValueFromValueDict(valueDict,['Local_X','Local_Y','v_Vel','v_Acc'])\n",
    "                #position X\n",
    "                if self.positionXMax<maxAndMinDict['Local_X']['max']:\n",
    "                    self.positionXMax=maxAndMinDict['Local_X']['max']\n",
    "                if self.positionXMin>maxAndMinDict['Local_X']['min']:\n",
    "                    self.positionXMin=maxAndMinDict['Local_X']['min']\n",
    "                #position Y\n",
    "                if self.positionYMax<maxAndMinDict['Local_Y']['max']:\n",
    "                    self.positionYMax=maxAndMinDict['Local_Y']['max']\n",
    "                if self.positionYMin>maxAndMinDict['Local_Y']['min']:\n",
    "                    self.positionYMin=maxAndMinDict['Local_Y']['min']\n",
    "                #speed\n",
    "                if self.speedMax<maxAndMinDict['v_Vel']['max']:\n",
    "                    self.speedMax=maxAndMinDict['v_Vel']['max']\n",
    "                if self.speedMin>maxAndMinDict['v_Vel']['min']:\n",
    "                    self.speedMin=maxAndMinDict['v_Vel']['min']\n",
    "                #acc\n",
    "                if self.accMax<maxAndMinDict['v_Acc']['max']:\n",
    "                    self.accMax=maxAndMinDict['v_Acc']['max']\n",
    "                if self.accMin>maxAndMinDict['v_Acc']['min']:\n",
    "                    self.accMin=maxAndMinDict['v_Acc']['min']\n",
    "            self.valueDictList.append(copy.deepcopy(valueDict))\n",
    "            self.sizeList.append(valueDict.keys().__len__()-self.allTensorsEachBatch)\n",
    "            sortedKeys=list(valueDict.keys())\n",
    "            sortedKeys.sort()\n",
    "            self.keysList.append(copy.deepcopy(sortedKeys))\n",
    "\n",
    "    def getNormalizationDict(self):\n",
    "        '''\n",
    "        Returns:\n",
    "            a dict:{'positionXMax':self.positionXMax,'positonYMax':self.self.positionYMax,\\\n",
    "               'positionXMin':self.positionXMin,'positionYMin':self.positionYMin,\\\n",
    "               'speedMax':self.speedMax,'speedMin':speedMin,\\\n",
    "               'accMax':self.accMax,'accMax':self.accMin}\n",
    "        '''\n",
    "        if not doNormalization:\n",
    "            raise Exception('NORMALIZATION IS NOT APPLIED')\n",
    "        return {'positionXMax':self.positionXMax,'positionYMax':self.positionYMax,\\\n",
    "               'positionXMin':self.positionXMin,'positionYMin':self.positionYMin,\\\n",
    "               'speedMax':self.speedMax,'speedMin':self.speedMin,\\\n",
    "               'accMax':self.accMax,'accMax':self.accMin}\n",
    "    \n",
    "    def __len__(self):\n",
    "        allLen=0\n",
    "        for length in self.sizeList:\n",
    "            allLen=allLen+length\n",
    "        return allLen\n",
    "    \n",
    "    def fromIdxMapToList(self,idx):\n",
    "        \"\"\"\n",
    "        since there are several lists,we have to know which list shoud we use and the true index in the list\n",
    "        Return:\n",
    "            the trueIndex, listIndex\n",
    "        \"\"\"\n",
    "        countSection=0\n",
    "        for i in range(0,self.sizeList.__len__()):\n",
    "            countSection+=self.sizeList[i]\n",
    "            if(idx<countSection):\n",
    "                return idx-countSection+self.sizeList[i],i\n",
    "            \n",
    "    \n",
    "            \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        #initialize trueIndex, listIndex\n",
    "        #\n",
    "        #this dict record the relation between matrix index and vehicle ID in the last frame\n",
    "        matrixIndexAndVehicleIDRecordDict={}\n",
    "        #initialize dict above\n",
    "        for i in range(0,maxMatrixIndex):\n",
    "            matrixIndexAndVehicleIDRecordDict[i]={'Vehicle_ID':-1,'refresh':-1}\n",
    "        matrixIndexAndVehicleIDRecordDict['time']=-1\n",
    "        trueIndex,listIndex=self.fromIdxMapToList(idx)\n",
    "        itemDict={'positionTensorList':[],'speedTensorList':[],'accTensorList':[],'angleTensorList':[],'time':[]}\n",
    "        valueDict=self.valueDictList[listIndex] #valueDict is the Dict of many frames\n",
    "        dictKeys=self.keysList[listIndex]\n",
    "        #generate tensors of first frame\n",
    "        positionTensor,speedTensor,accTensor,angleTensor,newVehicleList\\\n",
    "        =readFirstFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[trueIndex]])\n",
    "        angleSinTensor=torch.sin(angleTensor)\n",
    "        angleCosTensor=torch.cos(angleTensor)\n",
    "        #first frame normalization\n",
    "        if doNormalization:\n",
    "#             print('before nomalization')\n",
    "#             print(positionTensor.shape,speedTensor.shape,accTensor.shape)\n",
    "            positionTensor=torch.cat((torch.div(torch.sub(positionTensor[0,:],self.positionXMin),self.positionXMax-self.positionXMin).unsqueeze(0),\\\n",
    "                                     torch.div(torch.sub(positionTensor[1,:],self.positionYMin,),self.positionYMax-self.positionYMin).unsqueeze(0)),0)\n",
    "            speedTensor=torch.div(torch.sub(speedTensor,self.speedMin),self.speedMax-self.speedMin)\n",
    "            accTensor=torch.div(torch.sub(accTensor,self.accMin),self.accMax-self.accMin)\n",
    "#             print('after normalization')\n",
    "#             print(positionTensor.shape,speedTensor.shape,accTensor.shape)\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "        else:\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        allCombineTensorTrain=combinedTensor.unsqueeze(0)\n",
    "        allCombineTensorValid=0\n",
    "#         itemDict['positionTensorList'].append(positionTensor)\n",
    "#         itemDict['speedTensorList'].append(speedTensor)\n",
    "#         itemDict['accTensorList'].append(accTensor)\n",
    "#         itemDict['angleTensorList'].append(angleTensor)\n",
    "#         time=getValueByLable(['Global_Time'],valueDict[dictKeys[trueIndex]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]][0]\n",
    "#         itemDict['time'].append(time)\n",
    "        \n",
    "        for i in range(trueIndex+1,trueIndex+self.allTensorsEachBatch):\n",
    "            #generate tensor from general frame\n",
    "            positionTensor,speedTensor,accTensor,angleTensor,newVehicleList,vanishedVehicleList\\\n",
    "            =readGeneralFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[i]],positionTensor)\n",
    "            angleSinTensor=torch.sin(angleTensor)\n",
    "            angleCosTensor=torch.cos(angleTensor)\n",
    "            if doNormalization:\n",
    "                positionTensor=torch.cat((torch.div(torch.sub(positionTensor[0,:],self.positionXMin),self.positionXMax-self.positionXMin).unsqueeze(0),\\\n",
    "                                         torch.div(torch.sub(positionTensor[1,:],self.positionYMin,),self.positionYMax-self.positionYMin).unsqueeze(0)),0)\n",
    "                speedTensor=torch.div(torch.sub(speedTensor,self.speedMin),self.speedMax-self.speedMin)\n",
    "                accTensor=torch.div(torch.sub(accTensor,self.accMin),self.accMax-self.accMin)\n",
    "                combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                         speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                         accTensor.mul(angleCosTensor)),0)\n",
    "            else:\n",
    "                combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                         accTensor.mul(angleCosTensor)),0)\n",
    "            if i<self.numberOfTensorsEachBatch+trueIndex:\n",
    "                allCombineTensorTrain=torch.cat((allCombineTensorTrain,combinedTensor.unsqueeze(0)),0)\n",
    "            elif i==self.numberOfTensorsEachBatch+trueIndex:\n",
    "                allCombineTensorValid=combinedTensor.unsqueeze(0)\n",
    "            else:\n",
    "                allCombineTensorValid=torch.cat((allCombineTensorValid,combinedTensor.unsqueeze(0)),0)\n",
    "#             itemDict['positionTensorList'].append(positionTensor)\n",
    "#             itemDict['speedTensorList'].append(speedTensor)\n",
    "#             itemDict['accTensorList'].append(accTensor)\n",
    "#             itemDict['angleTensorList'].append(angleTensor)\n",
    "#             time=getValueByLable(['Global_Time'],valueDict[dictKeys[i]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]]\n",
    "#             itemDict['time'].append(time)\n",
    "        return allCombineTensorTrain,allCombineTensorValid\n",
    "# trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0805am-0820am/trajectories-0805am-0820am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0820am-0835am/trajectories-0820am-0835am.txt']\n",
    "trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n",
    "#run on 2080 in g814\n",
    "if runOnG814:\n",
    "    trajectoryFileList=['/home/wangyuchen/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ABOLISHED\n",
    "class computeRelationAndAllTheOtherTensorsWithDistanceThread(Process):\n",
    "    '''\n",
    "    multi-thread version of function computeRelationAndAllTehOtherTensorsWithDistance.\n",
    "    Normally, the value returned by this class is only of one batch.\n",
    "    '''\n",
    "    def __init__(self,threadID,name,timestepID,inputFrameTensor,theGivenRange,maxRelationsNumber=20):\n",
    "        '''\n",
    "        Args:\n",
    "        threadID,name,batchID,inputFrameTensor,theGivenRange,maxRelationsNumber=20\n",
    "        see details in dos string of computeRelationAndAllTheOtherTensorsWithDistance\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.threadID=threadID\n",
    "        self.name=name\n",
    "        self.timestepID=timestepID\n",
    "        self.inputFrameTensor=inputFrameTensor\n",
    "        self.theGivenRange=theGivenRange\n",
    "        self.maxRelationsNumber=maxRelationsNumber\n",
    "        \n",
    "    def run(self):\n",
    "        logging.debug(fromAllToStr('thread',self.threadID,' start'))\n",
    "        self.relationTensor,self.discountParameterTensor=computeRelationAndAllTheOtherTensorsWithDistance\\\n",
    "        (self.inputFrameTensor,self.theGivenRange,self.maxRelationsNumber) \n",
    "        logging.debug(fromAllToStr('thread',self.threadID,' finished'))\n",
    "    \n",
    "    def getValue(self):\n",
    "        '''\n",
    "        Returns:\n",
    "        relationTensor,discountParameterTensor\n",
    "        '''\n",
    "        return self.relationTensor,self.discountParameterTensor\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relationComputationWorker(relationDict, discountDict, timestepI, inputFrameTensor, theGivenRange, maxRelationsNumber):\n",
    "    relationTensor,discountParameterTensor\\\n",
    "    =computeRelationAndAllTheOtherTensorsWithDistance\\\n",
    "    (inputFrameTensor,theGivenRange,maxRelationsNumber)\n",
    "    relationDict[timestepI]=relationTensor\n",
    "    discountDict[timestepI]=discountParameterTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class tensorsDatasetV4(Dataset):\n",
    "    \"\"\"\n",
    "    dataset for difference series type\n",
    "    Returns:\n",
    "    INPUTS:\n",
    "    relationTensors,discountParameterTensors,\n",
    "    OUTPUTS:\n",
    "    allCombineTensorTrain, allCombineTensorValid,\\\n",
    "        combinedRelationTensors, combinedDiscountParameterTensors,differenceLabels\n",
    "    \"\"\"\n",
    "    def __init__(self, trajectoryFileList, numberOfTensorsEachBatch=10,lableTensorEachBatch=10,\\\n",
    "                maxRelationNumber=20,givenRange=0.08):\n",
    "\n",
    "        self.valueDictList=[]\n",
    "        self.sizeList=[]\n",
    "        self.numberOfTensorsEachBatch=numberOfTensorsEachBatch\n",
    "        self.lableTensorEachBatch=lableTensorEachBatch\n",
    "        self.allTensorsEachBatch=numberOfTensorsEachBatch+lableTensorEachBatch\n",
    "        self.keysList=[]\n",
    "        self.maxRelationNumber=maxRelationNumber\n",
    "        self.givenRange=givenRange\n",
    "        if doNormalization:\n",
    "            self.positionXMax=0\n",
    "            self.positionXMin=999999\n",
    "            self.positionYMax=0\n",
    "            self.positionYMin=99999\n",
    "            self.speedMax=-100\n",
    "            self.speedMin=999999\n",
    "            self.accMax=-100\n",
    "            self.accMin=9999\n",
    "        for eachFile in trajectoryFileList:\n",
    "            valueDict=fromDirGenerateDict(eachFile)\n",
    "            if doNormalization:\n",
    "                #get the max and min value for normalization\n",
    "                maxAndMinDict=getMaxAndMinValueFromValueDict(valueDict,['Local_X','Local_Y','v_Vel','v_Acc'])\n",
    "                #position X\n",
    "                if self.positionXMax<maxAndMinDict['Local_X']['max']:\n",
    "                    self.positionXMax=maxAndMinDict['Local_X']['max']\n",
    "                if self.positionXMin>maxAndMinDict['Local_X']['min']:\n",
    "                    self.positionXMin=maxAndMinDict['Local_X']['min']\n",
    "                #position Y\n",
    "                if self.positionYMax<maxAndMinDict['Local_Y']['max']:\n",
    "                    self.positionYMax=maxAndMinDict['Local_Y']['max']\n",
    "                if self.positionYMin>maxAndMinDict['Local_Y']['min']:\n",
    "                    self.positionYMin=maxAndMinDict['Local_Y']['min']\n",
    "                #speed\n",
    "                if self.speedMax<maxAndMinDict['v_Vel']['max']:\n",
    "                    self.speedMax=maxAndMinDict['v_Vel']['max']\n",
    "                if self.speedMin>maxAndMinDict['v_Vel']['min']:\n",
    "                    self.speedMin=maxAndMinDict['v_Vel']['min']\n",
    "                #acc\n",
    "                if self.accMax<maxAndMinDict['v_Acc']['max']:\n",
    "                    self.accMax=maxAndMinDict['v_Acc']['max']\n",
    "                if self.accMin>maxAndMinDict['v_Acc']['min']:\n",
    "                    self.accMin=maxAndMinDict['v_Acc']['min']\n",
    "            self.valueDictList.append(copy.deepcopy(valueDict))\n",
    "            self.sizeList.append(valueDict.keys().__len__()-self.allTensorsEachBatch)\n",
    "            sortedKeys=list(valueDict.keys())\n",
    "            sortedKeys.sort()\n",
    "            self.keysList.append(copy.deepcopy(sortedKeys))\n",
    "\n",
    "    def getNormalizationDict(self):\n",
    "        '''\n",
    "        Returns:\n",
    "            a dict:{'positionXMax':self.positionXMax,'positonYMax':self.self.positionYMax,\\\n",
    "               'positionXMin':self.positionXMin,'positionYMin':self.positionYMin,\\\n",
    "               'speedMax':self.speedMax,'speedMin':speedMin,\\\n",
    "               'accMax':self.accMax,'accMax':self.accMin}\n",
    "        '''\n",
    "        if not doNormalization:\n",
    "            raise Exception('NORMALIZATION IS NOT APPLIED')\n",
    "        return {'positionXMax':self.positionXMax,'positionYMax':self.positionYMax,\\\n",
    "               'positionXMin':self.positionXMin,'positionYMin':self.positionYMin,\\\n",
    "               'speedMax':self.speedMax,'speedMin':self.speedMin,\\\n",
    "               'accMax':self.accMax,'accMax':self.accMin}\n",
    "    \n",
    "    def __len__(self):\n",
    "        allLen=0\n",
    "        for length in self.sizeList:\n",
    "            allLen=allLen+length\n",
    "        return allLen\n",
    "    \n",
    "    def fromIdxMapToList(self,idx):\n",
    "        \"\"\"\n",
    "        since there are several lists,we have to know which list shoud we use and the true index in the list\n",
    "        Return:\n",
    "            the trueIndex, listIndex\n",
    "        \"\"\"\n",
    "        countSection=0\n",
    "        for i in range(0,self.sizeList.__len__()):\n",
    "            countSection+=self.sizeList[i]\n",
    "            if(idx<countSection):\n",
    "                return idx-countSection+self.sizeList[i],i\n",
    "            \n",
    "    \n",
    "            \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        #initialize trueIndex, listIndex\n",
    "        #\n",
    "        #this dict record the relation between matrix index and vehicle ID in the last frame\n",
    "        matrixIndexAndVehicleIDRecordDict={}\n",
    "        #initialize dict above\n",
    "        for i in range(0,maxMatrixIndex):\n",
    "            matrixIndexAndVehicleIDRecordDict[i]={'Vehicle_ID':-1,'refresh':-1}\n",
    "        matrixIndexAndVehicleIDRecordDict['time']=-1\n",
    "        trueIndex,listIndex=self.fromIdxMapToList(idx)\n",
    "        itemDict={'positionTensorList':[],'speedTensorList':[],'accTensorList':[],'angleTensorList':[],'time':[]}\n",
    "        valueDict=self.valueDictList[listIndex] #valueDict is the Dict of many frames\n",
    "        dictKeys=self.keysList[listIndex]\n",
    "        #generate tensors of first frame\n",
    "        positionTensor,speedTensor,accTensor,angleTensor,newVehicleList\\\n",
    "        =readFirstFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[trueIndex]])\n",
    "        angleSinTensor=torch.sin(angleTensor)\n",
    "        angleCosTensor=torch.cos(angleTensor)\n",
    "        #first frame normalization\n",
    "        if doNormalization:\n",
    "#             print('before nomalization')\n",
    "#             print(positionTensor.shape,speedTensor.shape,accTensor.shape)\n",
    "            positionTensor=torch.cat((torch.div(torch.sub(positionTensor[0,:],self.positionXMin),self.positionXMax-self.positionXMin).unsqueeze(0),\\\n",
    "                                     torch.div(torch.sub(positionTensor[1,:],self.positionYMin,),self.positionYMax-self.positionYMin).unsqueeze(0)),0)\n",
    "            speedTensor=torch.div(torch.sub(speedTensor,self.speedMin),self.speedMax-self.speedMin)\n",
    "            accTensor=torch.div(torch.sub(accTensor,self.accMin),self.accMax-self.accMin)\n",
    "#             print('after normalization')\n",
    "#             print(positionTensor.shape,speedTensor.shape,accTensor.shape)\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "        else:\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        allCombineTensorTrain=combinedTensor.unsqueeze(0)\n",
    "        allCombineTensorValid=0\n",
    "#         itemDict['positionTensorList'].append(positionTensor)\n",
    "#         itemDict['speedTensorList'].append(speedTensor)\n",
    "#         itemDict['accTensorList'].append(accTensor)\n",
    "#         itemDict['angleTensorList'].append(angleTensor)\n",
    "#         time=getValueByLable(['Global_Time'],valueDict[dictKeys[trueIndex]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]][0]\n",
    "#         itemDict['time'].append(time)\n",
    "        \n",
    "        for i in range(trueIndex+1,trueIndex+self.allTensorsEachBatch):\n",
    "            #generate tensor from general frame\n",
    "            positionTensor,speedTensor,accTensor,angleTensor,newVehicleList,vanishedVehicleList\\\n",
    "            =readGeneralFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[i]],positionTensor)\n",
    "            angleSinTensor=torch.sin(angleTensor)\n",
    "            angleCosTensor=torch.cos(angleTensor)\n",
    "            if doNormalization:\n",
    "                positionTensor=torch.cat((torch.div(torch.sub(positionTensor[0,:],self.positionXMin),self.positionXMax-self.positionXMin).unsqueeze(0),\\\n",
    "                                         torch.div(torch.sub(positionTensor[1,:],self.positionYMin,),self.positionYMax-self.positionYMin).unsqueeze(0)),0)\n",
    "                speedTensor=torch.div(torch.sub(speedTensor,self.speedMin),self.speedMax-self.speedMin)\n",
    "                accTensor=torch.div(torch.sub(accTensor,self.accMin),self.accMax-self.accMin)\n",
    "                combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                         speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                         accTensor.mul(angleCosTensor)),0)\n",
    "            else:\n",
    "                combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                         accTensor.mul(angleCosTensor)),0)\n",
    "            if i<self.numberOfTensorsEachBatch+trueIndex:\n",
    "                allCombineTensorTrain=torch.cat((allCombineTensorTrain,combinedTensor.unsqueeze(0)),0)\n",
    "            elif i==self.numberOfTensorsEachBatch+trueIndex:\n",
    "                allCombineTensorValid=combinedTensor.unsqueeze(0)\n",
    "            else:\n",
    "                allCombineTensorValid=torch.cat((allCombineTensorValid,combinedTensor.unsqueeze(0)),0)\n",
    "#             itemDict['positionTensorList'].append(positionTensor)\n",
    "#             itemDict['speedTensorList'].append(speedTensor)\n",
    "#             itemDict['accTensorList'].append(accTensor)\n",
    "#             itemDict['angleTensorList'].append(angleTensor)\n",
    "#             time=getValueByLable(['Global_Time'],valueDict[dictKeys[i]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]]\n",
    "#             itemDict['time'].append(time)\n",
    "#         return allCombineTensorTrain,allCombineTensorValid\n",
    "        #only consist of position tensor, ignore speed tensor and accelerate tensor\n",
    "        allCombineTensorTrain=allCombineTensorTrain[:,0:2,:]\n",
    "        allCombineTensorValid=allCombineTensorValid[:,0:2,:]\n",
    "        logging.debug(fromAllToStr('allCombineTensorTrain.shape:',allCombineTensorTrain.shape))\n",
    "        logging.debug(fromAllToStr('allCombineTensorValid.shape',allCombineTensorValid))\n",
    "        combinedRelationTensors,combinedDiscountParameterTensors=\\\n",
    "        computeRelationAndAllTheOtherTensorsWithDistance(\\\n",
    "        allCombineTensorTrain,theGivenRange=self.givenRange,\\\n",
    "        maxRelationsNumber=self.maxRelationNumber)\n",
    "        #permute the dimension order of the valid tensor\n",
    "        differenceLabels=differenceBetweenTwoFrameForTimeSteps(allCombineTensorValid.permute(0,2,1))\n",
    "        logging.debug(fromAllToStr(\"differenceLabels.shape:\",differenceLabels.shape))\n",
    "        return allCombineTensorTrain, allCombineTensorValid,\\\n",
    "        combinedRelationTensors, combinedDiscountParameterTensors,differenceLabels\n",
    "        \n",
    "        \n",
    "            \n",
    "# trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0805am-0820am/trajectories-0805am-0820am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0820am-0835am/trajectories-0820am-0835am.txt']\n",
    "trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n",
    "#run on 2080 in g814\n",
    "if runOnG814:\n",
    "    trajectoryFileList=['/home/wangyuchen/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class tensorsDatasetV4MultiThread(Dataset):\n",
    "    \"\"\"\n",
    "    dataset for difference series type\n",
    "    Apply multi thread mode when compute relation and discount parameter\n",
    "    Returns:\n",
    "    INPUTS:\n",
    "    relationTensors,discountParameterTensors,\n",
    "    OUTPUTS:\n",
    "    allCombineTensorTrain, allCombineTensorValid,\\\n",
    "        combinedRelationTensors, combinedDiscountParameterTensors,differenceLabels\n",
    "    \"\"\"\n",
    "    def __init__(self, trajectoryFileList, numberOfTensorsEachBatch=10,lableTensorEachBatch=10,\\\n",
    "                maxRelationNumber=20,givenRange=0.08):\n",
    "\n",
    "        self.valueDictList=[]\n",
    "        self.sizeList=[]\n",
    "        self.numberOfTensorsEachBatch=numberOfTensorsEachBatch\n",
    "        self.lableTensorEachBatch=lableTensorEachBatch\n",
    "        self.allTensorsEachBatch=numberOfTensorsEachBatch+lableTensorEachBatch\n",
    "        self.keysList=[]\n",
    "        self.maxRelationNumber=maxRelationNumber\n",
    "        self.givenRange=givenRange\n",
    "        if doNormalization:\n",
    "            self.positionXMax=0\n",
    "            self.positionXMin=999999\n",
    "            self.positionYMax=0\n",
    "            self.positionYMin=99999\n",
    "            self.speedMax=-100\n",
    "            self.speedMin=999999\n",
    "            self.accMax=-100\n",
    "            self.accMin=9999\n",
    "        for eachFile in trajectoryFileList:\n",
    "            valueDict=fromDirGenerateDict(eachFile)\n",
    "            if doNormalization:\n",
    "                #get the max and min value for normalization\n",
    "                maxAndMinDict=getMaxAndMinValueFromValueDict(valueDict,['Local_X','Local_Y','v_Vel','v_Acc'])\n",
    "                #position X\n",
    "                if self.positionXMax<maxAndMinDict['Local_X']['max']:\n",
    "                    self.positionXMax=maxAndMinDict['Local_X']['max']\n",
    "                if self.positionXMin>maxAndMinDict['Local_X']['min']:\n",
    "                    self.positionXMin=maxAndMinDict['Local_X']['min']\n",
    "                #position Y\n",
    "                if self.positionYMax<maxAndMinDict['Local_Y']['max']:\n",
    "                    self.positionYMax=maxAndMinDict['Local_Y']['max']\n",
    "                if self.positionYMin>maxAndMinDict['Local_Y']['min']:\n",
    "                    self.positionYMin=maxAndMinDict['Local_Y']['min']\n",
    "                #speed\n",
    "                if self.speedMax<maxAndMinDict['v_Vel']['max']:\n",
    "                    self.speedMax=maxAndMinDict['v_Vel']['max']\n",
    "                if self.speedMin>maxAndMinDict['v_Vel']['min']:\n",
    "                    self.speedMin=maxAndMinDict['v_Vel']['min']\n",
    "                #acc\n",
    "                if self.accMax<maxAndMinDict['v_Acc']['max']:\n",
    "                    self.accMax=maxAndMinDict['v_Acc']['max']\n",
    "                if self.accMin>maxAndMinDict['v_Acc']['min']:\n",
    "                    self.accMin=maxAndMinDict['v_Acc']['min']\n",
    "            self.valueDictList.append(copy.deepcopy(valueDict))\n",
    "            self.sizeList.append(valueDict.keys().__len__()-self.allTensorsEachBatch)\n",
    "            sortedKeys=list(valueDict.keys())\n",
    "            sortedKeys.sort()\n",
    "            self.keysList.append(copy.deepcopy(sortedKeys))\n",
    "\n",
    "    def getNormalizationDict(self):\n",
    "        '''\n",
    "        Returns:\n",
    "            a dict:{'positionXMax':self.positionXMax,'positonYMax':self.self.positionYMax,\\\n",
    "               'positionXMin':self.positionXMin,'positionYMin':self.positionYMin,\\\n",
    "               'speedMax':self.speedMax,'speedMin':speedMin,\\\n",
    "               'accMax':self.accMax,'accMax':self.accMin}\n",
    "        '''\n",
    "        if not doNormalization:\n",
    "            raise Exception('NORMALIZATION IS NOT APPLIED')\n",
    "        return {'positionXMax':self.positionXMax,'positionYMax':self.positionYMax,\\\n",
    "               'positionXMin':self.positionXMin,'positionYMin':self.positionYMin,\\\n",
    "               'speedMax':self.speedMax,'speedMin':self.speedMin,\\\n",
    "               'accMax':self.accMax,'accMax':self.accMin}\n",
    "    \n",
    "    def __len__(self):\n",
    "        allLen=0\n",
    "        for length in self.sizeList:\n",
    "            allLen=allLen+length\n",
    "        return allLen\n",
    "    \n",
    "    def fromIdxMapToList(self,idx):\n",
    "        \"\"\"\n",
    "        since there are several lists,we have to know which list shoud we use and the true index in the list\n",
    "        Return:\n",
    "            the trueIndex, listIndex\n",
    "        \"\"\"\n",
    "        countSection=0\n",
    "        for i in range(0,self.sizeList.__len__()):\n",
    "            countSection+=self.sizeList[i]\n",
    "            if(idx<countSection):\n",
    "                return idx-countSection+self.sizeList[i],i\n",
    "            \n",
    "    \n",
    "            \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        #initialize trueIndex, listIndex\n",
    "        #\n",
    "        #this dict record the relation between matrix index and vehicle ID in the last frame\n",
    "        matrixIndexAndVehicleIDRecordDict={}\n",
    "        #initialize dict above\n",
    "        for i in range(0,maxMatrixIndex):\n",
    "            matrixIndexAndVehicleIDRecordDict[i]={'Vehicle_ID':-1,'refresh':-1}\n",
    "        matrixIndexAndVehicleIDRecordDict['time']=-1\n",
    "        trueIndex,listIndex=self.fromIdxMapToList(idx)\n",
    "        itemDict={'positionTensorList':[],'speedTensorList':[],'accTensorList':[],'angleTensorList':[],'time':[]}\n",
    "        valueDict=self.valueDictList[listIndex] #valueDict is the Dict of many frames\n",
    "        dictKeys=self.keysList[listIndex]\n",
    "        #generate tensors of first frame\n",
    "        positionTensor,speedTensor,accTensor,angleTensor,newVehicleList\\\n",
    "        =readFirstFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[trueIndex]])\n",
    "        angleSinTensor=torch.sin(angleTensor)\n",
    "        angleCosTensor=torch.cos(angleTensor)\n",
    "        #first frame normalization\n",
    "        if doNormalization:\n",
    "#             print('before nomalization')\n",
    "#             print(positionTensor.shape,speedTensor.shape,accTensor.shape)\n",
    "            positionTensor=torch.cat((torch.div(torch.sub(positionTensor[0,:],self.positionXMin),self.positionXMax-self.positionXMin).unsqueeze(0),\\\n",
    "                                     torch.div(torch.sub(positionTensor[1,:],self.positionYMin,),self.positionYMax-self.positionYMin).unsqueeze(0)),0)\n",
    "            speedTensor=torch.div(torch.sub(speedTensor,self.speedMin),self.speedMax-self.speedMin)\n",
    "            accTensor=torch.div(torch.sub(accTensor,self.accMin),self.accMax-self.accMin)\n",
    "#             print('after normalization')\n",
    "#             print(positionTensor.shape,speedTensor.shape,accTensor.shape)\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "        else:\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        allCombineTensorTrain=combinedTensor.unsqueeze(0)\n",
    "        allCombineTensorValid=0\n",
    "#         itemDict['positionTensorList'].append(positionTensor)\n",
    "#         itemDict['speedTensorList'].append(speedTensor)\n",
    "#         itemDict['accTensorList'].append(accTensor)\n",
    "#         itemDict['angleTensorList'].append(angleTensor)\n",
    "#         time=getValueByLable(['Global_Time'],valueDict[dictKeys[trueIndex]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]][0]\n",
    "#         itemDict['time'].append(time)\n",
    "        \n",
    "        for i in range(trueIndex+1,trueIndex+self.allTensorsEachBatch):\n",
    "            #generate tensor from general frame\n",
    "            positionTensor,speedTensor,accTensor,angleTensor,newVehicleList,vanishedVehicleList\\\n",
    "            =readGeneralFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[i]],positionTensor)\n",
    "            angleSinTensor=torch.sin(angleTensor)\n",
    "            angleCosTensor=torch.cos(angleTensor)\n",
    "            if doNormalization:\n",
    "                positionTensor=torch.cat((torch.div(torch.sub(positionTensor[0,:],self.positionXMin),self.positionXMax-self.positionXMin).unsqueeze(0),\\\n",
    "                                         torch.div(torch.sub(positionTensor[1,:],self.positionYMin,),self.positionYMax-self.positionYMin).unsqueeze(0)),0)\n",
    "                speedTensor=torch.div(torch.sub(speedTensor,self.speedMin),self.speedMax-self.speedMin)\n",
    "                accTensor=torch.div(torch.sub(accTensor,self.accMin),self.accMax-self.accMin)\n",
    "                combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                         speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                         accTensor.mul(angleCosTensor)),0)\n",
    "            else:\n",
    "                combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                         accTensor.mul(angleCosTensor)),0)\n",
    "            if i<self.numberOfTensorsEachBatch+trueIndex:\n",
    "                allCombineTensorTrain=torch.cat((allCombineTensorTrain,combinedTensor.unsqueeze(0)),0)\n",
    "            elif i==self.numberOfTensorsEachBatch+trueIndex:\n",
    "                allCombineTensorValid=combinedTensor.unsqueeze(0)\n",
    "            else:\n",
    "                allCombineTensorValid=torch.cat((allCombineTensorValid,combinedTensor.unsqueeze(0)),0)\n",
    "#             itemDict['positionTensorList'].append(positionTensor)\n",
    "#             itemDict['speedTensorList'].append(speedTensor)\n",
    "#             itemDict['accTensorList'].append(accTensor)\n",
    "#             itemDict['angleTensorList'].append(angleTensor)\n",
    "#             time=getValueByLable(['Global_Time'],valueDict[dictKeys[i]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]]\n",
    "#             itemDict['time'].append(time)\n",
    "#         return allCombineTensorTrain,allCombineTensorValid\n",
    "        #only consist of position tensor, ignore speed tensor and accelerate tensor\n",
    "        allCombineTensorTrain=allCombineTensorTrain[:,0:2,:]\n",
    "        allCombineTensorValid=allCombineTensorValid[:,0:2,:]\n",
    "        logging.debug(fromAllToStr('allCombineTensorTrain.shape:',allCombineTensorTrain.shape))\n",
    "        logging.debug(fromAllToStr('allCombineTensorValid.shape',allCombineTensorValid))\n",
    "        #apply multiple thread techenique to handle the time consuming relation computation\n",
    "        threadList=[]\n",
    "        manager=Manager()\n",
    "        relationDict=manager.dict()\n",
    "        discountDict=manager.dict()\n",
    "        for timestepI in range(allCombineTensorTrain.shape[0]):\n",
    "            newThread=Process(target=relationComputationWorker,\\\n",
    "                              args=(relationDict,discountDict,timestepI,\\\n",
    "                                    allCombineTensorTrain[0].squeeze().unsqueeze(0),self.givenRange,self.maxRelationNumber))\n",
    "#             newThread=computeRelationAndAllTheOtherTensorsWithDistanceThread\\\n",
    "#             (timestepI,'computeRelationThread'+str(timestepI),timestepI,\\\n",
    "#              allCombineTensorTrain[0].squeeze().unsqueeze(0),self.givenRange,self.maxRelationNumber)\n",
    "            newThread.start()\n",
    "            threadList.append(newThread)\n",
    "        timestepI=0\n",
    "        while timestepI<allCombineTensorTrain.shape[0]:\n",
    "            threadList[timestepI].join()\n",
    "            timestepI=timestepI+1\n",
    "        \n",
    "        for timestepI in range(allCombineTensorTrain.shape[0]):\n",
    "            if timestepI==0:\n",
    "                combinedRelationTensors,combinedDiscountParameterTensors\\\n",
    "                =relationDict[timestepI],discountDict[timestepI]\n",
    "            else:\n",
    "                newCombinedRelationTensors, newCombinedDiscountParameterTensors\\\n",
    "                =relationDict[timestepI],discountDict[timestepI]\n",
    "                combinedRelationTensors=torch.cat((combinedRelationTensors,newCombinedRelationTensors),0)\n",
    "                combinedDiscountParameterTensors=torch.cat((combinedDiscountParameterTensors,newCombinedDiscountParameterTensors),0)\n",
    "        \n",
    "#         combinedRelationTensors,combinedDiscountParameterTensors=\\\n",
    "#         computeRelationAndAllTheOtherTensorsWithDistance(\\\n",
    "#         allCombineTensorTrain,theGivenRange=self.givenRange,\\\n",
    "#         maxRelationsNumber=self.maxRelationNumber)\n",
    "        #permute the dimension order of the valid tensor\n",
    "        logging.debug(fromAllToStr('allCombineTensorValid.shape:',allCombineTensorValid.shape))\n",
    "        differenceLabels=differenceBetweenTwoFrameForTimeSteps(torch.cat((allCombineTensorTrain[-1].unsqueeze(0),allCombineTensorValid),0).permute(0,2,1)) \n",
    "        logging.debug(fromAllToStr(\"differenceLabels.shape:\",differenceLabels.shape))\n",
    "        return allCombineTensorTrain, allCombineTensorValid,\\\n",
    "        combinedRelationTensors, combinedDiscountParameterTensors,differenceLabels\n",
    "        \n",
    "        \n",
    "            \n",
    "# trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0805am-0820am/trajectories-0805am-0820am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0820am-0835am/trajectories-0820am-0835am.txt']\n",
    "trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n",
    "#run on 2080 in g814\n",
    "if runOnG814:\n",
    "    trajectoryFileList=['/home/wangyuchen/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datasetV2=tensorsDatasetV2(trajectoryFileList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "dataIter=iter(datasetV2)\n",
    "first,second=dataIter.__next__()\n",
    "print(first.shape, second.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maxMatrixIndex=250\n",
    "dataloaderV2=DataLoader(datasetV2,batch_size=4,shuffle=True)\n",
    "for i,item in enumerate(dataloaderV2):\n",
    "    if(i>0):\n",
    "        break\n",
    "    print(i)\n",
    "    first,second=item\n",
    "    print(first.shape,second.shape)\n",
    "    print(first[0,:5,:6])\n",
    "    print(first[0,(2,245,246,247,248,249,250,251),6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def generateAdjacencyMatrix(batchedPositionTensor,lambdaX,lambdaY,omegaX,omegaY,m):\n",
    "    \"\"\"\n",
    "    Using batched position tensor generate batched adjacency matrix\n",
    "    Args:\n",
    "        batchedPositionTensor: a batch of position tensor, which size in (batch, timeSequence,2,vehicles), the \n",
    "        value 2 in dim=2 is the position of x and y. \n",
    "        lambda1,lambda2,omega1,omega2,m are parameters of the function. m<1\n",
    "        see detail in my notebook\n",
    "    Returns:\n",
    "        a batch of adjacency matrix\n",
    "    Example:\n",
    "        if given a batch of combined tensor, named theTensor, which size as below:\n",
    "            (4,100,6,250)\n",
    "        which means 4 batches, 100 time step, 6 dimension which respectively of positonx, positony, velocityx, \n",
    "        velocityy, accx,accy.\n",
    "        then we apply the function in such way:\n",
    "        generateAdjacencyMatrix(theTensor(:,:,0:1,:))\n",
    "    \"\"\"\n",
    "    print(batchedPositionTensor.size())\n",
    "    sizeOfEachMatrix=batchedPositionTensor[0,0,0,:].size()[0]\n",
    "    print(sizeOfEachMatrix)\n",
    "    for batchI in range(batchedPositionTensor.size()[0]): #revolve each batch\n",
    "#         print('batchI',batchI)\n",
    "        timeStepsMatrixList=[]\n",
    "        for timeStepI in range(batchedPositionTensor.size()[1]):#revolve each time step\n",
    "#             print('timeStepI:',timeStepI)\n",
    "#             adjacencyMatrix=np.zeros((sizeOfEachMatrix,sizeOfEachMatrix))\n",
    "            adjacencyList=[]\n",
    "            tempPositionList=batchedPositionTensor[batchI,timeStepI,:,:].numpy().tolist()\n",
    "#             start=time.time()\n",
    "            for i in range(sizeOfEachMatrix):\n",
    "                tempLineList=[]\n",
    "                for j in range(sizeOfEachMatrix):\n",
    "#                     adjacencyMatrix[i,j]=1\n",
    "                    if (tempPositionList[1][i]*tempPositionList[1][j]==0):\n",
    "                        toZero=0\n",
    "                    else:\n",
    "                        toZero=1\n",
    "                        \n",
    "                    #calculate original element with linear function\n",
    "#                     tempLineList.append((1-abs(tempPositionList[1][i]-tempPositionList[1][j]))*\\\n",
    "#                         (1-abs(tempPositionList[0][i]-tempPositionList[0][j]))*toZero)\n",
    "                    \n",
    "                    #calculate original element with exponential function\n",
    "                    element=(omegaY/(math.exp(lambdaY*(abs(tempPositionList[1][j]-tempPositionList[1][i])))))*\\\n",
    "                    (omegaX/(math.exp(lambdaX*(abs(tempPositionList[0][j]-tempPositionList[0][i])))))*toZero\n",
    "                    tempLineList.append(element)\n",
    "#                     adjacencyMatrix[i,j]=(batchedPositionTensor[batchI,timeStepI,1,i]-batchedPositionTensor[batchI,timeStepI,1,j])*\\\n",
    "#                         (batchedPositionTensor[batchI,timeStepI,0,i]-batchedPositionTensor[batchI,timeStepI,0,j])\n",
    "#                     (omegaY/math.exp(lambdaX*abs(batchedPositionTensor[batchI,timeStepI,1,i]-batchedPositionTensor[batchI,timeStepI,1,j])))*\\\n",
    "#                     (omegaX/math.exp(lambdaY*abs(batchedPositionTensor[batchI,timeStepI,0,i]-batchedPositionTensor[batchI,timeStepI,0,j])))\n",
    "                    \n",
    "                    #calculate original element with expenential\n",
    "#                     adjacencyMatrix[i,j]=\n",
    "#                     (omegaY/math.exp(lambdaX*abs(batchedPositionTensor[batchI,timeStepI,1,i]-batchedPositionTensor[batchI,timeStepI,1,j])))*\\\n",
    "#                     (omegaX/math.exp(lambdaY*abs(batchedPositionTensor[batchI,timeStepI,0,i]-batchedPositionTensor[batchI,timeStepI,0,j])))\n",
    "                    if(tempPositionList[1][j]-tempPositionList[1][i]<0):\n",
    "                        #if i follows j, then multiple m, m<1\n",
    "                        tempLineList[j]=tempLineList[j]*m\n",
    "                adjacencyList.append(tempLineList)\n",
    "            \n",
    "#             end=time.time()\n",
    "#             print(end-start)\n",
    "            adjacencyMatrix=torch.tensor(adjacencyList).unsqueeze(0)\n",
    "            if timeStepI==0:\n",
    "                matrixSequenceInTimeStepDim=adjacencyMatrix\n",
    "            else:\n",
    "                matrixSequenceInTimeStepDim=\\\n",
    "                torch.cat((matrixSequenceInTimeStepDim,adjacencyMatrix),0)\n",
    "        matrixSequenceInTimeStepDim=matrixSequenceInTimeStepDim.unsqueeze(0)\n",
    "        if batchI==0:\n",
    "            matrixSequenceInBatchDim=matrixSequenceInTimeStepDim\n",
    "        else:\n",
    "            matrixSequenceInBatchDim=torch.cat((matrixSequenceInBatchDim,matrixSequenceInTimeStepDim),0)            \n",
    "    return matrixSequenceInBatchDim\n",
    "\n",
    "def tensorNormalization(inputTensor,minValue,maxValue):\n",
    "    inputTensor.div_(maxValue)\n",
    "    \n",
    "def batchNormalizationForCombinedTensor(inputBatchedTensor,minX,maxX,minY,maxY,minV,maxV,minA,maxA):\n",
    "    tensorNormalization(inputBatchedTensor[:,:,0,:],minX,maxX)\n",
    "    tensorNormalization(inputBatchedTensor[:,:,1,:],minY,maxY)\n",
    "    tensorNormalization(inputBatchedTensor[:,:,2:4,:],minV,maxV)\n",
    "    tensorNormalization(inputBatchedTensor[:,:,4:6,:],minA,maxA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    __init__(self, input_size, cell_size, hidden_size, output_last = True)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, cell_size, hidden_size, output_last = True):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        \"\"\"\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((input, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "            return Hidden_State\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# maxMatrixIndex=250\n",
    "# trajectorDataSet=tensorsDataset(trajectoryFileList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataLoader=DataLoader(trajectorDataSet,batch_size=1,shuffle=True,num_workers=4)\n",
    "# for i,data in enumerate(dataLoader):\n",
    "#     print('11111')\n",
    "#     if(i>10):\n",
    "#         break\n",
    "#     print(data[0].shape)\n",
    "#     print(data[0][0,:,1,1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code fragment below is used to visualize tensor data\n",
    "# dataLoader=DataLoader(trajectorDataSet,batch_size=1,shuffle=True,num_workers=4)\n",
    "# for dataI,data in enumerate(dataLoader):\n",
    "#     if(dataI>10):\n",
    "#         break\n",
    "#     for i in range(int(data[0][0,:,0,0].shape[0])):\n",
    "#         tensorImage=visualizeTensorData(data[0][0,i,0,:],data[0][0,i,1,:],2500,100,10) \n",
    "#         fileName=str(100000+dataI)+'_'+str(100000+i)+'.png'\n",
    "#         cv2.imwrite('./tensorVisualizeFolder/'+fileName,tensorImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class relationNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    process objects to generate relation tensors\n",
    "    \"\"\"\n",
    "    def __init__(self,inputSize=4,outputSize=30,size1=10,size2=10,size3=10,size4=10):\n",
    "        super(relationNetwork,self).__init__()\n",
    "        self.size1=size1\n",
    "        self.size2=size2\n",
    "        self.size3=size3\n",
    "        self.size4=size4\n",
    "        self.layer1=nn.Linear(inputSize,size1)\n",
    "        self.layer2=nn.Linear(size1,size2)\n",
    "        self.layer3=nn.Linear(size2,size3)\n",
    "        self.layer4=nn.Linear(size3,size4)\n",
    "        self.layer5=nn.Linear(size4,outputSize)\n",
    "        self.ReLU=nn.ReLU()\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x1=self.ReLU(self.layer1(inputs))\n",
    "        x2=self.ReLU(self.layer2(x1))\n",
    "        x3=self.ReLU(self.layer3(x2))\n",
    "        x4=self.ReLU(self.layer4(x3))\n",
    "        outputs=self.ReLU(self.layer5(x4))\n",
    "        return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class effectNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    process relationTensor to generate effect tensors\n",
    "    \"\"\"\n",
    "    def __init__(self,inputSize=4,outputSize=30,size1=10,size2=10,size3=10,size4=10):\n",
    "        super(effectNetwork,self).__init__()\n",
    "        self.size1=size1\n",
    "        self.size2=size2\n",
    "        self.size3=size3\n",
    "        self.size4=size4\n",
    "        self.layer1=nn.Linear(inputSize,size1)\n",
    "        self.layer2=nn.Linear(size1,size2)\n",
    "        self.layer3=nn.Linear(size2,size3)\n",
    "        self.layer4=nn.Linear(size3,size4)\n",
    "        self.layer5=nn.Linear(size4,outputSize)\n",
    "        self.ReLU=nn.ReLU()\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x1=self.ReLU(self.layer1(inputs))\n",
    "        x2=self.ReLU(self.layer2(x1))\n",
    "        x3=self.ReLU(self.layer3(x2))\n",
    "        x4=self.ReLU(self.layer4(x3))\n",
    "        outputs=self.ReLU(self.layer5(x4))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class effectCombinationNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    process effect tensor to generate combined effect tensors\n",
    "    \"\"\"\n",
    "    def __init__(self,inputSize=4,outputSize=30,size1=10,size2=10,size3=10,size4=10):\n",
    "        super(effectCombinationNetwork,self).__init__()\n",
    "        self.size1=size1\n",
    "        self.size2=size2\n",
    "        self.size3=size3\n",
    "        self.size4=size4\n",
    "        self.layer1=nn.Linear(inputSize,size1)\n",
    "        self.layer2=nn.Linear(size1,size2)\n",
    "        self.layer3=nn.Linear(size2,size3)\n",
    "        self.layer4=nn.Linear(size3,size4)\n",
    "        self.layer5=nn.Linear(size4,outputSize)\n",
    "        self.ReLU=nn.ReLU()\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x1=self.ReLU(self.layer1(inputs))\n",
    "        x2=self.ReLU(self.layer2(x1))\n",
    "        x3=self.ReLU(self.layer3(x2))\n",
    "        x4=self.ReLU(self.layer4(x3))\n",
    "        outputs=self.ReLU(self.layer5(x4))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class objectModifyNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    modify object with effect tensors\n",
    "    \"\"\"\n",
    "    def __init__(self,inputSize=4,outputSize=30,size1=10,size2=10,size3=10,size4=10):\n",
    "        super(objectModifyNetwork,self).__init__()\n",
    "        self.size1=size1\n",
    "        self.size2=size2\n",
    "        self.size3=size3\n",
    "        self.size4=size4\n",
    "        self.layer1=nn.Linear(inputSize,size1)\n",
    "        self.layer2=nn.Linear(size1,size2)\n",
    "        self.layer3=nn.Linear(size2,size3)\n",
    "        self.layer4=nn.Linear(size3,size4)\n",
    "        self.layer5=nn.Linear(size4,outputSize)\n",
    "        self.ReLU=nn.ReLU()\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x1=self.ReLU(self.layer1(inputs))\n",
    "        x2=self.ReLU(self.layer2(x1))\n",
    "        x3=self.ReLU(self.layer3(x2))\n",
    "        x4=self.ReLU(self.layer4(x3))\n",
    "        outputs=self.layer5(x4)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hiddenStateToEffectNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    process hidden state tensor to generate combined effect tensors\n",
    "    \"\"\"\n",
    "    def __init__(self,inputSize=4,outputSize=30,size1=10,size2=10,size3=10,size4=10):\n",
    "        super(hiddenStateToEffectNetwork,self).__init__()\n",
    "        self.size1=size1\n",
    "        self.size2=size2\n",
    "        self.size3=size3\n",
    "        self.size4=size4\n",
    "        self.layer1=nn.Linear(inputSize,size1)\n",
    "        self.layer2=nn.Linear(size1,size2)\n",
    "        self.layer3=nn.Linear(size2,size3)\n",
    "        self.layer4=nn.Linear(size3,size4)\n",
    "        self.layer5=nn.Linear(size4,outputSize)\n",
    "        self.ReLU=nn.ReLU()\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x1=self.ReLU(self.layer1(inputs))\n",
    "        x2=self.ReLU(self.layer2(x1))\n",
    "        x3=self.ReLU(self.layer3(x2))\n",
    "        x4=self.ReLU(self.layer4(x3))\n",
    "        outputs=self.ReLU(self.layer5(x4))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hiddenStateToDifferenceNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    process hidden state tensor to generate difference tensors\n",
    "    \"\"\"\n",
    "    def __init__(self,inputSize=4,outputSize=30,size1=10,size2=10,size3=10,size4=10):\n",
    "        super(hiddenStateToDifferenceNetwork,self).__init__()\n",
    "        self.size1=size1\n",
    "        self.size2=size2\n",
    "        self.size3=size3\n",
    "        self.size4=size4\n",
    "        self.layer1=nn.Linear(inputSize,size1)\n",
    "        self.layer2=nn.Linear(size1,size2)\n",
    "        self.layer3=nn.Linear(size2,size3)\n",
    "        self.layer4=nn.Linear(size3,size4)\n",
    "        self.layer5=nn.Linear(size4,outputSize)\n",
    "        self.ReLU=nn.ReLU()\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x1=self.ReLU(self.layer1(inputs))\n",
    "        x2=self.ReLU(self.layer2(x1))\n",
    "        x3=self.ReLU(self.layer3(x2))\n",
    "        x4=self.ReLU(self.layer4(x3))\n",
    "        outputs=self.ReLU(self.layer5(x4))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#this block build for relation network testing\n",
    "#delete later if needed\n",
    "relationTensorSize=40\n",
    "positionTuple=(0,1,6,7)\n",
    "velocityTuple=(2,3,8,9)\n",
    "acclerateTuple=(4,5,10,11)\n",
    "positionRelationNet=relationNetwork(outputSize=relationTensorSize)\n",
    "velocityRelationNet=relationNetwork(outputSize=relationTensorSize)\n",
    "accelerateRelationNet=relationNetwork(outputSize=relationTensorSize)\n",
    "\n",
    "maxMatrixIndex=250\n",
    "\n",
    "#load test data in network testing block\n",
    "dataloaderV2=DataLoader(datasetV2,batch_size=1,shuffle=True)\n",
    "for i,item in enumerate(dataloaderV2):\n",
    "    if(i>0):\n",
    "        break\n",
    "    print(i)\n",
    "    first,second=item\n",
    "#     print(first.shape,second.shape)\n",
    "#     print(first[0,:5,:6])\n",
    "#     print(first[0,(2,245,246,247,248,249,250,251),6:])\n",
    "    #from frame to position, velocity, accelerate\n",
    "    positionRelationTensors=positionRelationNet(first[:,:,positionTuple])\n",
    "    velocityRelationTensors=velocityRelationNet(first[:,:,velocityTuple])\n",
    "    accelerateRelationTensors=accelerateRelationNet(first[:,:,acclerateTuple])\n",
    "    print(positionRelationTensors.shape)\n",
    "    objectsAndRelationTensors=torch.cat((first[:,:,positionTuple],positionRelationTensors),2)\n",
    "    print(objectsAndRelationTensors.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "objectAndTensorSize=relationTensorSize+4 \n",
    "effectOutputTensorSize=20\n",
    "\n",
    "#the number 4 is is the size of positon(or velocity or accelerate) pairs,\n",
    "#such as (positonxObject1,positonyObject1,positionxObject2,positionyObject2)\n",
    "positionEffectNet=effectNetwork(inputSize=objectAndTensorSize,outputSize=effectOutputTensorSize)\n",
    "velocityEffectNet=effectNetwork(inputSize=objectAndTensorSize,outputSize=effectOutputTensorSize)\n",
    "accelerateEffectNet=effectNetwork(inputSize=objectAndTensorSize,outputSize=effectOutputTensorSize)\n",
    "first,second=next(iter(dataloaderV2))\n",
    "print(first.shape)\n",
    "\n",
    "#relation computation\n",
    "positionRelationTensors=positionRelationNet(first[:,:,positionTuple])\n",
    "velocityRelationTensors=velocityRelationNet(first[:,:,velocityTuple])\n",
    "accelerateRelationTensors=accelerateRelationNet(first[:,:,acclerateTuple])\n",
    "                                                      \n",
    "objectsAndPositionRelationTensors=torch.cat((first[:,:,positionTuple],positionRelationTensors),2)\n",
    "objectsAndVelocityRelationTensors=torch.cat((first[:,:,positionTuple],velocityRelationTensors),2)\n",
    "objectsAndAccelerateRelationTensors=torch.cat((first[:,:,positionTuple],accelerateRelationTensors),2)\n",
    "\n",
    "#effect computation\n",
    "positionEffectTensors=positionEffectNet(objectsAndPositionRelationTensors)\n",
    "velocityEffectTensors=velocityEffectNet(objectsAndVelocityRelationTensors)\n",
    "accelerateEffectTensors=accelerateEffectNet(objectsAndAccelerateRelationTensors)\n",
    "\n",
    "#effect combination type 1\n",
    "#tensor summation\n",
    "batchSize=positionRelationTensors.shape[0]\n",
    "positionEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "velocityEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "accelerateEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "for i in range(maxMatrixIndex):\n",
    "    positionEffectSummation[:,i,:]=torch.sum(positionEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "    velocityEffectSummation[:,i,:]=torch.sum(velocityEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "    accelerateEffectSummation[:,i,:]=torch.sum(accelerateEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "    \n",
    "#effect combination net initial\n",
    "#combined tensors length\n",
    "combinedTensorSize=20\n",
    "effectCombinationNet=effectCombinationNetwork(inputSize=effectOutputTensorSize*3,outputSize=combinedTensorSize)\n",
    "\n",
    "#combine tensors and process the combined one\n",
    "combinedEffectTensors=torch.cat((positionEffectSummation,velocityEffectSummation,accelerateEffectSummation),2)\n",
    "print(combinedEffectTensors.shape)\n",
    "processedCombinedEffectTensors=effectCombinationNet(combinedEffectTensors)\n",
    "print(processedCombinedEffectTensors.shape)\n",
    "\n",
    "#generate a tuple in which each element is the index of a vehicle\n",
    "#the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "#this part has been put into init function of Module class\n",
    "listForEachVehicle=[]\n",
    "for i in range(maxMatrixIndex):\n",
    "    listForEachVehicle.append(i*(maxMatrixIndex-1))\n",
    "tupleForEachVehicle=tuple(listForEachVehicle)\n",
    "\n",
    "#the property of each vehicle\n",
    "vehicleProperty=first[:,tupleForEachVehicle,0:6]\n",
    "\n",
    "objectAndFinalEffect=torch.cat((vehicleProperty,processedCombinedEffectTensors),2)\n",
    "print(objectAndFinalEffect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#initialize the final network to generate new objects properties\n",
    "objectModifyNet=objectModifyNetwork(inputSize=combinedTensorSize+6,outputSize=6)\n",
    "finalObjectState=objectModifyNet(objectAndFinalEffect)\n",
    "print(finalObjectState.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from relation to new object network\n",
    "class fromRelationToObjectNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fromRelationToObjectNetwork,self).__init__()\n",
    "        self.maxMatrixIndex=250\n",
    "        #generate a tuple in which each element is the index of a vehicle\n",
    "        #the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "        listForEachVehicle=[]\n",
    "        for i in range(self.maxMatrixIndex):\n",
    "            listForEachVehicle.append(i*(self.maxMatrixIndex-1))\n",
    "        self.tupleForEachVehicle=tuple(listForEachVehicle)\n",
    "        \n",
    "        #position relation network initialize\n",
    "        self.relationTensorSize=40\n",
    "        self.positionTuple=(0,1,6,7)\n",
    "        self.velocityTuple=(2,3,8,9)\n",
    "        self.acclerateTuple=(4,5,10,11)\n",
    "        self.positionRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "        self.velocityRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "        self.accelerateRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "        \n",
    "        #effect network initialize\n",
    "        self.objectAndTensorSize=self.relationTensorSize+4 \n",
    "        self.effectOutputTensorSize=20\n",
    "        #the number 4 is is the size of positon(or velocity or accelerate) pairs,\n",
    "        #such as (positonxObject1,positonyObject1,positionxObject2,positionyObject2)\n",
    "        self.positionEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "        self.velocityEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "        self.accelerateEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "        \n",
    "        #effect combination net initialize\n",
    "        #combined tensors length\n",
    "        self.combinedTensorSize=20\n",
    "        self.effectCombinationNet=\\\n",
    "        effectCombinationNetwork(inputSize=self.effectOutputTensorSize*3,outputSize=self.combinedTensorSize)\n",
    "        \n",
    "        #initialize the final network to generate new objects properties\n",
    "        self.objectModifyNet=objectModifyNetwork(inputSize=self.combinedTensorSize+6,outputSize=6)\n",
    "        \n",
    "    def forward(self,inputObjectsPairs):\n",
    "        #relation computation\n",
    "        positionRelationTensors=self.positionRelationNet(inputObjectsPairs[:,:,self.positionTuple])\n",
    "        velocityRelationTensors=self.velocityRelationNet(inputObjectsPairs[:,:,self.velocityTuple])\n",
    "        accelerateRelationTensors=self.accelerateRelationNet(inputObjectsPairs[:,:,self.acclerateTuple])\n",
    "\n",
    "        objectsAndPositionRelationTensors=torch.cat((inputObjectsPairs[:,:,self.positionTuple],positionRelationTensors),2)\n",
    "        objectsAndVelocityRelationTensors=torch.cat((inputObjectsPairs[:,:,self.velocityTuple],velocityRelationTensors),2)\n",
    "        objectsAndAccelerateRelationTensors=torch.cat((inputObjectsPairs[:,:,self.acclerateTuple],accelerateRelationTensors),2)\n",
    "\n",
    "        #effect computation\n",
    "        positionEffectTensors=self.positionEffectNet(objectsAndPositionRelationTensors)\n",
    "        velocityEffectTensors=self.velocityEffectNet(objectsAndVelocityRelationTensors)\n",
    "        accelerateEffectTensors=self.accelerateEffectNet(objectsAndAccelerateRelationTensors)\n",
    "\n",
    "        \n",
    "        #effect combination type 1\n",
    "        #tensor summation\n",
    "        batchSize=positionRelationTensors.shape[0]\n",
    "        if useGpu==True:\n",
    "            positionEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "            velocityEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "            accelerateEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "        else: \n",
    "            positionEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "            velocityEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "            accelerateEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "        for i in range(maxMatrixIndex):\n",
    "            positionEffectSummation[:,i,:]=torch.sum(positionEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "            velocityEffectSummation[:,i,:]=torch.sum(velocityEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "            accelerateEffectSummation[:,i,:]=torch.sum(accelerateEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "        combinedEffectTensors=torch.cat((positionEffectSummation,velocityEffectSummation,accelerateEffectSummation),2)\n",
    "        processedCombinedEffectTensors=self.effectCombinationNet(combinedEffectTensors)\n",
    "        \n",
    "        #the property of each vehicle\n",
    "        vehicleProperty=inputObjectsPairs[:,self.tupleForEachVehicle,0:6]\n",
    "        objectAndFinalEffect=torch.cat((vehicleProperty,processedCombinedEffectTensors),2)\n",
    "        \n",
    "        #compute final state\n",
    "        finalObjectState=self.objectModifyNet(objectAndFinalEffect)\n",
    "        return finalObjectState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This module is supposed to be placed in LSTM model\n",
    "class fromRelationToEffectNetwork(nn.Module):\n",
    "    def __init__(self,effectOutputTensorSize=20):\n",
    "        super(fromRelationToEffectNetwork,self).__init__()\n",
    "        self.maxMatrixIndex=250\n",
    "        #generate a tuple in which each element is the index of a vehicle\n",
    "        #the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "        listForEachVehicle=[]\n",
    "        for i in range(self.maxMatrixIndex):\n",
    "            listForEachVehicle.append(i*(self.maxMatrixIndex-1))\n",
    "        self.tupleForEachVehicle=tuple(listForEachVehicle)\n",
    "        \n",
    "        #position relation network initialize\n",
    "        self.relationTensorSize=40\n",
    "        self.positionTuple=(0,1,6,7)\n",
    "        self.velocityTuple=(2,3,8,9)\n",
    "        self.acclerateTuple=(4,5,10,11)\n",
    "        self.positionRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "        self.velocityRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "        self.accelerateRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "        \n",
    "        #effect network initialize\n",
    "        self.objectAndTensorSize=self.relationTensorSize+4 \n",
    "        self.effectOutputTensorSize=effectOutputTensorSize\n",
    "        #the number 4 is the size of positon(or velocity or accelerate) pairs,\n",
    "        #such as (positonxObject1,positonyObject1,positionxObject2,positionyObject2)\n",
    "        self.positionEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "        self.velocityEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "        self.accelerateEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "        \n",
    "        #effect combination net initialize\n",
    "        #combined tensors length\n",
    "        self.combinedTensorSize=20\n",
    "        self.effectCombinationNet=\\\n",
    "        effectCombinationNetwork(inputSize=self.effectOutputTensorSize*3,outputSize=self.combinedTensorSize)\n",
    "        \n",
    "        #remove objectModifyNet in objectToEffectModel\n",
    "        #initialize the final network to generate new objects properties\n",
    "#         self.objectModifyNet=objectModifyNetwork(inputSize=self.combinedTensorSize+6,outputSize=6)\n",
    "        \n",
    "    def forward(self,inputObjectsPairs):\n",
    "        #relation computation\n",
    "        effectOutputTensorSize=self.effectOutputTensorSize\n",
    "        positionRelationTensors=self.positionRelationNet(inputObjectsPairs[:,:,self.positionTuple])\n",
    "        velocityRelationTensors=self.velocityRelationNet(inputObjectsPairs[:,:,self.velocityTuple])\n",
    "        accelerateRelationTensors=self.accelerateRelationNet(inputObjectsPairs[:,:,self.acclerateTuple])\n",
    "\n",
    "        objectsAndPositionRelationTensors=torch.cat((inputObjectsPairs[:,:,self.positionTuple],positionRelationTensors),2)\n",
    "        objectsAndVelocityRelationTensors=torch.cat((inputObjectsPairs[:,:,self.velocityTuple],velocityRelationTensors),2)\n",
    "        objectsAndAccelerateRelationTensors=torch.cat((inputObjectsPairs[:,:,self.acclerateTuple],accelerateRelationTensors),2)\n",
    "\n",
    "        #effect computation\n",
    "        positionEffectTensors=self.positionEffectNet(objectsAndPositionRelationTensors)\n",
    "        velocityEffectTensors=self.velocityEffectNet(objectsAndVelocityRelationTensors)\n",
    "        accelerateEffectTensors=self.accelerateEffectNet(objectsAndAccelerateRelationTensors)\n",
    "\n",
    "        \n",
    "        #effect combination type 1\n",
    "        #tensor summation\n",
    "        batchSize=positionRelationTensors.shape[0]\n",
    "        if useGpu==True:\n",
    "            positionEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "            velocityEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "            accelerateEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "        else: \n",
    "            positionEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "            velocityEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "            accelerateEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "        for i in range(maxMatrixIndex):\n",
    "            positionEffectSummation[:,i,:]=torch.sum(positionEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "            velocityEffectSummation[:,i,:]=torch.sum(velocityEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "            accelerateEffectSummation[:,i,:]=torch.sum(accelerateEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "        combinedEffectTensors=torch.cat((positionEffectSummation,velocityEffectSummation,accelerateEffectSummation),2)\n",
    "        processedCombinedEffectTensors=self.effectCombinationNet(combinedEffectTensors)\n",
    "        \n",
    "        #remove object extraction component and computation component\n",
    "#         #the property of each vehicle\n",
    "#         vehicleProperty=inputObjectsPairs[:,self.tupleForEachVehicle,0:6]\n",
    "#         objectAndFinalEffect=torch.cat((vehicleProperty,processedCombinedEffectTensors),2)\n",
    "        \n",
    "#         #compute final state\n",
    "#         finalObjectState=self.objectModifyNet(objectAndFinalEffect)\n",
    "        return processedCombinedEffectTensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This module is supposed to be placed in LSTM model\n",
    "class fromRelationToEffectNetworkPositionOnly(nn.Module):\n",
    "    def __init__(self,effectOutputTensorSize=20):\n",
    "        super(fromRelationToEffectNetworkPositionOnly,self).__init__()\n",
    "        self.maxMatrixIndex=250\n",
    "        #generate a tuple in which each element is the index of a vehicle\n",
    "        #the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "        listForEachVehicle=[]\n",
    "        for i in range(self.maxMatrixIndex):\n",
    "            listForEachVehicle.append(i*(self.maxMatrixIndex-1))\n",
    "        self.tupleForEachVehicle=tuple(listForEachVehicle)\n",
    "        \n",
    "        #position relation network initialize\n",
    "        self.relationTensorSize=40\n",
    "        self.positionTuple=(0,1,6,7)\n",
    "#         self.velocityTuple=(2,3,8,9)\n",
    "#         self.acclerateTuple=(4,5,10,11)\n",
    "        self.positionRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "#         self.velocityRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "#         self.accelerateRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "        \n",
    "        #effect network initialize\n",
    "        self.objectAndTensorSize=self.relationTensorSize+4 \n",
    "        self.effectOutputTensorSize=effectOutputTensorSize\n",
    "        #the number 4 is the size of positon(or velocity or accelerate) pairs,\n",
    "        #such as (positonxObject1,positonyObject1,positionxObject2,positionyObject2)\n",
    "        self.positionEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "#         self.velocityEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "#         self.accelerateEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "        \n",
    "        #effect combination net initialize\n",
    "        #combined tensors length\n",
    "#         self.combinedTensorSize=20\n",
    "#         self.effectCombinationNet=\\\n",
    "#         effectCombinationNetwork(inputSize=self.effectOutputTensorSize*3,outputSize=self.combinedTensorSize)\n",
    "        \n",
    "        #remove objectModifyNet in objectToEffectModel\n",
    "        #initialize the final network to generate new objects properties\n",
    "#         self.objectModifyNet=objectModifyNetwork(inputSize=self.combinedTensorSize+6,outputSize=6)\n",
    "        \n",
    "    def forward(self,inputObjectsPairs):\n",
    "        #relation computation\n",
    "        effectOutputTensorSize=self.effectOutputTensorSize\n",
    "        positionRelationTensors=self.positionRelationNet(inputObjectsPairs[:,:,self.positionTuple])\n",
    "#         velocityRelationTensors=self.velocityRelationNet(inputObjectsPairs[:,:,self.velocityTuple])\n",
    "#         accelerateRelationTensors=self.accelerateRelationNet(inputObjectsPairs[:,:,self.acclerateTuple])\n",
    "\n",
    "        objectsAndPositionRelationTensors=torch.cat((inputObjectsPairs[:,:,self.positionTuple],positionRelationTensors),2)\n",
    "#         objectsAndVelocityRelationTensors=torch.cat((inputObjectsPairs[:,:,self.velocityTuple],velocityRelationTensors),2)\n",
    "#         objectsAndAccelerateRelationTensors=torch.cat((inputObjectsPairs[:,:,self.acclerateTuple],accelerateRelationTensors),2)\n",
    "\n",
    "        #effect computation\n",
    "        positionEffectTensors=self.positionEffectNet(objectsAndPositionRelationTensors)\n",
    "#         velocityEffectTensors=self.velocityEffectNet(objectsAndVelocityRelationTensors)\n",
    "#         accelerateEffectTensors=self.accelerateEffectNet(objectsAndAccelerateRelationTensors)\n",
    "\n",
    "        \n",
    "        #effect combination type 1\n",
    "        #tensor summation\n",
    "        batchSize=positionRelationTensors.shape[0]\n",
    "        if useGpu==True:\n",
    "            positionEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "#             velocityEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "#             accelerateEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "        else: \n",
    "            positionEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "#             velocityEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "#             accelerateEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "        for i in range(maxMatrixIndex):\n",
    "            positionEffectSummation[:,i,:]=torch.sum(positionEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "#             velocityEffectSummation[:,i,:]=torch.sum(velocityEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "#             accelerateEffectSummation[:,i,:]=torch.sum(accelerateEffectTensors[:,(i*249):((i+1)*249),:],1)\n",
    "#         combinedEffectTensors=torch.cat((positionEffectSummation,velocityEffectSummation,accelerateEffectSummation),2)\n",
    "#         processedCombinedEffectTensors=self.effectCombinationNet(combinedEffectTensors)\n",
    "        \n",
    "        #remove object extraction component and computation component\n",
    "#         #the property of each vehicle\n",
    "#         vehicleProperty=inputObjectsPairs[:,self.tupleForEachVehicle,0:6]\n",
    "#         objectAndFinalEffect=torch.cat((vehicleProperty,processedCombinedEffectTensors),2)\n",
    "        \n",
    "#         #compute final state\n",
    "#         finalObjectState=self.objectModifyNet(objectAndFinalEffect)\n",
    "        return positionEffectSummation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationLSTM(nn.Module):\n",
    "    def __init__(self, input_size=20, cell_size=20, hidden_size=20, output_last = True):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        the input of LSTM  structure was the output of 'fromRelationToEffectNet' module, so that \n",
    "        the effectOutputTensorSize has the same number as input_size. \n",
    "        \n",
    "        \"\"\"\n",
    "        super(RelationLSTM, self).__init__()\n",
    "        self.maxMatrixIndex=250\n",
    "        \n",
    "        #generate a tuple in which each element is the index of a vehicle\n",
    "        #the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "        listForEachVehicle=[]\n",
    "        for i in range(self.maxMatrixIndex):\n",
    "            listForEachVehicle.append(i*(self.maxMatrixIndex-1))\n",
    "        self.tupleForEachVehicle=tuple(listForEachVehicle)\n",
    "        self.positionTuple=(0,1,6,7)\n",
    "        self.velocityTuple=(2,3,8,9)\n",
    "        self.acclerateTuple=(4,5,10,11)\n",
    "        \n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.fromRelationToEffectNet=fromRelationToEffectNetwork(effectOutputTensorSize=input_size)\n",
    "        self.objectModifyNet=objectModifyNetwork(inputSize=hidden_size+6,outputSize=6)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, inputEffectTensor, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((inputEffectTensor, Hidden_State), 2)\n",
    "        print('in step,combined.shape',combined.shape)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            for i in range(time_step):\n",
    "                effects=self.fromRelationToEffectNet(inputs[:,i,:,:])\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(effects), Hidden_State, Cell_State) \n",
    "                #the property of each vehicle\n",
    "            print(inputs.shape)\n",
    "            vehicleProperty=inputs[:,-1,self.tupleForEachVehicle,0:6].squeeze()\n",
    "            objectAndFinalEffect=torch.cat((vehicleProperty,Hidden_State),2)\n",
    "            outputState=self.objectModifyNet(objectAndFinalEffect)\n",
    "            return outputState\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "#         use_gpu = torch.cuda.is_available()\n",
    "        if useGpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size,maxMatrixIndex, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size,maxMatrixIndex, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, maxMatrixIndex,self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, maxMatrixIndex,self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def fromObjectsToRelationPairs(combinedTensor):\n",
    "    '''\n",
    "    Args:\n",
    "        The input tensor should already be transposed if it is generated from the network's output\n",
    "    Returns:\n",
    "        Relation pairs\n",
    "    '''\n",
    "    #generate relation tensor for all vehicle pairs\n",
    "    relationTensorLeft=combinedTensor[:,0].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])\n",
    "    relationTensorRight=torch.transpose(torch.cat((combinedTensor[:,:0],combinedTensor[:,1:]),1),0,1)\n",
    "#         print(relationTensorRight.shape,relationTensorRight.shape)\n",
    "    for i in range(1,combinedTensor.shape[1]):\n",
    "        relationTensorLeft=torch.cat((relationTensorLeft,\\\n",
    "                                      combinedTensor[:,i].expand(combinedTensor.shape[1]-1,combinedTensor.shape[0])),0)\n",
    "        relationTensorRight=torch.cat((relationTensorRight,\\\n",
    "                                       torch.transpose(torch.cat((combinedTensor[:,:i],combinedTensor[:,i+1:]),1),0,1)),0)\n",
    "#         print(relationTensorLeft.shape,relationTensorRight.shape)\n",
    "    combinedRelationTensor=torch.cat((relationTensorLeft,relationTensorRight),1) \n",
    "    return combinedRelationTensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationLSTMSeq2Seq(nn.Module):\n",
    "    def __init__(self, input_size=20, cell_size=20, hidden_size=20, \\\n",
    "                 input_size_2=20, cell_size_2=20,hidden_size_2=20, outputTimeFrame=5,output_last = True):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        the input of LSTM  structure was the output of 'fromRelationToEffectNet' module, so that \n",
    "        the effectOutputTensorSize has the same number as input_size. \n",
    "        \n",
    "        \"\"\"\n",
    "        super(RelationLSTMSeq2Seq, self).__init__()\n",
    "        self.maxMatrixIndex=250\n",
    "        \n",
    "        #generate a tuple in which each element is the index of a vehicle\n",
    "        #the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "        listForEachVehicle=[]\n",
    "        for i in range(self.maxMatrixIndex):\n",
    "            listForEachVehicle.append(i*(self.maxMatrixIndex-1))\n",
    "        self.tupleForEachVehicle=tuple(listForEachVehicle)\n",
    "        self.positionTuple=(0,1,6,7)\n",
    "        self.velocityTuple=(2,3,8,9)\n",
    "        self.acclerateTuple=(4,5,10,11)\n",
    "        \n",
    "        #effect representive vector computation lstm\n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        #object modifying lstm\n",
    "        self.cell_size2 = cell_size_2\n",
    "        self.hidden_size2 = hidden_size_2\n",
    "        self.fl2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        self.il2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        self.ol2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        self.Cl2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        \n",
    "        self.outputTimeFrame=outputTimeFrame\n",
    "\n",
    "        self.fromRelationToEffectNet=fromRelationToEffectNetwork(effectOutputTensorSize=input_size)\n",
    "        self.objectModifyNet=objectModifyNetwork(inputSize=hidden_size+6,outputSize=6)\n",
    "        self.hiddenStateToEffectNetwork=hiddenStateToEffectNetwork(inputSize=hidden_size,outputSize=input_size)\n",
    "        #descreption for the statement above: the input_size applied to the parameter outputSize is \n",
    "        #the size of effect tensor in the init function. \n",
    "        \n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, inputEffectTensor, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((inputEffectTensor, Hidden_State), 2)\n",
    "#         print('in step,combined.shape',combined.shape)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def step2(self, inputPreEffectTensor, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((inputPreEffectTensor, Hidden_State), 2)\n",
    "#         print('in step2,combined.shape',combined.shape)\n",
    "        f = F.sigmoid(self.fl2(combined))\n",
    "        i = F.sigmoid(self.il2(combined))\n",
    "        o = F.sigmoid(self.ol2(combined))\n",
    "        C = F.tanh(self.Cl2(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State,Hidden_State_2,Cell_State_2 = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            #effect computation\n",
    "            for i in range(time_step):\n",
    "                effects=self.fromRelationToEffectNet(inputs[:,i,:,:])\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(effects), Hidden_State, Cell_State) \n",
    "                #the property of each vehicle\n",
    "                \n",
    "            Hidden_State_2=Hidden_State\n",
    "            Cell_State_2=Cell_State\n",
    "            \n",
    "            #the lstm process below take as inputs the previous object states and output the next predicted states\n",
    "            #applying function permute to deal with the dimension inconsistency\n",
    "            '''\n",
    "            inputs should be processed by function \"fromObjectsToRelationPairsBatchAndTimestepVersion\" \n",
    "            IF DATASETV3 VERSION IS USED TO GET DATA\n",
    "            '''\n",
    "            print('in seq2seq, inputs shape:',inputs.shape)\n",
    "            preVehicleProperty=inputs[:,-1,self.tupleForEachVehicle,0:6].squeeze()\n",
    "            preVehicleRelations=inputs[:,-1,:,:]\n",
    "            \n",
    "            #object properties computation\n",
    "            for i in range(outputTimeFrame):\n",
    "                objectAndFinalEffect=torch.cat((preVehicleProperty,Hidden_State_2),2)  \n",
    "                preVehicleProperty=self.objectModifyNet(objectAndFinalEffect)\n",
    "                effects=self.fromRelationToEffectNet(preVehicleRelations)\n",
    "                Hidden_State_2,Cell_State_2=self.step2(torch.squeeze(effects),Hidden_State_2,Cell_State_2)\n",
    "                if i==0:\n",
    "                    #add dimension timestep, which in dimension 1\n",
    "                    outputVehicleProperties=preVehicleProperty.unsqueeze(1) \n",
    "                else:\n",
    "                    outputVehicleProperties=torch.cat((outputVehicleProperties,preVehicleProperty.unsqueeze(1)),1)\n",
    "                #don't need to compute new effect vector after the prediction of the last time step\n",
    "                if i<outputTimeFrame-1:\n",
    "                    effectFromHiddenState=self.hiddenStateToEffectNetwork(Hidden_State_2)\n",
    "                    self.objectModifyNet()\n",
    "                    preVehicleProperty.cpu()\n",
    "                    #add timestep dimension for further process\n",
    "                    preVehiclePropertyAddTimestep=preVehicleProperty.unsqueeze(1)\n",
    "                    relationPairs=fromObjectsToRelationPairsBatchAndTimestepVersion(preVehiclePropertyAddTimestep).squeeze()\n",
    "                    if useGpu:\n",
    "                        relationPairs.cuda()\n",
    "                    effectInPropertiesComputation=self.fromRelationToEffectNet(relationPairs)\n",
    "                    Hidden_State_2,Cell_State_2=self.step2(effectInPropertiesComputation,Hidden_State_2,Cell_State_2)\n",
    "                if i==outputTimeFrame:\n",
    "                    break\n",
    "#             print(inputs.shape)\n",
    "#             vehicleProperty=inputs[:,-1,self.tupleForEachVehicle,0:6].squeeze()\n",
    "#             objectAndFinalEffect=torch.cat((vehicleProperty,Hidden_State),2)\n",
    "#             outputState=self.objectModifyNet(objectAndFinalEffect)\n",
    "            return outputVehicleProperties\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "#         use_gpu = torch.cuda.is_available()\n",
    "        if useGpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size,maxMatrixIndex, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size,maxMatrixIndex, self.hidden_size).cuda())\n",
    "            Hidden_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2).cuda())\n",
    "            Cell_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2).cuda())\n",
    "            return Hidden_State, Cell_State,Hidden_State_2,Cell_State_2\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, maxMatrixIndex,self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, maxMatrixIndex,self.hidden_size))\n",
    "            Hidden_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2))\n",
    "            Cell_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2))\n",
    "            return Hidden_State, Cell_State,Hidden_State_2,Cell_State_2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationLSTMSeq2SeqPositionOnly(nn.Module):\n",
    "    def __init__(self, input_size=20, cell_size=20, hidden_size=20, \\\n",
    "                 input_size_2=20, cell_size_2=20,hidden_size_2=20, outputTimeFrame=5,output_last = True):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        the input of LSTM  structure is the output of 'fromRelationToEffectNet' module, so that \n",
    "        the effectOutputTensorSize has the same number as input_size. \n",
    "        \n",
    "        \"\"\"\n",
    "        super(RelationLSTMSeq2SeqPositionOnly, self).__init__()\n",
    "        self.maxMatrixIndex=250\n",
    "        \n",
    "        #generate a tuple in which each element is the index of a vehicle\n",
    "        #the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "        listForEachVehicle=[]\n",
    "        for i in range(self.maxMatrixIndex):\n",
    "            listForEachVehicle.append(i*(self.maxMatrixIndex-1))\n",
    "        self.tupleForEachVehicle=tuple(listForEachVehicle)\n",
    "        self.positionTuple=(0,1,6,7)\n",
    "#         self.velocityTuple=(2,3,8,9)\n",
    "#         self.acclerateTuple=(4,5,10,11)\n",
    "        \n",
    "        #effect representive vector computation lstm\n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        #object modifying lstm\n",
    "        self.cell_size2 = cell_size_2\n",
    "        self.hidden_size2 = hidden_size_2\n",
    "        self.fl2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        self.il2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        self.ol2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        self.Cl2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        \n",
    "        self.outputTimeFrame=outputTimeFrame\n",
    "\n",
    "        self.fromRelationToEffectNet=fromRelationToEffectNetworkPositionOnly(effectOutputTensorSize=input_size)\n",
    "        self.objectModifyNet=objectModifyNetwork(inputSize=input_size+6,outputSize=6)\n",
    "        self.hiddenStateToEffectNetwork=hiddenStateToEffectNetwork(inputSize=hidden_size,outputSize=input_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, inputEffectTensor, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((inputEffectTensor, Hidden_State), 2)\n",
    "#         print('in step,combined.shape',combined.shape)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def step2(self, inputPreEffectTensor, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((inputPreEffectTensor, Hidden_State), 2)\n",
    "#         print('in step2,combined.shape',combined.shape)\n",
    "        f = F.sigmoid(self.fl2(combined))\n",
    "        i = F.sigmoid(self.il2(combined))\n",
    "        o = F.sigmoid(self.ol2(combined))\n",
    "        C = F.tanh(self.Cl2(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State,Hidden_State_2,Cell_State_2 = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            #effect computation\n",
    "            for i in range(time_step):\n",
    "                effects=self.fromRelationToEffectNet(inputs[:,i,:,:])\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(effects), Hidden_State, Cell_State) \n",
    "                #the property of each vehicle\n",
    "                \n",
    "            Hidden_State_2=Hidden_State\n",
    "            Cell_State_2=Cell_State\n",
    "            \n",
    "            #the lstm process below take as inputs the previous object states and output the next predicted states\n",
    "            #applying function permute to deal with the dimension inconsistency\n",
    "            '''\n",
    "            inputs should be processed by function \"fromObjectsToRelationPairsBatchAndTimestepVersion\" \n",
    "            IF DATASETV3 VERSION IS USED TO GET DATA\n",
    "            '''\n",
    "            print('in seq2seq, inputs shape:',inputs.shape)\n",
    "            preVehicleProperty=inputs[:,-1,self.tupleForEachVehicle,0:6].squeeze()\n",
    "            preRelations=inputs[:,-1,:,:]\n",
    "            #object properties computation\n",
    "            for i in range(outputTimeFrame):\n",
    "                #objectAndFinalEffect=torch.cat((preVehicleProperty,Hidden_State_2),2)  #??????????\n",
    "                #WRONG!!!!The final hidden state of the first lstm model is not a effect tensor!!\n",
    "                #The hidden state of the first lstm represents somehow the encode hidden state in translation network,\n",
    "                #and obviously, the hidden state of encode component in translation network \n",
    "                #does not contain the result of translation. We could get the result from the output of\n",
    "                #the decode part of the translation network\n",
    "                #the shape of input tensor to the function fromRelationToEffectNet is (batch, vehicles, properties)\n",
    "                preEffect=self.fromRelationToEffectNet(preRelations)#the effect produced by this function is already a combined effect\n",
    "                logging.debug(fromAllToStr('preEffect.shape: ',preEffect.shape))\n",
    "                Hidden_State_2,Cell_State_2=self.step2(preEffect,Hidden_State_2,Cell_State_2)\n",
    "                logging.debug(fromAllToStr('Hidden_State_2.shape: ',Hidden_State_2.shape))\n",
    "                effectFromHiddenState=self.hiddenStateToEffectNetwork(Hidden_State_2)\n",
    "                logging.debug(fromAllToStr('effectFromeHiddenState.shape: ',effectFromHiddenState.shape))\n",
    "                objectAndEffectTensor=torch.cat((effectFromHiddenState,preVehicleProperty),2)\n",
    "                logging.debug(fromAllToStr('objectAndEffectTensor.shape: ',objectAndEffectTensor.shape))\n",
    "                modifiedObject=self.objectModifyNet(objectAndEffectTensor)\n",
    "                logging.debug(fromAllToStr('modifiedObject.shape: ',modifiedObject.shape))\n",
    "                newRelation=fromObjectsToRelationPairsBatchAndTimestepVersion(modifiedObject.unsqueeze(1).permute(0,1,3,2))\n",
    "                preRelations=newRelation.squeeze()\n",
    "                if i==0:\n",
    "                    #add dimension timestep, which in dimension 1\n",
    "                    outputVehicleProperties=modifiedObject.unsqueeze(1) \n",
    "                else:\n",
    "                    outputVehicleProperties=torch.cat((outputVehicleProperties,modifiedObject.unsqueeze(1)),1)\n",
    "                #doesn't need to compute new effect vector after the prediction of the last time step\n",
    "                if i==outputTimeFrame:\n",
    "                    break\n",
    "#             print(inputs.shape)\n",
    "#             vehicleProperty=inputs[:,-1,self.tupleForEachVehicle,0:6].squeeze()\n",
    "#             objectAndFinalEffect=torch.cat((vehicleProperty,Hidden_State),2)\n",
    "#             outputState=self.objectModifyNet(objectAndFinalEffect)\n",
    "            return outputVehicleProperties\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "#         use_gpu = torch.cuda.is_available()\n",
    "        if useGpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size,maxMatrixIndex, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size,maxMatrixIndex, self.hidden_size).cuda())\n",
    "            Hidden_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2).cuda())\n",
    "            Cell_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2).cuda())\n",
    "            return Hidden_State, Cell_State,Hidden_State_2,Cell_State_2\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, maxMatrixIndex,self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, maxMatrixIndex,self.hidden_size))\n",
    "            Hidden_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2))\n",
    "            Cell_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2))\n",
    "            return Hidden_State, Cell_State,Hidden_State_2,Cell_State_2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fromRelationToEffectNetworkWithDiscountParameter(nn.Module):\n",
    "    '''\n",
    "    A new network for producing effect from relation with a discount parameter tensor \n",
    "    the dimension of the input relation tensor is (batches, timesteps, properties)\n",
    "    '''\n",
    "    def __init__(self,effectOutputTensorSize=20, maxRelationNumber=20,maxMatrixIndex=250,relationTensorSize=40):\n",
    "        super(fromRelationToEffectNetworkWithDiscountParameter,self).__init__()\n",
    "        self.maxMatrixIndex=maxMatrixIndex\n",
    "\n",
    "        \n",
    "        #position relation network initialize\n",
    "        self.relationTensorSize=relationTensorSize\n",
    "        self.positionTuple=(0,1,2,3)\n",
    "        self.positionRelationNet=relationNetwork(outputSize=self.relationTensorSize)\n",
    "        self.maxRelationNumber=maxRelationNumber\n",
    "       \n",
    "        #effect network initialize\n",
    "        self.objectAndTensorSize=self.relationTensorSize+4 #NOTE HERE: does it neccessary to contain both the tow object positions in the effect tensor?\n",
    "        self.effectOutputTensorSize=effectOutputTensorSize\n",
    "        #the number 4 is the size of positon(or velocity or accelerate) pairs,\n",
    "        #such as (positonxObject1,positonyObject1,positionxObject2,positionyObject2)\n",
    "        self.positionEffectNet=effectNetwork(inputSize=self.objectAndTensorSize,outputSize=self.effectOutputTensorSize)\n",
    "\n",
    "  \n",
    "    def forward(self,inputObjectsPairs,discountParameterTensor):\n",
    "        #relation computation\n",
    "        effectOutputTensorSize=self.effectOutputTensorSize\n",
    "        positionRelationTensors=self.positionRelationNet(inputObjectsPairs[:,:,self.positionTuple])\n",
    "        objectsAndPositionRelationTensors=torch.cat((inputObjectsPairs[:,:,self.positionTuple],positionRelationTensors),2)\n",
    "        #effect computation\n",
    "        positionEffectTensors=self.positionEffectNet(objectsAndPositionRelationTensors)\n",
    "        #effect combination with discount parameter\n",
    "        #tensor summation\n",
    "        batchSize=positionRelationTensors.shape[0]\n",
    "        #apply discount parameters of distance to effectTensors\n",
    "        logging.debug(fromAllToStr('positionEffectTensors.shape: ',positionEffectTensors.shape))\n",
    "        logging.debug(fromAllToStr('discountParameterTensor.shape: ',discountParameterTensor.shape))\n",
    "        positionEffectTensors=torch.mul(positionEffectTensors,discountParameterTensor.unsqueeze(2))\n",
    "        if useGpu==True:\n",
    "            positionEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize).cuda()\n",
    "        else: \n",
    "            positionEffectSummation=torch.zeros(batchSize,maxMatrixIndex,effectOutputTensorSize)\n",
    "        for i in range(maxMatrixIndex):\n",
    "            positionEffectSummation[:,i,:]=torch.sum(positionEffectTensors[:,(i*self.maxRelationNumber):((i+1)*self.maxRelationNumber),:],1)\n",
    "        \n",
    "        #remove object extraction component and computation component\n",
    "#         #the property of each vehicle\n",
    "#         vehicleProperty=inputObjectsPairs[:,self.tupleForEachVehicle,0:6]\n",
    "#         objectAndFinalEffect=torch.cat((vehicleProperty,processedCombinedEffectTensors),2)\n",
    "        \n",
    "#         #compute final state\n",
    "#         finalObjectState=self.objectModifyNet(objectAndFinalEffect)\n",
    "        return positionEffectSummation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class differenceLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=20, cell_size=20, hidden_size=20, \\\n",
    "                 input_size_2=20, cell_size_2=20,hidden_size_2=20, outputTimeFrame=11,output_last = True,\\\n",
    "                maxRelationNUmber=20,differenceSize=2,inputRelationTensor=4,theGivenRange=0.08):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        the input of LSTM  structure was the output of 'fromRelationToEffectNet' module, so that \n",
    "        the effectOutputTensorSize has the same number as input_size. \n",
    "        The dataset for this mode, DatasetV4, only return tensors with position values without velocity and accelerate values.\n",
    "        \n",
    "        \"\"\"\n",
    "        super(differenceLSTMModel, self).__init__()\n",
    "        self.maxMatrixIndex=250\n",
    "        self.theGivenRange=theGivenRange\n",
    "        \n",
    "        #generate a tuple in which each element is the index of a vehicle\n",
    "        #the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "        listForEachVehicle=[]\n",
    "        for i in range(self.maxMatrixIndex):\n",
    "            listForEachVehicle.append(i*(self.maxMatrixIndex-1))\n",
    "        self.tupleForEachVehicle=tuple(listForEachVehicle)\n",
    "#         self.positionTuple=(0,1,6,7)\n",
    "#         self.velocityTuple=(2,3,8,9)\n",
    "#         self.acclerateTuple=(4,5,10,11)\n",
    "        \n",
    "        #effect representive vector computation lstm\n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        #object modifying lstm\n",
    "        self.cell_size2 = cell_size_2\n",
    "        self.hidden_size2 = hidden_size_2\n",
    "        self.fl2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        self.il2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        self.ol2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        self.Cl2 = nn.Linear(input_size_2 + hidden_size_2, hidden_size_2)\n",
    "        \n",
    "        self.outputTimeFrame=outputTimeFrame\n",
    "\n",
    "        self.fromRelationToEffectNet=fromRelationToEffectNetworkPositionOnly(effectOutputTensorSize=input_size)\n",
    "        self.objectModifyNet=objectModifyNetwork(inputSize=hidden_size+6,outputSize=6)\n",
    "        self.effectComputationWithDiscountParameterNet=fromRelationToEffectNetworkWithDiscountParameter(\\\n",
    "            maxRelationNumber=maxRelationsNumberGlobal,effectOutputTensorSize=input_size)\n",
    "        #the two variable in output size represent the difference of x and y positions\n",
    "        self.hiddenStateToDifferenceTensorNet=\\\n",
    "        hiddenStateToDifferenceNetwork(inputSize=hidden_size,outputSize=2)\n",
    "        \n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, inputEffectTensor, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((inputEffectTensor, Hidden_State), 2)\n",
    "#         print('in step,combined.shape',combined.shape)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def step2(self, inputPreEffectTensor, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((inputPreEffectTensor, Hidden_State), 2)\n",
    "#         print('in step2,combined.shape',combined.shape)\n",
    "        f = F.sigmoid(self.fl2(combined))\n",
    "        i = F.sigmoid(self.il2(combined))\n",
    "        o = F.sigmoid(self.ol2(combined))\n",
    "        C = F.tanh(self.Cl2(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs,discountParameterTensor,vehicleGraph):\n",
    "        '''\n",
    "        Args(only for notes):\n",
    "            inputs:relation tensors\n",
    "        Returns:\n",
    "            allDifferenceTensor,allGraphTensor\n",
    "        '''\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State,Hidden_State_2,Cell_State_2 = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            #effect computation\n",
    "            for i in range(time_step):\n",
    "                logging.debug(fromAllToStr('inputs[:,i,:,:].shape',inputs[:,i,:,:].shape))\n",
    "                logging.debug(fromAllToStr('discountParameterTensor[:,i,:].shape',discountParameterTensor[:,i,:].shape))\n",
    "                logging.debug(fromAllToStr('self.effectComputationWithDiscountParameterNet',self.effectComputationWithDiscountParameterNet))\n",
    "                logging.info(fromAllToStr('is effectComputationWithDiscountParameterNet in cuda:',next(self.effectComputationWithDiscountParameterNet.parameters()).is_cuda))\n",
    "                logging.info(fromAllToStr('inputs.device:',inputs.device))\n",
    "                logging.info(fromAllToStr('discoutParameterTensor.device',discountParameterTensor.device))\n",
    "                effects=self.effectComputationWithDiscountParameterNet\\\n",
    "                (inputs[:,i,:,:],discountParameterTensor[:,i,:])\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(effects), Hidden_State, Cell_State) \n",
    "                #the property of each vehicle\n",
    "                \n",
    "            Hidden_State_2=Hidden_State\n",
    "            Cell_State_2=Cell_State\n",
    "            \n",
    "            #the lstm process below take as inputs the previous object states and output the next predicted states\n",
    "            #applying function permute to deal with the dimension inconsistency\n",
    "            logging.debug(fromAllToStr('in seq2seq, inputs shape:',inputs.shape))\n",
    "            preVehicleProperty=vehicleGraph[:,-1,:,:].squeeze()\n",
    "            \n",
    "            \n",
    "            #object properties computation\n",
    "            for i in range(self.outputTimeFrame):\n",
    "                #produce relation first\n",
    "                for relationComputingBatch in range(preVehicleProperty.shape[0]):\n",
    "                    logging.info(fromAllToStr())\n",
    "                    relationTensorInBatchComputing, discountParameterTensorInBatchComputing=\\\n",
    "                    computeRelationAndAllTheOtherTensorsWithDistance(preVehicleProperty[relationComputingBatch].unsqueeze(0),self.theGivenRange)\n",
    "                    logging.debug(fromAllToStr('relationTensorInBatchComputing.shape: ',relationTensorInBatchComputing.shape))\n",
    "                    logging.debug(fromAllToStr('discountParameterTensorInBatchComputing.shape: ',discountParameterTensorInBatchComputing.shape))\n",
    "                    relationTensorInBatchComputing,discountParameterTensorInBatchComputing=\\\n",
    "                    relationTensorInBatchComputing.unsqueeze(0),discountParameterTensorInBatchComputing.unsqueeze(0)\n",
    "                    if relationComputingBatch==0:\n",
    "                        allRelationTensorOfPrevehicle,allDiscountParameterTensor=\\\n",
    "                        relationTensorInBatchComputing,discountParameterTensorInBatchComputing\n",
    "                        logging.debug(fromAllToStr('relationComputingBatch=0 allRelationTensorOfPrevehicle.shape:',allRelationTensorOfPrevehicle.shape))\n",
    "                        logging.debug(fromAllToStr('relationComputingBatch=0 allDiscountParameterTensor.shape:',allDiscountParameterTensor.shape))\n",
    "                    else:\n",
    "                        allRelationTensorOfPrevehicle,allDiscountParameterTensor=\\\n",
    "                        torch.cat((allRelationTensorOfPrevehicle,relationTensorInBatchComputing),0),\\\n",
    "                        torch.cat((allDiscountParameterTensor,discountParameterTensorInBatchComputing),0)\n",
    "                        logging.debug(fromAllToStr('else allRelationTensorOfPrevehicle.shape:',allRelationTensorOfPrevehicle.shape))\n",
    "                        logging.debug(fromAllToStr('else allDiscountParameterTensor.shape:',allDiscountParameterTensor.shape))\n",
    "                #then compute effect using relations and discount parameters\n",
    "                logging.debug(fromAllToStr('allRelationTensorOfPrevehicle.shape:',allRelationTensorOfPrevehicle.shape))\n",
    "                logging.debug(fromAllToStr('allDiscountParameterTensor.shape:',allDiscountParameterTensor.shape))\n",
    "                combinedEffect=self.effectComputationWithDiscountParameterNet\\\n",
    "                (allRelationTensorOfPrevehicle[:,0,:,:],allDiscountParameterTensor[:,0,:])\n",
    "#                 if i==0:\n",
    "#                     #add dimension timestep, which in dimension 1\n",
    "#                     outputVehicleProperties=preVehicleProperty.unsqueeze(1) \n",
    "#                 else:\n",
    "#                     outputVehicleProperties=torch.cat((outputVehicleProperties,preVehicleProperty.unsqueeze(1)),1)\n",
    "                #don't need to compute new effect vector after the prediction of the last time step\n",
    "                if i<self.outputTimeFrame:\n",
    "                    Hidden_State_2,Cell_State_2=self.step2(combinedEffect,Hidden_State_2,Cell_State_2)\n",
    "                    differenceTensor=self.hiddenStateToDifferenceTensorNet(Hidden_State_2)\n",
    "                    logging.debug(fromAllToStr('differenceTensor.shape:',differenceTensor.shape))\n",
    "                    logging.debug(fromAllToStr('preVehicleProperty.shape:',preVehicleProperty.shape))\n",
    "                    newGraph=preVehicleProperty+differenceTensor.permute(0,2,1)\n",
    "                    #tensors of difference and predicted graph should be stored as the output of the model\n",
    "                    if i==0:\n",
    "                        #the reason for we do not unsqueeze dimension 0 but 1 is that 0 is the dimension of batch, and 1 represent time step\n",
    "                        allDifferenceTensor=differenceTensor.unsqueeze(1)\n",
    "                        allGraphTensor=newGraph.unsqueeze(1)\n",
    "                    else:\n",
    "                        #see above why we cat dimension 1 but not 0\n",
    "                        allDifferenceTensor=torch.cat((allDifferenceTensor,differenceTensor.unsqueeze(1)),1)\n",
    "                        allGraphTensor=torch.cat((allGraphTensor,newGraph.unsqueeze(1)),1)\n",
    "                if i==self.outputTimeFrame:\n",
    "                    break\n",
    "#             print(inputs.shape)\n",
    "#             vehicleProperty=inputs[:,-1,self.tupleForEachVehicle,0:6].squeeze()\n",
    "#             objectAndFinalEffect=torch.cat((vehicleProperty,Hidden_State),2)\n",
    "#             outputState=self.objectModifyNet(objectAndFinalEffect)\n",
    "            return allDifferenceTensor,allGraphTensor\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "#         use_gpu = torch.cuda.is_available()\n",
    "        if useGpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size,maxMatrixIndex, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size,maxMatrixIndex, self.hidden_size).cuda())\n",
    "            Hidden_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2).cuda())\n",
    "            Cell_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2).cuda())\n",
    "            return Hidden_State, Cell_State,Hidden_State_2,Cell_State_2\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, maxMatrixIndex,self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, maxMatrixIndex,self.hidden_size))\n",
    "            Hidden_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2))\n",
    "            Cell_State_2=Variable(torch.zeros(batch_size,maxMatrixIndex,self.hidden_size2))\n",
    "            return Hidden_State, Cell_State,Hidden_State_2,Cell_State_2\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class elementWeightedLoss(nn.Module):\n",
    "    def __init__(self,lambdaDistance,lambdaVelocity,lambdaAccelerate):\n",
    "        super(elementWeightedLoss,self).__init__()\n",
    "        self.lambdaDistance,self.lambdaVelocity,self.lambdaAccelerate=\\\n",
    "        lambdaDistance,lambdaVelocity,lambdaAccelerate\n",
    "        \n",
    "    def forward(self,output,label):\n",
    "        '''\n",
    "        output and label dimension: [batch, timestep, vehiclenum, properties]\n",
    "        properties dimension:(distancex,distancey,velocityx,velocityy,acceleratex,acceleratey)\n",
    "        '''\n",
    "        distanceLoss=torch.mean(torch.pow(output[:,:,:,0:2]-label[:,:,:,0:2],2))\n",
    "        velocityLoss=torch.mean(torch.pow(output[:,:,:,2:4]-label[:,:,:,2:4],2))\n",
    "        accelerateLoss=torch.mean(torch.pow(output[:,:,:,4:6]-label[:,:,:,4:6],2))\n",
    "        return torch.mul(distanceLoss,self.lambdaDistance)+torch.mul(velocityLoss,self.lambdaVelocity)+\\\n",
    "                torch.mul(accelerateLoss,self.lambdaAccelerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# seperation of model and testing part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing differenceLSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runDifferenceLSTMModel:\n",
    "    differenceLSTMNet=differenceLSTMModel(outputTimeFrame=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runDifferenceLSTMModel:\n",
    "    trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n",
    "    datasetV4Instance=tensorsDatasetV4MultiThread(trajectoryFileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runDifferenceLSTMModel:\n",
    "    datasetV4Loader=DataLoader(datasetV4Instance,batch_size=2,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "allCombineTensorTrain, allCombineTensorValid,\\\n",
    "combinedRelationTensors, combinedDiscountParameterTensors,differenceLabels=item\n",
    "logging.debug(fromAllToStr(all))\n",
    "print(differenceLSTMNet)\n",
    "differenceLSTMNet(combinedRelationTensors,combinedDiscountParameterTensors,allCombineTensorTrain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 17:13:27,935 -181 - __getitem__ - DEBUG - allCombineTensorTrain.shape:torch.Size([10, 2, 250])\n",
      "2020-08-29 17:13:27,937 -182 - __getitem__ - DEBUG - allCombineTensorValid.shapetensor([[[0.0000, 0.0000, 0.4652,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.9563,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.4652,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.9584,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.4651,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.9604,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]])\n",
      "2020-08-29 17:13:27,972 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:27,986 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:28,003 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:28,018 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:28,037 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:28,054 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:28,117 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:28,130 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:28,073 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:28,158 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:32,743 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:13:32,765 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:13:33,346 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])2020-08-29 17:13:33,349 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "\n",
      "2020-08-29 17:13:33,385 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:13:33,397 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:13:33,531 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:13:33,565 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:13:33,678 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])2020-08-29 17:13:33,683 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:13:33,727 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])2020-08-29 17:13:33,708 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "\n",
      "\n",
      "2020-08-29 17:13:33,745 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:13:33,761 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:13:33,818 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:13:33,867 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:13:33,880 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0250, 0.0178, 1.0000, 2.0000, 1.0000],\n",
      "        [0.0203, 0.0418, 1.0000, 2.0000, 1.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:34,070 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:13:34,114 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:13:34,290 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0250, 0.0178, 1.0000, 2.0000, 1.0000],\n",
      "        [0.0203, 0.0418, 1.0000, 2.0000, 1.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:34,346 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:13:34,364 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:13:34,409 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0250, 0.0178, 1.0000, 2.0000, 1.0000],\n",
      "        [0.0203, 0.0418, 1.0000, 2.0000, 1.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:34,427 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0250, 0.0178, 1.0000, 2.0000, 1.0000],\n",
      "        [0.0203, 0.0418, 1.0000, 2.0000, 1.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:34,649 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0250, 0.0178, 1.0000, 2.0000, 1.0000],\n",
      "        [0.0203, 0.0418, 1.0000, 2.0000, 1.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:34,662 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0250, 0.0178, 1.0000, 2.0000, 1.0000],\n",
      "        [0.0203, 0.0418, 1.0000, 2.0000, 1.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:34,710 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0250, 0.0178, 1.0000, 2.0000, 1.0000],\n",
      "        [0.0203, 0.0418, 1.0000, 2.0000, 1.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:34,768 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0250, 0.0178, 1.0000, 2.0000, 1.0000],\n",
      "        [0.0203, 0.0418, 1.0000, 2.0000, 1.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:34,781 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0250, 0.0178, 1.0000, 2.0000, 1.0000],\n",
      "        [0.0203, 0.0418, 1.0000, 2.0000, 1.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:34,979 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.0250, 0.0178, 1.0000, 2.0000, 1.0000],\n",
      "        [0.0203, 0.0418, 1.0000, 2.0000, 1.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:35,031 -217 - __getitem__ - DEBUG - allCombineTensorValid.shape:torch.Size([10, 2, 250])\n",
      "2020-08-29 17:13:35,032 -15 - differenceBetweenTwoFrameForTimeSteps - DEBUG - torch.Size([10, 250, 2])\n",
      "2020-08-29 17:13:35,032 -16 - differenceBetweenTwoFrameForTimeSteps - DEBUG - torch.Size([10, 250, 2])\n",
      "2020-08-29 17:13:35,033 -17 - differenceBetweenTwoFrameForTimeSteps - DEBUG - torch.Size([11, 250, 2])\n",
      "2020-08-29 17:13:35,033 -219 - __getitem__ - DEBUG - differenceLabels.shape:torch.Size([10, 250, 2])\n",
      "2020-08-29 17:13:35,230 -181 - __getitem__ - DEBUG - allCombineTensorTrain.shape:torch.Size([10, 2, 250])\n",
      "2020-08-29 17:13:35,231 -182 - __getitem__ - DEBUG - allCombineTensorValid.shapetensor([[[0.0000, 0.1084, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.8881, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.1059, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.8909, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.1034, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.8936, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.0944, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.9072, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0929, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.9099, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0919, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.9127, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]])\n",
      "2020-08-29 17:13:35,263 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:35,277 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:35,292 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:35,306 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:35,322 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:35,341 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:35,373 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:35,397 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:35,354 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:35,461 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:42,092 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:13:42,133 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:13:42,176 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:13:42,222 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:13:42,306 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:13:42,332 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:13:42,439 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:13:42,484 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:13:42,517 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:13:42,569 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:13:42,819 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:13:42,866 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:13:43,190 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:13:43,230 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:13:43,329 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:13:43,341 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])2020-08-29 17:13:43,369 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "\n",
      "2020-08-29 17:13:43,385 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:13:43,521 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:13:43,565 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:13:43,843 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:43,920 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:44,068 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:44,167 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:44,280 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:44,533 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:44,673 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:44,715 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:44,759 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:44,776 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0.0000, 0.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        [0.1412, 0.9618, 1.0000, 2.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 1.0000, 0.0000]])\n",
      "2020-08-29 17:13:44,858 -217 - __getitem__ - DEBUG - allCombineTensorValid.shape:torch.Size([10, 2, 250])\n",
      "2020-08-29 17:13:44,860 -15 - differenceBetweenTwoFrameForTimeSteps - DEBUG - torch.Size([10, 250, 2])\n",
      "2020-08-29 17:13:44,860 -16 - differenceBetweenTwoFrameForTimeSteps - DEBUG - torch.Size([10, 250, 2])\n",
      "2020-08-29 17:13:44,861 -17 - differenceBetweenTwoFrameForTimeSteps - DEBUG - torch.Size([11, 250, 2])\n",
      "2020-08-29 17:13:44,862 -219 - __getitem__ - DEBUG - differenceLabels.shape:torch.Size([10, 250, 2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "if runDifferenceLSTMModel:\n",
    "    for items in iter(datasetV4Loader):\n",
    "        \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runDifferenceLSTMModel:\n",
    "    if not isTest:\n",
    "        learningRate=1e-3\n",
    "        MSELoss=nn.MSELoss()\n",
    "        lambdaWholeNet=lambda epoch: 0.5**(epoch//30)\n",
    "        optim=torch.optim.RMSprop([{'params':differenceLSTMNet.parameters(),'initial_lr':learningRate}],lr=learningRate)\n",
    "        lrSchedule=torch.optim.lr_scheduler.LambdaLR(optim,lambdaWholeNet,last_epoch=10)\n",
    "        if useGpu:\n",
    "            differenceLSTMNet.cuda()\n",
    "        differenceLSTMNet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 17:13:56,382 -94 - forward - DEBUG - inputs[:,i,:,:].shapetorch.Size([2, 5000, 4])\n",
      "2020-08-29 17:13:56,383 -95 - forward - DEBUG - discountParameterTensor[:,i,:].shapetorch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,383 -96 - forward - DEBUG - self.effectComputationWithDiscountParameterNetfromRelationToEffectNetworkWithDiscountParameter(\n",
      "  (positionRelationNet): relationNetwork(\n",
      "    (layer1): Linear(in_features=4, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=40, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      "  (positionEffectNet): effectNetwork(\n",
      "    (layer1): Linear(in_features=44, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      ")\n",
      "2020-08-29 17:13:56,392 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n",
      "2020-08-29 17:13:56,392 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,415 -94 - forward - DEBUG - inputs[:,i,:,:].shapetorch.Size([2, 5000, 4])\n",
      "2020-08-29 17:13:56,416 -95 - forward - DEBUG - discountParameterTensor[:,i,:].shapetorch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,416 -96 - forward - DEBUG - self.effectComputationWithDiscountParameterNetfromRelationToEffectNetworkWithDiscountParameter(\n",
      "  (positionRelationNet): relationNetwork(\n",
      "    (layer1): Linear(in_features=4, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=40, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      "  (positionEffectNet): effectNetwork(\n",
      "    (layer1): Linear(in_features=44, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      ")\n",
      "2020-08-29 17:13:56,423 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n",
      "2020-08-29 17:13:56,424 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,444 -94 - forward - DEBUG - inputs[:,i,:,:].shapetorch.Size([2, 5000, 4])\n",
      "2020-08-29 17:13:56,444 -95 - forward - DEBUG - discountParameterTensor[:,i,:].shapetorch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,445 -96 - forward - DEBUG - self.effectComputationWithDiscountParameterNetfromRelationToEffectNetworkWithDiscountParameter(\n",
      "  (positionRelationNet): relationNetwork(\n",
      "    (layer1): Linear(in_features=4, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=40, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      "  (positionEffectNet): effectNetwork(\n",
      "    (layer1): Linear(in_features=44, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      ")\n",
      "2020-08-29 17:13:56,452 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n",
      "2020-08-29 17:13:56,452 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,469 -94 - forward - DEBUG - inputs[:,i,:,:].shapetorch.Size([2, 5000, 4])\n",
      "2020-08-29 17:13:56,470 -95 - forward - DEBUG - discountParameterTensor[:,i,:].shapetorch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,471 -96 - forward - DEBUG - self.effectComputationWithDiscountParameterNetfromRelationToEffectNetworkWithDiscountParameter(\n",
      "  (positionRelationNet): relationNetwork(\n",
      "    (layer1): Linear(in_features=4, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=40, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      "  (positionEffectNet): effectNetwork(\n",
      "    (layer1): Linear(in_features=44, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      ")\n",
      "2020-08-29 17:13:56,476 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n",
      "2020-08-29 17:13:56,476 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,488 -94 - forward - DEBUG - inputs[:,i,:,:].shapetorch.Size([2, 5000, 4])\n",
      "2020-08-29 17:13:56,488 -95 - forward - DEBUG - discountParameterTensor[:,i,:].shapetorch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,489 -96 - forward - DEBUG - self.effectComputationWithDiscountParameterNetfromRelationToEffectNetworkWithDiscountParameter(\n",
      "  (positionRelationNet): relationNetwork(\n",
      "    (layer1): Linear(in_features=4, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=40, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      "  (positionEffectNet): effectNetwork(\n",
      "    (layer1): Linear(in_features=44, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      ")\n",
      "2020-08-29 17:13:56,494 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n",
      "2020-08-29 17:13:56,495 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,508 -94 - forward - DEBUG - inputs[:,i,:,:].shapetorch.Size([2, 5000, 4])\n",
      "2020-08-29 17:13:56,509 -95 - forward - DEBUG - discountParameterTensor[:,i,:].shapetorch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,509 -96 - forward - DEBUG - self.effectComputationWithDiscountParameterNetfromRelationToEffectNetworkWithDiscountParameter(\n",
      "  (positionRelationNet): relationNetwork(\n",
      "    (layer1): Linear(in_features=4, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=40, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      "  (positionEffectNet): effectNetwork(\n",
      "    (layer1): Linear(in_features=44, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      ")\n",
      "2020-08-29 17:13:56,514 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n",
      "2020-08-29 17:13:56,514 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,524 -94 - forward - DEBUG - inputs[:,i,:,:].shapetorch.Size([2, 5000, 4])\n",
      "2020-08-29 17:13:56,525 -95 - forward - DEBUG - discountParameterTensor[:,i,:].shapetorch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,525 -96 - forward - DEBUG - self.effectComputationWithDiscountParameterNetfromRelationToEffectNetworkWithDiscountParameter(\n",
      "  (positionRelationNet): relationNetwork(\n",
      "    (layer1): Linear(in_features=4, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=40, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      "  (positionEffectNet): effectNetwork(\n",
      "    (layer1): Linear(in_features=44, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 17:13:56,530 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n",
      "2020-08-29 17:13:56,530 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,541 -94 - forward - DEBUG - inputs[:,i,:,:].shapetorch.Size([2, 5000, 4])\n",
      "2020-08-29 17:13:56,542 -95 - forward - DEBUG - discountParameterTensor[:,i,:].shapetorch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,542 -96 - forward - DEBUG - self.effectComputationWithDiscountParameterNetfromRelationToEffectNetworkWithDiscountParameter(\n",
      "  (positionRelationNet): relationNetwork(\n",
      "    (layer1): Linear(in_features=4, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=40, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      "  (positionEffectNet): effectNetwork(\n",
      "    (layer1): Linear(in_features=44, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      ")\n",
      "2020-08-29 17:13:56,548 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n",
      "2020-08-29 17:13:56,548 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,556 -94 - forward - DEBUG - inputs[:,i,:,:].shapetorch.Size([2, 5000, 4])\n",
      "2020-08-29 17:13:56,557 -95 - forward - DEBUG - discountParameterTensor[:,i,:].shapetorch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,557 -96 - forward - DEBUG - self.effectComputationWithDiscountParameterNetfromRelationToEffectNetworkWithDiscountParameter(\n",
      "  (positionRelationNet): relationNetwork(\n",
      "    (layer1): Linear(in_features=4, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=40, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      "  (positionEffectNet): effectNetwork(\n",
      "    (layer1): Linear(in_features=44, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      ")\n",
      "2020-08-29 17:13:56,562 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n",
      "2020-08-29 17:13:56,563 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,572 -94 - forward - DEBUG - inputs[:,i,:,:].shapetorch.Size([2, 5000, 4])\n",
      "2020-08-29 17:13:56,572 -95 - forward - DEBUG - discountParameterTensor[:,i,:].shapetorch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,573 -96 - forward - DEBUG - self.effectComputationWithDiscountParameterNetfromRelationToEffectNetworkWithDiscountParameter(\n",
      "  (positionRelationNet): relationNetwork(\n",
      "    (layer1): Linear(in_features=4, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=40, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      "  (positionEffectNet): effectNetwork(\n",
      "    (layer1): Linear(in_features=44, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      ")\n",
      "2020-08-29 17:13:56,577 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n",
      "2020-08-29 17:13:56,578 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:13:56,588 -107 - forward - DEBUG - in seq2seq, inputs shape:torch.Size([2, 10, 5000, 4])\n",
      "2020-08-29 17:13:56,589 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:13:58,556 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:13:58,556 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:13:58,879 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:13:58,886 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n",
      "2020-08-29 17:13:58,886 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:13:58,886 -124 - forward - DEBUG - relationComputingBatch=0 allRelationTensorOfPrevehicle.shape:torch.Size([1, 1, 5000, 4])\n",
      "2020-08-29 17:13:58,887 -125 - forward - DEBUG - relationComputingBatch=0 allDiscountParameterTensor.shape:torch.Size([1, 1, 5000])\n",
      "2020-08-29 17:13:58,887 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:14:00,806 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:14:00,806 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:14:01,124 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:14:01,131 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n",
      "2020-08-29 17:14:01,131 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:14:01,132 -130 - forward - DEBUG - else allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:01,133 -131 - forward - DEBUG - else allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:01,133 -133 - forward - DEBUG - allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:01,134 -134 - forward - DEBUG - allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:01,139 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n",
      "2020-08-29 17:14:01,140 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:14:01,150 -146 - forward - DEBUG - differenceTensor.shape:torch.Size([2, 250, 2])\n",
      "2020-08-29 17:14:01,151 -147 - forward - DEBUG - preVehicleProperty.shape:torch.Size([2, 2, 250])\n",
      "2020-08-29 17:14:01,153 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:14:03,118 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:14:03,119 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:14:03,450 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:14:03,457 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n",
      "2020-08-29 17:14:03,458 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:14:03,459 -124 - forward - DEBUG - relationComputingBatch=0 allRelationTensorOfPrevehicle.shape:torch.Size([1, 1, 5000, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 17:14:03,459 -125 - forward - DEBUG - relationComputingBatch=0 allDiscountParameterTensor.shape:torch.Size([1, 1, 5000])\n",
      "2020-08-29 17:14:03,460 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:14:05,336 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:14:05,336 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:14:05,654 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:14:05,660 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n",
      "2020-08-29 17:14:05,661 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:14:05,661 -130 - forward - DEBUG - else allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:05,662 -131 - forward - DEBUG - else allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:05,662 -133 - forward - DEBUG - allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:05,663 -134 - forward - DEBUG - allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:05,669 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n",
      "2020-08-29 17:14:05,669 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:14:05,679 -146 - forward - DEBUG - differenceTensor.shape:torch.Size([2, 250, 2])\n",
      "2020-08-29 17:14:05,680 -147 - forward - DEBUG - preVehicleProperty.shape:torch.Size([2, 2, 250])\n",
      "2020-08-29 17:14:05,680 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:14:07,774 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:14:07,775 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:14:08,165 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:14:08,172 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n",
      "2020-08-29 17:14:08,173 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:14:08,174 -124 - forward - DEBUG - relationComputingBatch=0 allRelationTensorOfPrevehicle.shape:torch.Size([1, 1, 5000, 4])\n",
      "2020-08-29 17:14:08,174 -125 - forward - DEBUG - relationComputingBatch=0 allDiscountParameterTensor.shape:torch.Size([1, 1, 5000])\n",
      "2020-08-29 17:14:08,175 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:14:10,616 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:14:10,616 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:14:11,039 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:14:11,047 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n",
      "2020-08-29 17:14:11,047 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:14:11,048 -130 - forward - DEBUG - else allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:11,048 -131 - forward - DEBUG - else allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:11,049 -133 - forward - DEBUG - allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:11,049 -134 - forward - DEBUG - allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:11,055 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n",
      "2020-08-29 17:14:11,056 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:14:11,069 -146 - forward - DEBUG - differenceTensor.shape:torch.Size([2, 250, 2])\n",
      "2020-08-29 17:14:11,069 -147 - forward - DEBUG - preVehicleProperty.shape:torch.Size([2, 2, 250])\n",
      "2020-08-29 17:14:11,070 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:14:13,542 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:14:13,542 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:14:13,925 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:14:13,934 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n",
      "2020-08-29 17:14:13,934 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:14:13,935 -124 - forward - DEBUG - relationComputingBatch=0 allRelationTensorOfPrevehicle.shape:torch.Size([1, 1, 5000, 4])\n",
      "2020-08-29 17:14:13,935 -125 - forward - DEBUG - relationComputingBatch=0 allDiscountParameterTensor.shape:torch.Size([1, 1, 5000])\n",
      "2020-08-29 17:14:13,936 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:14:16,814 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:14:16,815 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:14:17,404 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:14:17,414 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n",
      "2020-08-29 17:14:17,415 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:14:17,416 -130 - forward - DEBUG - else allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:17,417 -131 - forward - DEBUG - else allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:17,418 -133 - forward - DEBUG - allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:17,419 -134 - forward - DEBUG - allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:17,429 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n",
      "2020-08-29 17:14:17,431 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:14:17,450 -146 - forward - DEBUG - differenceTensor.shape:torch.Size([2, 250, 2])\n",
      "2020-08-29 17:14:17,451 -147 - forward - DEBUG - preVehicleProperty.shape:torch.Size([2, 2, 250])\n",
      "2020-08-29 17:14:17,452 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:14:20,458 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:14:20,458 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 17:14:20,831 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:14:20,837 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n",
      "2020-08-29 17:14:20,838 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:14:20,839 -124 - forward - DEBUG - relationComputingBatch=0 allRelationTensorOfPrevehicle.shape:torch.Size([1, 1, 5000, 4])\n",
      "2020-08-29 17:14:20,839 -125 - forward - DEBUG - relationComputingBatch=0 allDiscountParameterTensor.shape:torch.Size([1, 1, 5000])\n",
      "2020-08-29 17:14:20,840 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:14:23,070 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:14:23,071 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:14:23,470 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:14:23,477 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n",
      "2020-08-29 17:14:23,478 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:14:23,479 -130 - forward - DEBUG - else allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:23,479 -131 - forward - DEBUG - else allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:23,479 -133 - forward - DEBUG - allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:23,480 -134 - forward - DEBUG - allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:23,485 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n",
      "2020-08-29 17:14:23,486 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:14:23,497 -146 - forward - DEBUG - differenceTensor.shape:torch.Size([2, 250, 2])\n",
      "2020-08-29 17:14:23,497 -147 - forward - DEBUG - preVehicleProperty.shape:torch.Size([2, 2, 250])\n",
      "2020-08-29 17:14:23,498 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:14:25,840 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:14:25,840 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:14:26,223 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:14:26,230 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n",
      "2020-08-29 17:14:26,230 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:14:26,231 -124 - forward - DEBUG - relationComputingBatch=0 allRelationTensorOfPrevehicle.shape:torch.Size([1, 1, 5000, 4])\n",
      "2020-08-29 17:14:26,231 -125 - forward - DEBUG - relationComputingBatch=0 allDiscountParameterTensor.shape:torch.Size([1, 1, 5000])\n",
      "2020-08-29 17:14:26,232 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:14:28,384 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:14:28,384 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:14:28,759 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:14:28,766 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n",
      "2020-08-29 17:14:28,766 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:14:28,767 -130 - forward - DEBUG - else allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:28,768 -131 - forward - DEBUG - else allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:28,768 -133 - forward - DEBUG - allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:28,769 -134 - forward - DEBUG - allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:28,775 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n",
      "2020-08-29 17:14:28,776 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:14:28,786 -146 - forward - DEBUG - differenceTensor.shape:torch.Size([2, 250, 2])\n",
      "2020-08-29 17:14:28,786 -147 - forward - DEBUG - preVehicleProperty.shape:torch.Size([2, 2, 250])\n",
      "2020-08-29 17:14:28,787 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:14:31,146 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:14:31,146 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:14:31,541 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:14:31,548 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n",
      "2020-08-29 17:14:31,548 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:14:31,549 -124 - forward - DEBUG - relationComputingBatch=0 allRelationTensorOfPrevehicle.shape:torch.Size([1, 1, 5000, 4])\n",
      "2020-08-29 17:14:31,549 -125 - forward - DEBUG - relationComputingBatch=0 allDiscountParameterTensor.shape:torch.Size([1, 1, 5000])\n",
      "2020-08-29 17:14:31,550 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:14:33,711 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:14:33,711 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:14:34,084 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:14:34,091 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n",
      "2020-08-29 17:14:34,091 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:14:34,091 -130 - forward - DEBUG - else allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:34,092 -131 - forward - DEBUG - else allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:34,092 -133 - forward - DEBUG - allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:34,093 -134 - forward - DEBUG - allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:34,099 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 17:14:34,100 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:14:34,110 -146 - forward - DEBUG - differenceTensor.shape:torch.Size([2, 250, 2])\n",
      "2020-08-29 17:14:34,110 -147 - forward - DEBUG - preVehicleProperty.shape:torch.Size([2, 2, 250])\n",
      "2020-08-29 17:14:34,111 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:14:36,393 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:14:36,393 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:14:36,786 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:14:36,793 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n",
      "2020-08-29 17:14:36,793 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:14:36,794 -124 - forward - DEBUG - relationComputingBatch=0 allRelationTensorOfPrevehicle.shape:torch.Size([1, 1, 5000, 4])\n",
      "2020-08-29 17:14:36,794 -125 - forward - DEBUG - relationComputingBatch=0 allDiscountParameterTensor.shape:torch.Size([1, 1, 5000])\n",
      "2020-08-29 17:14:36,795 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:14:39,047 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:14:39,048 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:14:39,432 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:14:39,439 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n",
      "2020-08-29 17:14:39,439 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:14:39,439 -130 - forward - DEBUG - else allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:39,440 -131 - forward - DEBUG - else allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:39,440 -133 - forward - DEBUG - allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:39,441 -134 - forward - DEBUG - allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:39,447 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n",
      "2020-08-29 17:14:39,448 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:14:39,461 -146 - forward - DEBUG - differenceTensor.shape:torch.Size([2, 250, 2])\n",
      "2020-08-29 17:14:39,462 -147 - forward - DEBUG - preVehicleProperty.shape:torch.Size([2, 2, 250])\n",
      "2020-08-29 17:14:39,463 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:14:41,919 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:14:41,919 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:14:42,316 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:14:42,323 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n",
      "2020-08-29 17:14:42,323 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:14:42,324 -124 - forward - DEBUG - relationComputingBatch=0 allRelationTensorOfPrevehicle.shape:torch.Size([1, 1, 5000, 4])\n",
      "2020-08-29 17:14:42,324 -125 - forward - DEBUG - relationComputingBatch=0 allDiscountParameterTensor.shape:torch.Size([1, 1, 5000])\n",
      "2020-08-29 17:14:42,324 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:14:44,491 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:14:44,492 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:14:44,863 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:14:44,870 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n",
      "2020-08-29 17:14:44,870 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:14:44,871 -130 - forward - DEBUG - else allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:44,871 -131 - forward - DEBUG - else allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:44,872 -133 - forward - DEBUG - allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:44,872 -134 - forward - DEBUG - allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:44,879 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n",
      "2020-08-29 17:14:44,879 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:14:44,892 -146 - forward - DEBUG - differenceTensor.shape:torch.Size([2, 250, 2])\n",
      "2020-08-29 17:14:44,893 -147 - forward - DEBUG - preVehicleProperty.shape:torch.Size([2, 2, 250])\n",
      "2020-08-29 17:14:44,894 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:14:47,216 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:14:47,217 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:14:47,602 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:14:47,608 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n",
      "2020-08-29 17:14:47,609 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:14:47,609 -124 - forward - DEBUG - relationComputingBatch=0 allRelationTensorOfPrevehicle.shape:torch.Size([1, 1, 5000, 4])\n",
      "2020-08-29 17:14:47,609 -125 - forward - DEBUG - relationComputingBatch=0 allDiscountParameterTensor.shape:torch.Size([1, 1, 5000])\n",
      "2020-08-29 17:14:47,610 -18 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - inputFrameTensor.shape:torch.Size([1, 2, 250])\n",
      "2020-08-29 17:14:49,829 -28 - computeRelationAndAllTheOtherTensorsWithDistance - DEBUG - relationTensorInOneTimeStep.shape:\n",
      "torch.Size([5000, 4])\n",
      "2020-08-29 17:14:49,830 -16 - discountParameterByExponentialWithDistance - DEBUG - secondVehiclePropertyStartIndex2\n",
      "2020-08-29 17:14:50,199 -39 - discountParameterByExponentialWithDistance - DEBUG - computationTensor:\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.]])\n",
      "2020-08-29 17:14:50,206 -117 - forward - DEBUG - relationTensorInBatchComputing.shape: torch.Size([1, 5000, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 17:14:50,206 -118 - forward - DEBUG - discountParameterTensorInBatchComputing.shape: torch.Size([1, 5000])\n",
      "2020-08-29 17:14:50,206 -130 - forward - DEBUG - else allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:50,207 -131 - forward - DEBUG - else allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:50,208 -133 - forward - DEBUG - allRelationTensorOfPrevehicle.shape:torch.Size([2, 1, 5000, 4])\n",
      "2020-08-29 17:14:50,209 -134 - forward - DEBUG - allDiscountParameterTensor.shape:torch.Size([2, 1, 5000])\n",
      "2020-08-29 17:14:50,215 -36 - forward - DEBUG - positionEffectTensors.shape: torch.Size([2, 5000, 20])\n",
      "2020-08-29 17:14:50,215 -37 - forward - DEBUG - discountParameterTensor.shape: torch.Size([2, 5000])\n",
      "2020-08-29 17:14:50,224 -146 - forward - DEBUG - differenceTensor.shape:torch.Size([2, 250, 2])\n",
      "2020-08-29 17:14:50,225 -147 - forward - DEBUG - preVehicleProperty.shape:torch.Size([2, 2, 250])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 17:03:03,455 -2 - <module> - DEBUG - torch.Size([2, 10, 250, 2])\n",
      "2020-08-29 17:03:03,457 -2 - <module> - DEBUG - torch.Size([2, 10, 2, 250])\n",
      "2020-08-29 17:03:03,458 -3 - <module> - DEBUG - allCombinedTensorValid.shape:torch.Size([2, 10, 2, 250])\n",
      "2020-08-29 17:03:03,459 -4 - <module> - DEBUG - differenceLabel.shape:torch.Size([2, 10, 250, 2])\n",
      "2020-08-29 17:03:03,459 -5 - <module> - DEBUG - allCombineTensorTrain.shape:torch.Size([2, 10, 2, 250])\n",
      "2020-08-29 17:03:03,460 -6 - <module> - DEBUG - allCombineTensorValid.shape:torch.Size([2, 10, 2, 250])\n",
      "2020-08-29 17:03:03,461 -7 - <module> - DEBUG - combinedRelationTensors.shape:torch.Size([2, 10, 5000, 4])\n"
     ]
    }
   ],
   "source": [
    "for eachItem in result:\n",
    "    logging.debug(fromAllToStr(eachItem.shape))\n",
    "logging.debug(fromAllToStr('allCombinedTensorValid.shape:',allCombineTensorValid.shape))\n",
    "logging.debug(fromAllToStr('differenceLabel.shape:',differenceLabels.shape))\n",
    "logging.debug(fromAllToStr('allCombineTensorTrain.shape:',allCombineTensorTrain.shape))\n",
    "logging.debug(fromAllToStr('allCombineTensorValid.shape:',allCombineTensorValid.shape))\n",
    "logging.debug(fromAllToStr('combinedRelationTensors.shape:',combinedRelationTensors.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MSELoss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-e4f3a769c5e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# outputDifferences,outputGraphs=result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputDifferences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdifferenceLabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloss2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputGraphs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallCombineTensorValid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlossAll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mloss2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MSELoss' is not defined"
     ]
    }
   ],
   "source": [
    "# outputDifferences,outputGraphs=result\n",
    "loss1=MSELoss(outputDifferences,differenceLabels)\n",
    "loss2=MSELoss(outputGraphs,allCombineTensorValid)\n",
    "lossAll=loss1+loss2\n",
    "optim.zero_grad()\n",
    "lossAll.backward()\n",
    "optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 22:24:24,151 -7 - <module> - INFO - data loading finished\n",
      "2020-08-29 22:24:24,151 -7 - <module> - INFO - data loading finished\n",
      "2020-08-29 22:24:24,156 -17 - <module> - INFO - combinedRelationTensors.device:cuda:0\n",
      "2020-08-29 22:24:24,156 -17 - <module> - INFO - combinedRelationTensors.device:cuda:0\n",
      "2020-08-29 22:24:24,157 -18 - <module> - INFO - forward start\n",
      "2020-08-29 22:24:24,157 -18 - <module> - INFO - forward start\n",
      "2020-08-29 22:24:24,159 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,159 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,160 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,160 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,161 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "2020-08-29 22:24:24,161 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "/home/wangyuchen/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/wangyuchen/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "2020-08-29 22:24:24,193 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,193 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,194 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,194 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,195 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "2020-08-29 22:24:24,195 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "2020-08-29 22:24:24,218 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,218 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,219 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,219 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,220 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "2020-08-29 22:24:24,220 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "2020-08-29 22:24:24,243 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,243 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,244 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,244 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,245 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "2020-08-29 22:24:24,245 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "2020-08-29 22:24:24,266 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,266 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,267 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,267 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,268 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "2020-08-29 22:24:24,268 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "2020-08-29 22:24:24,289 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,289 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,290 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,290 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,291 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "2020-08-29 22:24:24,291 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "2020-08-29 22:24:24,312 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,312 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,313 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,313 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,313 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "2020-08-29 22:24:24,313 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "2020-08-29 22:24:24,334 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,334 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,335 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,335 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,337 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "2020-08-29 22:24:24,337 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "2020-08-29 22:24:24,359 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,359 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,360 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,360 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,362 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "2020-08-29 22:24:24,362 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "2020-08-29 22:24:24,383 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,383 -97 - forward - INFO - is effectComputationWithDiscountParameterNet in cuda:True\n",
      "2020-08-29 22:24:24,384 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,384 -98 - forward - INFO - inputs.device:cuda:0\n",
      "2020-08-29 22:24:24,385 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "2020-08-29 22:24:24,385 -99 - forward - INFO - discoutParameterTensor.devicecuda:0\n",
      "2020-08-29 22:24:24,407 -118 - forward - INFO - \n",
      "2020-08-29 22:24:24,407 -118 - forward - INFO - \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CUDA but got backend CPU for sequence element 1 in sequence argument at position #1 'tensors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-43c0c48488f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfromAllToStr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'combinedRelationTensors.device:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcombinedRelationTensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'forward start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdifferenceLSTMNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombinedRelationTensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcombinedDiscountParameterTensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallCombineTensorTrain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#edit tag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'forward finished'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moutputDifferences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputGraphs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-185-2407708bbdef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, discountParameterTensor, vehicleGraph)\u001b[0m\n\u001b[1;32m    118\u001b[0m                     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfromAllToStr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                     \u001b[0mrelationTensorInBatchComputing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscountParameterTensorInBatchComputing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                     \u001b[0mcomputeRelationAndAllTheOtherTensorsWithDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreVehicleProperty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelationComputingBatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheGivenRange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfromAllToStr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relationTensorInBatchComputing.shape: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrelationTensorInBatchComputing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfromAllToStr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'discountParameterTensorInBatchComputing.shape: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiscountParameterTensorInBatchComputing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-150-9bfc794335f6>\u001b[0m in \u001b[0;36mcomputeRelationAndAllTheOtherTensorsWithDistance\u001b[0;34m(inputFrameTensor, theGivenRange, maxRelationsNumber)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvehicleId\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputFrameTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             relationTensor=relationCalculateWithRange(inputFrameTensor[timeStepCount].permute(1,0),\n\u001b[0;32m---> 23\u001b[0;31m                                                       theGivenRange,vehicleId,maxRelationsNumber=maxRelationsNumber)\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvehicleId\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mrelationTensorInOneTimeStep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelationTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-149-f7236752be67>\u001b[0m in \u001b[0;36mrelationCalculateWithRange\u001b[0;34m(propertyTensors, distanceRange, targetVehicleId, maxRelationsNumber)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mzeroTensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxRelationsNumber\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfinalPropertiesTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinalPropertiesTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         finalPropertiesTensor=torch.cat((finalPropertiesTensor,\\\n\u001b[0;32m---> 44\u001b[0;31m                                          zeroTensor))\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m#     logging.debug('targetVehicleId'+str(targetVehicleId))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CUDA but got backend CPU for sequence element 1 in sequence argument at position #1 'tensors'"
     ]
    }
   ],
   "source": [
    "if runDifferenceLSTMModel:\n",
    "    differenceLSTMNet.cuda()\n",
    "    losses1=[]\n",
    "    losses2=[]\n",
    "    lossesAll=[]\n",
    "    for items in iter(datasetV4Loader):\n",
    "        logging.info('data loading finished')\n",
    "        # differenceLSTMNet=differenceLSTMModel(outputTimeFrame=10) \n",
    "        allCombineTensorTrain, allCombineTensorValid,\\\n",
    "        combinedRelationTensors, combinedDiscountParameterTensors,differenceLabels=items\n",
    "        if useGpu:\n",
    "            combinedRelationTensors=Variable(combinedRelationTensors.cuda())\n",
    "            combinedDiscountParameterTensors=Variable(combinedDiscountParameterTensors.cuda())\n",
    "            allCombineTensorTrain=Variable(allCombineTensorTrain.cuda())\n",
    "            allCombineTensorValid=Variable(allCombineTensorValid.cuda())\n",
    "            differenceLabels=Variable(differenceLabels.cuda())\n",
    "        logging.info(fromAllToStr('combinedRelationTensors.device:',combinedRelationTensors.device))\n",
    "        logging.info('forward start')\n",
    "        result=differenceLSTMNet(combinedRelationTensors,combinedDiscountParameterTensors,allCombineTensorTrain) #edit tag\n",
    "        logging.info('forward finished')\n",
    "        outputDifferences,outputGraphs=result\n",
    "        loss1=MSELoss(outputDifferences,differenceLabels)\n",
    "        loss2=MSELoss(outputGraphs,allCombineTensorValid)\n",
    "        lossAll=loss1+loss2\n",
    "        losses.append(lossAll)\n",
    "        logging.info(fromAllToStr('loss1:',loss1,'\\nloss2:',loss2,'\\nlossAll:'.lossAll))\n",
    "        optim.zero_grad()\n",
    "        logging.info('backward started')\n",
    "        lossAll.backward()\n",
    "        logging.info('backward finished')\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differenceLSTMModel(\n",
      "  (fl): Linear(in_features=40, out_features=20, bias=True)\n",
      "  (il): Linear(in_features=40, out_features=20, bias=True)\n",
      "  (ol): Linear(in_features=40, out_features=20, bias=True)\n",
      "  (Cl): Linear(in_features=40, out_features=20, bias=True)\n",
      "  (fl2): Linear(in_features=40, out_features=20, bias=True)\n",
      "  (il2): Linear(in_features=40, out_features=20, bias=True)\n",
      "  (ol2): Linear(in_features=40, out_features=20, bias=True)\n",
      "  (Cl2): Linear(in_features=40, out_features=20, bias=True)\n",
      "  (fromRelationToEffectNet): fromRelationToEffectNetworkPositionOnly(\n",
      "    (positionRelationNet): relationNetwork(\n",
      "      (layer1): Linear(in_features=4, out_features=10, bias=True)\n",
      "      (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (layer5): Linear(in_features=10, out_features=40, bias=True)\n",
      "      (ReLU): ReLU()\n",
      "    )\n",
      "    (positionEffectNet): effectNetwork(\n",
      "      (layer1): Linear(in_features=44, out_features=10, bias=True)\n",
      "      (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (layer5): Linear(in_features=10, out_features=20, bias=True)\n",
      "      (ReLU): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (objectModifyNet): objectModifyNetwork(\n",
      "    (layer1): Linear(in_features=26, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=6, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      "  (effectComputationWithDiscountParameterNet): fromRelationToEffectNetworkWithDiscountParameter(\n",
      "    (positionRelationNet): relationNetwork(\n",
      "      (layer1): Linear(in_features=4, out_features=10, bias=True)\n",
      "      (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (layer5): Linear(in_features=10, out_features=40, bias=True)\n",
      "      (ReLU): ReLU()\n",
      "    )\n",
      "    (positionEffectNet): effectNetwork(\n",
      "      (layer1): Linear(in_features=44, out_features=10, bias=True)\n",
      "      (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (layer5): Linear(in_features=10, out_features=20, bias=True)\n",
      "      (ReLU): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (hiddenStateToDifferenceTensorNet): hiddenStateToDifferenceNetwork(\n",
      "    (layer1): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (layer2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer3): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer4): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (layer5): Linear(in_features=10, out_features=2, bias=True)\n",
      "    (ReLU): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(differenceLSTMNet)\n",
    "next(differenceLSTMNet.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 17:14:59,930 -1 - <module> - DEBUG - tensor(0.0296, grad_fn=<MseLossBackward>)tensor(0.0304, grad_fn=<MseLossBackward>)tensor(0.0600, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "logging.debug(fromAllToStr(loss1,loss2,lossAll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-29 15:59:03,017 -2 - <module> - DEBUG - torch.Size([2, 10, 2, 250])\n",
      "2020-08-29 15:59:03,018 -2 - <module> - DEBUG - torch.Size([2, 10, 2, 250])\n",
      "2020-08-29 15:59:03,019 -2 - <module> - DEBUG - torch.Size([2, 10, 5000, 4])\n",
      "2020-08-29 15:59:03,020 -2 - <module> - DEBUG - torch.Size([2, 10, 5000])\n",
      "2020-08-29 15:59:03,020 -2 - <module> - DEBUG - torch.Size([2, 10, 250, 2])\n",
      "2020-08-29 15:59:03,021 -3 - <module> - DEBUG - differenceLabels.shapetorch.Size([2, 10, 250, 2])\n"
     ]
    }
   ],
   "source": [
    "for eachItem in items:\n",
    "    logging.debug(fromAllToStr(eachItem.shape))\n",
    "logging.debug(fromAllToStr('differenceLabels.shape',differenceLabels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST RELATION WITHIN A GIVEN RANGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datasetV4Instance=tensorsDatasetV4(trajectoryFileList,lableTensorEachBatch=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datasetV4Loader=DataLoader(datasetV4Instance,batch_size=5,num_workers=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "itemList=datasetV4Instance.__getitem__(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for item in itemList:\n",
    "    logging.debug(fromAllToStr(item.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combineTensorTrain,combineTensorValid,combinedRelationTensors,combinedDiscountParameterTensors,\\\n",
    "differenceLabels=itemList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logging.debug(fromAllToStr('combnedRelationTensors.shape',combinedRelationTensors.shape))\n",
    "for i in range(combinedRelationTensors.shape[0]):\n",
    "    logging.debug(fromAllToStr('combinedRelationTensor, batch ', i, ':',combinedRelationTensors[i,0:50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logging.debug(fromAllToStr(\"relationInAllTimeStep.shape:\",relationInAllTimeStep.shape))\n",
    "logging.debug(fromAllToStr(\"discountInAllTimeStep,shape:\",discountInAllTimeStep.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorA=torch.randn(10,10,100)\n",
    "tensorB=torch.randn(10,10,1)\n",
    "logging.debug(fromAllToStr('tensorA',tensorA))\n",
    "logging.debug(fromAllToStr('tensorB',tensorB))\n",
    "tensorAmB=torch.mul(tensorA,tensorB)\n",
    "logging.debug(fromAllToStr('tensorAmB',tensorAmB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loaderIter=iter(datasetV3Loader)\n",
    "toTestDifferenceItem, toTestDifferenceLabel=loaderIter.__next__()\n",
    "logging.debug(fromAllToStr(\"toTestDifferenceItem[0]:\",toTestDifferenceItem[0][0][0]))\n",
    "differenceSeries=differenceBetweenTwoFrameForBatch(toTestDifferenceItem)\n",
    "logging.debug(fromAllToStr('differenceSeries.shape:',differenceSeries.shape,'toTestDifferenceItem.shape:',\\\n",
    "                          toTestDifferenceItem.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logging.info('test')\n",
    "logTensor=torch.zeros(3,3)\n",
    "logging.debug(str(logTensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testTensor=torch.rand((6))\n",
    "logging.debug(testTensor)\n",
    "logging.debug(testTensor.expand(3,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test seq2seq relation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#test code\n",
    "if runSeq2SeqRelationModel:\n",
    "    outputTimeFrame=5\n",
    "    RelationLSTMSeq2SeqModel=RelationLSTMSeq2Seq(outputTimeFrame=outputTimeFrame)\n",
    "    datasetV3Instance=tensorsDatasetV3(trajectoryFileList,lableTensorEachBatch=outputTimeFrame)\n",
    "    datasetV3Loader=DataLoader(datasetV3Instance,batch_size=2)\n",
    "    V3iter=iter(datasetV3Loader)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#test code\n",
    "if runSeq2SeqRelationModel:\n",
    "    RelationLSTMSeq2SeqModel=RelationLSTMSeq2Seq(outputTimeFrame=outputTimeFrame)\n",
    "    inputs, labels=V3iter.__next__()\n",
    "    inputs=fromObjectsToRelationPairsBatchAndTimestepVersion(inputs)\n",
    "    outputs=RelationLSTMSeq2SeqModel(inputs)\n",
    "    print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading model and dataset\n",
    "if runSeq2SeqRelationModel:\n",
    "    epochs=500\n",
    "    itersInEachEpoch=100\n",
    "    outputTimeFrame=500\n",
    "    relationLSTMSeq2SeqModel=RelationLSTMSeq2SeqPositionOnly(outputTimeFrame=outputTimeFrame)\n",
    "    datasetV3Instance=tensorsDatasetV3(trajectoryFileList,lableTensorEachBatch=outputTimeFrame)\n",
    "    datasetV3Loader=DataLoader(datasetV3Instance,batch_size=8,num_workers=4)\n",
    "    V3iter=iter(datasetV3Loader)\n",
    "    if useGpu:\n",
    "        relationLSTMSeq2SeqModel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runSeq2SeqRelationModel:\n",
    "    if not isTest:\n",
    "        learningRate=1e-3\n",
    "        lossFn=elementWeightedLoss(100,0.1,0.1)\n",
    "        lambdaWholeNet=lambda epoch: 0.5**(epoch//30)\n",
    "        optim=torch.optim.RMSprop([{'params':relationLSTMSeq2SeqModel.parameters(),'initial_lr':learningRate}],lr=learningRate)\n",
    "        lrSchedule=torch.optim.lr_scheduler.LambdaLR(optim,lambdaWholeNet,last_epoch=10)\n",
    "        relationLSTMSeq2SeqModel.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training seq2seqRelation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runSeq2SeqRelationModel:\n",
    "    if not isTest:\n",
    "        lossCurve=[]\n",
    "        for epoch in range(epochs):\n",
    "            for iteration in range(itersInEachEpoch):\n",
    "                try:\n",
    "                    inputs, labels=V3iter.__next__()\n",
    "                except StopIteration:\n",
    "                    V3iter=iter(datasetV3Loader)\n",
    "                    inputs, labels=V3iter.__next__()\n",
    "                inputs=fromObjectsToRelationPairsBatchAndTimestepVersion(inputs)\n",
    "                labels=labels.permute(0,1,3,2)\n",
    "                if useGpu:\n",
    "                    inputs=Variable(inputs.cuda())\n",
    "                    labels=Variable(labels.cuda())\n",
    "                outputs=relationLSTMSeq2SeqModel(inputs)\n",
    "                logging.debug(fromAllToStr('compare the shape of outputs and labels:',outputs.shape, labels.shape))\n",
    "                loss=lossFn(outputs,labels)\n",
    "                lossCurve.append(loss)\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                logging.info(fromAllToStr('loss in opoch ',epoch,',iteration',iteration,':',loss))\n",
    "                if(iteration%10==0):\n",
    "                    plt.plot(lossCurve)\n",
    "                    plt.savefig(fromAllToStr('.\\positionOnly\\lossCurve epoch ',epoch+1000000, ' iteration ',iteration+10000000,'.jpg'))\n",
    "            lrSchedule.step()\n",
    "            if epoch%2==0:\n",
    "                torch.save(relationLSTMSeq2SeqModel.state_dict(),\\\n",
    "                           '.\\positionOnly\\relationLSTMSeq2SeqMode_in_epoch_weightedLossAndPositionOnly_'+str(epoch+10000)+'.pt')\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing seq2seqRelation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetV3Loader=DataLoader(datasetV3Instance,batch_size=2,num_workers=4)\n",
    "V3iter=iter(datasetV3Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 6, 250]) torch.Size([5, 5, 6, 250])\n",
      "torch.Size([5, 10, 62250, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangyuchen/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/wangyuchen/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "2020-08-23 17:47:35,285 -106 - forward - DEBUG - preEffect.shape: torch.Size([5, 250, 20])\n",
      "2020-08-23 17:47:35,287 -108 - forward - DEBUG - Hidden_State_2.shape: torch.Size([5, 250, 20])\n",
      "2020-08-23 17:47:35,289 -110 - forward - DEBUG - effectFromeHiddenState.shape: torch.Size([5, 250, 20])\n",
      "2020-08-23 17:47:35,291 -112 - forward - DEBUG - objectAndEffectTensor.shape: torch.Size([5, 250, 26])\n",
      "2020-08-23 17:47:35,293 -114 - forward - DEBUG - modifiedObject.shape: torch.Size([5, 250, 6])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in seq2seq, inputs shape: torch.Size([5, 10, 62250, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-23 17:47:35,654 -106 - forward - DEBUG - preEffect.shape: torch.Size([5, 250, 20])\n",
      "2020-08-23 17:47:35,656 -108 - forward - DEBUG - Hidden_State_2.shape: torch.Size([5, 250, 20])\n",
      "2020-08-23 17:47:35,658 -110 - forward - DEBUG - effectFromeHiddenState.shape: torch.Size([5, 250, 20])\n",
      "2020-08-23 17:47:35,659 -112 - forward - DEBUG - objectAndEffectTensor.shape: torch.Size([5, 250, 26])\n",
      "2020-08-23 17:47:35,661 -114 - forward - DEBUG - modifiedObject.shape: torch.Size([5, 250, 6])\n",
      "2020-08-23 17:47:36,013 -106 - forward - DEBUG - preEffect.shape: torch.Size([5, 250, 20])\n",
      "2020-08-23 17:47:36,015 -108 - forward - DEBUG - Hidden_State_2.shape: torch.Size([5, 250, 20])\n",
      "2020-08-23 17:47:36,017 -110 - forward - DEBUG - effectFromeHiddenState.shape: torch.Size([5, 250, 20])\n",
      "2020-08-23 17:47:36,018 -112 - forward - DEBUG - objectAndEffectTensor.shape: torch.Size([5, 250, 26])\n",
      "2020-08-23 17:47:36,020 -114 - forward - DEBUG - modifiedObject.shape: torch.Size([5, 250, 6])\n",
      "2020-08-23 17:47:36,371 -106 - forward - DEBUG - preEffect.shape: torch.Size([5, 250, 20])\n",
      "2020-08-23 17:47:36,374 -108 - forward - DEBUG - Hidden_State_2.shape: torch.Size([5, 250, 20])\n",
      "2020-08-23 17:47:36,376 -110 - forward - DEBUG - effectFromeHiddenState.shape: torch.Size([5, 250, 20])\n",
      "2020-08-23 17:47:36,377 -112 - forward - DEBUG - objectAndEffectTensor.shape: torch.Size([5, 250, 26])\n",
      "2020-08-23 17:47:36,379 -114 - forward - DEBUG - modifiedObject.shape: torch.Size([5, 250, 6])\n",
      "2020-08-23 17:47:36,741 -106 - forward - DEBUG - preEffect.shape: torch.Size([5, 250, 20])\n",
      "2020-08-23 17:47:36,743 -108 - forward - DEBUG - Hidden_State_2.shape: torch.Size([5, 250, 20])\n",
      "2020-08-23 17:47:36,745 -110 - forward - DEBUG - effectFromeHiddenState.shape: torch.Size([5, 250, 20])\n",
      "2020-08-23 17:47:36,746 -112 - forward - DEBUG - objectAndEffectTensor.shape: torch.Size([5, 250, 26])\n",
      "2020-08-23 17:47:36,748 -114 - forward - DEBUG - modifiedObject.shape: torch.Size([5, 250, 6])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5, 250, 6])\n"
     ]
    }
   ],
   "source": [
    "if runSeq2SeqRelationModel:\n",
    "    if isTest:\n",
    "        relationLSTMSeq2SeqModel.eval()\n",
    "        with torch.no_grad():\n",
    "            relationLSTMSeq2SeqModel.load_state_dict(torch.load('relationLSTMSeq2SeqMode_in_epoch_weightedLossAndPositionOnly_10008.pt'))\n",
    "    #         inputs,labels=V3iter.__next__()\n",
    "            itemIndex=5838\n",
    "            inputs,labels=datasetV3Instance.__getitem__(itemIndex)\n",
    "            inputs=inputs.unsqueeze(0)\n",
    "            labels=labels.unsqueeze(0)\n",
    "            for ii in range(4):\n",
    "                newInput, newLabel=datasetV3Instance.__getitem__(itemIndex+ii)\n",
    "                newInput=newInput.unsqueeze(0)\n",
    "                newLabel=newLabel.unsqueeze(0)\n",
    "                inputs=torch.cat((inputs,newInput),0)\n",
    "                labels=torch.cat((labels,newLabel),0)\n",
    "\n",
    "            print(inputs.shape,labels.shape)\n",
    "\n",
    "            inputs=fromObjectsToRelationPairsBatchAndTimestepVersion(inputs)\n",
    "            print(inputs.shape)\n",
    "            labels=labels.permute(0,1,3,2)\n",
    "            outputs=relationLSTMSeq2SeqModel(inputs)\n",
    "            print(outputs.shape)\n",
    "            normalizationDict=datasetV3Instance.getNormalizationDict()\n",
    "            for i in range(labels.shape[1]):\n",
    "                resultImage=visualizeTensorData(outputs[0,i,:,0],outputs[0,i,:,1],normalizationDict=normalizationDict)\n",
    "                fileName='./predictWithRelationSeq2Seq/'+str(i)+'.png'\n",
    "                cv2.imwrite(fileName,resultImage)\n",
    "                resultImage=visualizeTensorData(labels[0,i,:,0],labels[0,i,:,1],normalizationDict=normalizationDict)\n",
    "                fileName='./predictWithRelationSeq2Seq/'+'l'+str(i)+'.png'\n",
    "                cv2.imwrite(fileName,resultImage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-23 18:03:53,663 -10 - <module> - DEBUG - torch.Size([5, 1, 1, 6])\n",
      "2020-08-23 18:03:53,664 -11 - <module> - DEBUG - tensor([[[[0.1176, 0.0546, 0.0279, 0.5070, 0.0483, 0.5155]]],\n",
      "\n",
      "\n",
      "        [[[0.1176, 0.0546, 0.0279, 0.5070, 0.0483, 0.5155]]],\n",
      "\n",
      "\n",
      "        [[[0.1215, 0.0595, 0.0295, 0.5152, 0.0483, 0.5197]]],\n",
      "\n",
      "\n",
      "        [[[0.1230, 0.0636, 0.0290, 0.5147, 0.0479, 0.5192]]],\n",
      "\n",
      "\n",
      "        [[[0.1257, 0.0675, 0.0284, 0.5142, 0.0483, 0.5188]]]])\n"
     ]
    }
   ],
   "source": [
    "if runSeq2SeqRelationModel:\n",
    "    if isTest:\n",
    "        vehicleListHalf=[]\n",
    "        for i in range(0,250,2):\n",
    "            vehicleListHalf.append(i)\n",
    "        trajectoryImage=visualizeTrajectory(outputs,normalizationDict=normalizationDict,radius=3,vehicleList=vehicleListHalf)\n",
    "        cv2.imwrite('trajectoryImage.jpg',trajectoryImage[0]) \n",
    "        differenceEachVehicleEachFrame,differenceEachVehicleAllFrame,averageDifferenceAllVehicleEachFrame,\\\n",
    "        averageDifferenceAllVehicleAllFrame=numericalEvaluation(outputs,labels) \n",
    "        logging.debug(fromAllToStr(averageDifferenceAllVehicleAllFrame.shape))\n",
    "        logging.debug(fromAllToStr(averageDifferenceAllVehicleAllFrame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test lstm relation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start test lstm relation model\n"
     ]
    }
   ],
   "source": [
    "print('start test lstm relation model')\n",
    "if runRelationLSTM:\n",
    "    datasetV3Instance=tensorsDatasetV3(trajectoryFileList)\n",
    "    datasetV3Loader=DataLoader(datasetV3Instance,batch_size=2)\n",
    "    V3iter=iter(datasetV3Loader)\n",
    "    relationLSTMInstance=RelationLSTM()\n",
    "    if useGpu:\n",
    "        relationLSTMInstance.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "def calculateXandN(x,n):\n",
    "    return (1+x)/(n+1+2*x)\n",
    "ns=[]\n",
    "xs=[]\n",
    "for i in range(0,100):\n",
    "    xs.append(i)\n",
    "for i in range(0,10):\n",
    "    ns.append(i)\n",
    "lines=[]\n",
    "for i in range(20):\n",
    "    lines.append([])\n",
    "for x in xs:\n",
    "    for n in ns:\n",
    "        lines[n].append(calculateXandN(x,n))\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(241)\n",
    "plt.plot(xs,lines[0],'b')\n",
    "plt.plot(xs,lines[1],'g')\n",
    "plt.plot(xs,lines[2],'k')\n",
    "plt.plot(xs,lines[3],'y')\n",
    "plt.plot(xs,lines[4],'m')\n",
    "plt.plot(xs,lines[5],'-')\n",
    "plt.subplot(242)\n",
    "plt.plot(ns,lines[0],'b')\n",
    "plt.subplot(243)\n",
    "plt.plot(ns,lines[1],'b')\n",
    "plt.subplot(244)\n",
    "plt.plot(ns,lines[2],'b')\n",
    "plt.subplot(245)\n",
    "plt.plot(ns,lines[3],'b')\n",
    "plt.subplot(246)\n",
    "plt.plot(ns,lines[4],'b')\n",
    "plt.subplot(247)\n",
    "plt.plot(ns,lines[5],'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training relation lstm\n",
    "if runRelationLSTM:\n",
    "    if not isTest:\n",
    "        learningRate=1e-3\n",
    "        MSELoss=nn.MSELoss()\n",
    "        lambdaWholeNet=lambda epoch: 0.5**(epoch//30)\n",
    "        optim=torch.optim.RMSprop([{'params':relationLSTMInstance.parameters(),'initial_lr':learningRate}],lr=learningRate)\n",
    "        lrSchedule=torch.optim.lr_scheduler.LambdaLR(optim,lambdaWholeNet,last_epoch=10)\n",
    "        relationLSTMInstance.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "label.shape torch.Size([2, 10, 6, 250])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangyuchen/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/wangyuchen/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "torch.Size([2, 10, 62250, 12])\n",
      "output.shape torch.Size([2, 250, 6])\n",
      "epoch  0  i 1  loss tensor(0.0382, grad_fn=<MseLossBackward>)\n",
      "label.shape torch.Size([2, 10, 6, 250])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "torch.Size([2, 10, 62250, 12])\n",
      "output.shape torch.Size([2, 250, 6])\n",
      "epoch  0  i 2  loss tensor(0.0286, grad_fn=<MseLossBackward>)\n",
      "label.shape torch.Size([2, 10, 6, 250])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "in step,combined.shape torch.Size([2, 250, 40])\n",
      "torch.Size([2, 10, 62250, 12])\n",
      "output.shape torch.Size([2, 250, 6])\n",
      "epoch  0  i 3  loss tensor(0.0229, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-c7320c2e96b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#             outputView=output.reshape((7,6,250)).cpu()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if runRelationLSTM:\n",
    "    #training relation lstm\n",
    "    if not runOnG814:\n",
    "        %matplotlib inline\n",
    "    from IPython.display import clear_output\n",
    "    normalizationDict=datasetV3Instance.getNormalizationDict()\n",
    "    optim.zero_grad()\n",
    "    if not isTest:  \n",
    "        losses=[]\n",
    "        iterInEpoch=50\n",
    "        for epoch in range(5):\n",
    "            print(epoch)\n",
    "            i=0\n",
    "            for inputs,label in V3iter:\n",
    "                i=i+1\n",
    "                if i>iterInEpoch*(epoch+1):\n",
    "                    break\n",
    "        #         print(i)\n",
    "                inputs=fromObjectsToRelationPairsBatchAndTimestepVersion(inputs)\n",
    "                print('label.shape',label.shape)\n",
    "                label=label[:,0,:,:].squeeze()\n",
    "                label=label.permute(0,2,1)\n",
    "#                 label=label[:,tupleForEachVehicle,0:6]\n",
    "                if useGpu:\n",
    "                    inputs=Variable(inputs.cuda())\n",
    "                    label=Variable(label.cuda())\n",
    "                output=relationLSTMInstance(inputs)\n",
    "\n",
    "        #         print(output[0,0:10,:],secondObjects[0,0:10,:])\n",
    "                print('output.shape',output.shape)\n",
    "                loss=MSELoss(output,label)\n",
    "                if i<5:\n",
    "                    print('epoch ',epoch, ' i', i,' loss',loss)\n",
    "        #         print(loss)\n",
    "                losses.append(loss.item())\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "    #             outputView=output.reshape((7,6,250)).cpu()\n",
    "    #             for j in range(10):\n",
    "    #                 inputs=inputs.cpu()\n",
    "    #                 resultImage=visualizeTensorData(inputs[0,j,0,:],inputs[0,j,1,:],normalizationDict=normalizationDict)\n",
    "    #                 fileName='./predictWithRelationLSTM/'+str((epoch+1)*10000000+i*100000+j)+'.png'\n",
    "    #                 cv2.imwrite(fileName,resultImage)\n",
    "    #             resultImage=visualizeTensorData(outputView[0,0,:],outputView[0,1,:],normalizationDict=normalizationDict)\n",
    "    #             fileName='./predictWithLSTMOnly/'+str((epoch+1)*10000000+i*100000+50)+'.png' #the predicted image is named with string which last two number is 50(because j < 50)\n",
    "    #             cv2.imwrite(fileName,resultImage)\n",
    "            lrSchedule.step()\n",
    "        plt.figure(figsize=(30,30))\n",
    "        plt.plot(losses)\n",
    "        plt.savefig('./losses.png')\n",
    "        torch.save(relationLSTMInstance.state_dict(),'./relationLSTM.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test relation-object model over a period of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runObjectRelationNet:\n",
    "    normalizationDict=datasetV2.getNormalizationDict()\n",
    "\n",
    "    datas=[]\n",
    "    for i in range(0,6):\n",
    "        break\n",
    "        datas.append([])\n",
    "    for ii in range(0,2000):\n",
    "        break\n",
    "        theInput,second=datasetV2.__getitem__(ii)\n",
    "        theInput=theInput.unsqueeze(0)\n",
    "        second=second.unsqueeze(0)\n",
    "        #         print(i)\n",
    "        #         theInput,second=item\n",
    "        if useGpu:\n",
    "            theInput=Variable(theInput.cuda())\n",
    "            second=Variable(second.cuda())\n",
    "        inputObjects=theInput[:,tupleForEachVehicle,0:6]\n",
    "        secondObjects=second[:,tupleForEachVehicle,0:6]\n",
    "        for i in range(0,6):\n",
    "            datas[i].append(inputObjects[0,0,i])\n",
    "    #     print('inputObjects.shape',inputObjects.shape)\n",
    "    #     resultImage=visualizeTensorData(inputObjects[0,:,0].cpu(),inputObjects[0,:,1].cpu(),normalizationDict=normalizationDict)\n",
    "    #     fileName='./resultImage/'+str(ii)+'.png'\n",
    "    #     cv2.imwrite(fileName,resultImage)\n",
    "    timeStamp=int(time.time())\n",
    "    dirName='resultImage'+str(timeStamp)\n",
    "    os.mkdir(dirName)\n",
    "    if isTest:\n",
    "        with torch.no_grad():\n",
    "            wholeNet.eval()\n",
    "            theInput,second=datasetV2.__getitem__(5000)\n",
    "            theInput=theInput.unsqueeze(0)\n",
    "            second=second.unsqueeze(0)\n",
    "        #         print(i)\n",
    "    #         theInput,second=item\n",
    "            if useGpu:\n",
    "                theInput=Variable(theInput.cuda())\n",
    "                second=Variable(second.cuda())\n",
    "            inputObjects=theInput[:,tupleForEachVehicle,0:6]\n",
    "            secondObjects=second[:,tupleForEachVehicle,0:6]\n",
    "            print('inputObjects.shape',inputObjects.shape)\n",
    "            resultImage=visualizeTensorData(inputObjects[0,:,0].cpu(),inputObjects[0,:,1].cpu(),normalizationDict=normalizationDict)\n",
    "            fileName='./resultImage/'+'0000000000000000'+'.png'\n",
    "            cv2.imwrite(fileName,resultImage)\n",
    "            stepInput=fromObjectsToRelationPairs(inputObjects[0].permute(1,0)).unsqueeze(0)\n",
    "        #             output=wholeNet(theInput)\n",
    "            print(stepInput.shape)\n",
    "        #             print(output.shape)\n",
    "            #predict step by step\n",
    "            for step in range(500):\n",
    "                output=wholeNet(stepInput)\n",
    "                print('step: ',step)\n",
    "                for ii in range(output.shape[1]):\n",
    "                    print(output[0,ii])\n",
    "    #             break\n",
    "    #             for j in range(10):\n",
    "    #                 print(stepInput[:,tupleForEachVehicle,0:6][0,j,:])\n",
    "    #                 print(output[0,j,:])\n",
    "    #                 print()\n",
    "                stepInput=fromObjectsToRelationPairs(output[0].permute(1,0)).unsqueeze(0)\n",
    "    #             print('outputShape',output.shape)\n",
    "    #             print('outputshape[0]',output[0].shape)\n",
    "                resultImage=visualizeTensorData(output[0,:,0].cpu(),output[0,:,1].cpu(),normalizationDict=normalizationDict)\n",
    "\n",
    "                import os\n",
    "                fileName='./'+dirName+'/'+str(1000000+step)+'.png'\n",
    "                cv2.imwrite(fileName,resultImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training and testing process for 'fromRelationToObjectnetwork'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runObjectRelationNet:\n",
    "    #generate a tuple in which each element is the index of a vehicle\n",
    "    #the tuple is used to get the property of each vehicle from the left side of data from the dataset function\n",
    "    listForEachVehicle=[]\n",
    "    for i in range(maxMatrixIndex):\n",
    "        listForEachVehicle.append(i*(maxMatrixIndex-1))\n",
    "    tupleForEachVehicle=tuple(listForEachVehicle)\n",
    "\n",
    "    dataloaderV2=DataLoader(datasetV2,batch_size=1,shuffle=True)\n",
    "\n",
    "\n",
    "    wholeNet=fromRelationToObjectNetwork()\n",
    "    if isTest:\n",
    "        wholeNet.load_state_dict(torch.load(modelPath))\n",
    "\n",
    "\n",
    "    if useGpu:\n",
    "        wholeNet.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runObjectRelationNet:\n",
    "    if not isTest:\n",
    "        learningRate=1e-3\n",
    "        MSELoss=nn.MSELoss()\n",
    "        lambdaWholeNet=lambda epoch: 0.5**(epoch//30)\n",
    "        optim=torch.optim.RMSprop([{'params':wholeNet.parameters(),'initial_lr':learningRate}],lr=learningRate)\n",
    "        lrSchedule=torch.optim.lr_scheduler.LambdaLR(optim,lambdaWholeNet,last_epoch=10)\n",
    "        wholeNet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if runObjectRelationNet:\n",
    "    if not runOnG814:\n",
    "        %matplotlib inline\n",
    "    from IPython.display import clear_output\n",
    "    if not isTest:  \n",
    "        losses=[]\n",
    "        iterInEpoch=50\n",
    "        for epoch in range(300):\n",
    "            print(epoch)\n",
    "            for i,item in enumerate(dataloaderV2):\n",
    "                if i>iterInEpoch:\n",
    "                    break\n",
    "        #         print(i)\n",
    "                theInput,second=item\n",
    "                if useGpu:\n",
    "                    theInput=Variable(theInput.cuda())\n",
    "                    second=Variable(second.cuda())\n",
    "                secondObjects=second[:,tupleForEachVehicle,0:6]\n",
    "\n",
    "                output=wholeNet(theInput)\n",
    "        #         print(output[0,0:10,:],secondObjects[0,0:10,:])\n",
    "                loss=MSELoss(output,secondObjects)\n",
    "                if i<5:\n",
    "                    print('epoch ',epoch, ' i', i,' loss',loss)\n",
    "        #         print(loss)\n",
    "                losses.append(loss.item())\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "            lrSchedule.step()\n",
    "        plt.figure(figsize=(30,30))\n",
    "        plt.plot(losses)\n",
    "        plt.savefig('./losses.png')\n",
    "        torch.save(wholeNet.state_dict(),'./wholeNet_300epoch_50perEpoch.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training simple LSTM module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runLSTM:\n",
    "    #lstm version \n",
    "    if not isTest:\n",
    "        learningRate=1e-3\n",
    "        MSELoss=nn.MSELoss()\n",
    "        lambdaWholeNet=lambda epoch: 0.5**(epoch//30)\n",
    "        optim=torch.optim.RMSprop([{'params':lstmModel.parameters(),'initial_lr':learningRate}],lr=learningRate)\n",
    "        lrSchedule=torch.optim.lr_scheduler.LambdaLR(optim,lambdaWholeNet,last_epoch=10)\n",
    "        lstmModel.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if runLSTM:\n",
    "    #lstm version\n",
    "    if not runOnG814:\n",
    "        %matplotlib inline\n",
    "    from IPython.display import clear_output\n",
    "    normalizationDict=datasetV3.getNormalizationDict()\n",
    "    if not isTest:  \n",
    "        losses=[]\n",
    "        iterInEpoch=50\n",
    "        for epoch in range(5):\n",
    "            print(epoch)\n",
    "            i=0\n",
    "            for inputs,label in iterV3:\n",
    "                i=i+1\n",
    "                if i>iterInEpoch*(epoch+1):\n",
    "                    break\n",
    "        #         print(i)\n",
    "                if useGpu:\n",
    "                    inputs=Variable(inputs.cuda())\n",
    "                    label=Variable(label.cuda())\n",
    "                output=lstmModel(inputs.reshape((inputs.shape[0],inputs.shape[1],-1)))\n",
    "\n",
    "        #         print(output[0,0:10,:],secondObjects[0,0:10,:])\n",
    "                loss=MSELoss(output,label.squeeze().reshape((label.shape[0],-1)))\n",
    "                if i<5:\n",
    "                    print('epoch ',epoch, ' i', i,' loss',loss)\n",
    "        #         print(loss)\n",
    "                losses.append(loss.item())\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                outputView=output.reshape((7,6,250)).cpu()\n",
    "                for j in range(10):\n",
    "                    inputs=inputs.cpu()\n",
    "                    resultImage=visualizeTensorData(inputs[0,j,0,:],inputs[0,j,1,:],normalizationDict=normalizationDict)\n",
    "                    fileName='./predictWithLSTMOnly/'+str((epoch+1)*10000000+i*100000+j)+'.png'\n",
    "                    cv2.imwrite(fileName,resultImage)\n",
    "                resultImage=visualizeTensorData(outputView[0,0,:],outputView[0,1,:],normalizationDict=normalizationDict)\n",
    "                fileName='./predictWithLSTMOnly/'+str((epoch+1)*10000000+i*100000+50)+'.png' #the predicted image is named with string which last two number is 50(because j < 50)\n",
    "                cv2.imwrite(fileName,resultImage)\n",
    "            lrSchedule.step()\n",
    "        plt.figure(figsize=(30,30))\n",
    "        plt.plot(losses)\n",
    "        plt.savefig('./losses.png')\n",
    "        torch.save(wholeNet.state_dict(),'./wholeNet_300epoch_50perEpoch.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#draw properties of a single tensor over time\n",
    "#output results step by step\n",
    "plt.subplot(321)\n",
    "plt.plot(datas[0])\n",
    "plt.subplot(322)\n",
    "plt.plot(datas[1])\n",
    "plt.subplot(323)\n",
    "plt.plot(datas[2])\n",
    "plt.subplot(324)\n",
    "plt.plot(datas[3])\n",
    "plt.subplot(325)\n",
    "plt.plot(datas[4])\n",
    "plt.subplot(326)\n",
    "plt.plot(datas[5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
