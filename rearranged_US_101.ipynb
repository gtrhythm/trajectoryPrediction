{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def getValueByLable(lableList,valueList):\n",
    "    \"\"\"\n",
    "    For instance, given a lable list ['Local_X','Local_Y'] and a value list [2.0, 24.0, 437.0, 1118846981300.0, 16.254, \n",
    "    79.349, 6451167.199, 1873312.382, 14.5, 4.9, 2.0, 39.14, -5.73, 2.0, 0.0, 13.0, 0.0, 0.0] which values sorted by the \n",
    "    order of allLableList below, the function return a value Dict {'Local_X':16.254, 'Local_Y':79.349}\n",
    "    Args:\n",
    "        lableList: the list of lables you've required, such as['Vehicle_ID', 'Total_Frames','Global_Time']\n",
    "        valueList: the list contains all legally value, sorted by:['Vehicle_ID', 'Frame_ID','Total_Frames','Global_Time','Local_X','Local_Y','Global_X','Global_Y',\\\n",
    "                      'v_Length','v_Width','v_Class','v_Vel','v_Acc','Lane_ID','Preceding','Following','Space_Headway',\\\n",
    "                      'Time_Headway']\n",
    "    Returns: \n",
    "        value list in the as the order of lableList\n",
    "    For instance, given a lable list ['Local_X','Local_Y'] and a value list [2.0, 24.0, 437.0, 1118846981300.0, 16.254, \n",
    "    79.349, 6451167.199, 1873312.382, 14.5, 4.9, 2.0, 39.14, -5.73, 2.0, 0.0, 13.0, 0.0, 0.0] which values sorted by the \n",
    "    order of allLableList above, the function return a value List [16.254, 79.349]\n",
    "\n",
    "    \"\"\"\n",
    "    allLableList=['Vehicle_ID', 'Frame_ID','Total_Frames','Global_Time','Local_X','Local_Y','Global_X','Global_Y',\\\n",
    "                  'v_Length','v_Width','v_Class','v_Vel','v_Acc','Lane_ID','Preceding','Following','Space_Headway',\\\n",
    "                  'Time_Headway']\n",
    "    valueDictReturn={}\n",
    "    for lableItem in lableList:\n",
    "        valueDictReturn[lableItem]=valueList[allLableList.index(lableItem)]\n",
    "    return valueDictReturn\n",
    "\n",
    "def rearrangeDataByGlobalTime(allValueLists):\n",
    "    '''\n",
    "    Args:\n",
    "        allValueLists: all values have been read from a txt file which have already been converted to a list\n",
    "    Returns:\n",
    "        dict have been arranged by global time. One single global time generally contains several value lists.\n",
    "    '''\n",
    "    valueDict={}\n",
    "    for valueList in allValueLists:\n",
    "        dictKey=getValueByLable(['Global_Time'],valueList)['Global_Time']\n",
    "        if dictKey in valueDict:\n",
    "            # if dictKey already there, then add valueList to the list of the key\n",
    "            valueDict[dictKey].append(valueList)\n",
    "        else:\n",
    "            #else, create a list and append valueList on it\n",
    "            valueDict[dictKey]=[valueList]\n",
    "    return valueDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def readFirstFrame(matrixIndexAndVehicleIDRecordDictParam, valueLists):\n",
    "    \"\"\"\n",
    "    To generate the first set of tensors from the first frame\n",
    "    Args:\n",
    "        matrixIndexAndVehicleIDRecordDictParam: just as its name\n",
    "        valueLists: a list consists of all valuelist at one time\n",
    "    Returns:\n",
    "        several tensors arranged by: positionTensor, speedTensor, accTensor, angleTensor,newVehicleList(type:list)\n",
    "    \n",
    "    \"\"\"\n",
    "    maxMatrixIndex=matrixIndexAndVehicleIDRecordDictParam.keys().__len__()-1\n",
    "    #tensors initialize\n",
    "    positionTensor=torch.zeros(2,maxMatrixIndex)\n",
    "    speedTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    accTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    angleTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    newVehicleIDList=[]\n",
    "    curMatrixIndex=0\n",
    "    matrixIndexAndVehicleIDRecordDictParam['time']=getValueByLable([\"Global_Time\"],valueLists[0])['Global_Time']\n",
    "    #fill out all tensors\n",
    "    for eachValueList in valueLists:\n",
    "        #get values from eachValueList, generate dict\n",
    "        returnedEachValueDict=getValueByLable(['Vehicle_ID','Local_X','Local_Y','v_Vel','v_Acc'],eachValueList)\n",
    "        #assign to the curMatrixIndex-th row of corresponding tensor\n",
    "        #angle Tensor assignment is not neeed for the initial value of each element in it is already zero\n",
    "        positionTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['Local_X'],returnedEachValueDict['Local_Y']))\n",
    "        speedTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Vel']))\n",
    "        accTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Acc']))\n",
    "        #then handle the record matrix\n",
    "        matrixIndexAndVehicleIDRecordDictParam[curMatrixIndex]['Vehicle_ID']=returnedEachValueDict['Vehicle_ID']\n",
    "        matrixIndexAndVehicleIDRecordDictParam[curMatrixIndex]['refresh']=0\n",
    "        newVehicleIDList.append(copy.deepcopy(returnedEachValueDict['Vehicle_ID']))\n",
    "        curMatrixIndex=curMatrixIndex+1\n",
    "    return positionTensor,speedTensor,accTensor,angleTensor,newVehicleIDList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMatrixIndexByVehicleID(matrixIndexAndVehicleIDRecordDictParam, vehicle_ID):\n",
    "    for i in range(0, len(matrixIndexAndVehicleIDRecordDictParam)-1):\n",
    "        if matrixIndexAndVehicleIDRecordDictParam[i]['Vehicle_ID']==vehicle_ID:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def findEmptyMatrixIndex(matrixIndexAndVehicleIDRecordDictParam):\n",
    "    for i in range(0, len(matrixIndexAndVehicleIDRecordDictParam)-1):\n",
    "        if matrixIndexAndVehicleIDRecordDictParam[i]['Vehicle_ID']==-1:\n",
    "            #Vehicle_ID=-1 when there is no existed vehicle ID bounding to the index\n",
    "            return i\n",
    "    raise Exception(\"NO EMPTY ELEMENT IN MATRIX\")\n",
    "\n",
    "def readGeneralFrame(matrixIndexAndVehicleIDRecordDictParam, valueLists, prePositionTensor):\n",
    "    \"\"\"\n",
    "    To generate the first set of tensors from the general frame that have a preceding one\n",
    "    Args:\n",
    "        matrixIndexAndVehicleIDRecordDictParam: just as its name\n",
    "        valueLists: a list consists of all valuelist at one time\n",
    "        prePositionTensor: positionTensor from the preceding frame, which is used to calculate angle tensor\n",
    "    Returns:\n",
    "        everal tensors arranged by: positionTensor, speedTensor, accTensor, angleTensor,newVehicleList(type:list),\n",
    "        vanishedVehicleList(type:list)\n",
    "    \n",
    "    \"\"\"\n",
    "    #tensors initialize\n",
    "    maxMatrixIndex=matrixIndexAndVehicleIDRecordDictParam.keys().__len__()-1\n",
    "    positionTensor=torch.zeros(2,maxMatrixIndex)\n",
    "    speedTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    accTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    angleTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    newVehicleIDList=[]\n",
    "    vanishedVehicleList=[]\n",
    "    curMatrixIndex=0\n",
    "    matrixIndexAndVehicleIDRecordDictParam['time']=getValueByLable([\"Global_Time\"],valueLists[0])['Global_Time']\n",
    "    #fill out all tensors\n",
    "    for eachValueList in valueLists:\n",
    "        #get values from eachValueList, generate dict\n",
    "        returnedEachValueDict=getValueByLable(['Vehicle_ID','Local_X','Local_Y','v_Vel','v_Acc'],eachValueList)\n",
    "        indexOfVehicle=findMatrixIndexByVehicleID(matrixIndexAndVehicleIDRecordDictParam,returnedEachValueDict['Vehicle_ID'])\n",
    "        if indexOfVehicle!=-1:\n",
    "        #index exist then the vehicle already existed in the preceded frame\n",
    "            matrixIndexAndVehicleIDRecordDictParam[indexOfVehicle]['refresh']=1\n",
    "            curMatrixIndex=indexOfVehicle\n",
    "            #assign to the curMatrixIndex-th row of corresponding tensor\n",
    "            positionTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['Local_X'],returnedEachValueDict['Local_Y']))\n",
    "            speedTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Vel']))\n",
    "            accTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Acc']))\n",
    "            angleTensor[:,curMatrixIndex]=math.atan2(positionTensor[0,curMatrixIndex]-\\\n",
    "                                                     prePositionTensor[0,curMatrixIndex],\\\n",
    "                                                    positionTensor[1,curMatrixIndex]-prePositionTensor[1,curMatrixIndex])\n",
    "        else:\n",
    "        #a new vehicle ID\n",
    "            newVehicleIDList.append(copy.deepcopy(returnedEachValueDict['Vehicle_ID']))\n",
    "            curMatrixIndex=findEmptyMatrixIndex(matrixIndexAndVehicleIDRecordDictParam)\n",
    "            matrixIndexAndVehicleIDRecordDictParam[curMatrixIndex]['Vehicle_ID']=copy.deepcopy(returnedEachValueDict['Vehicle_ID'])\n",
    "            matrixIndexAndVehicleIDRecordDictParam[curMatrixIndex]['refresh']=1\n",
    "            #assign to the curMatrixIndex-th row of corresponding tensor\n",
    "            positionTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['Local_X'],returnedEachValueDict['Local_Y']))\n",
    "            speedTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Vel']))\n",
    "            accTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Acc']))\n",
    "            angleTensor[:,curMatrixIndex]=math.atan2(positionTensor[0,curMatrixIndex]-\\\n",
    "                                                     prePositionTensor[0,curMatrixIndex],\\\n",
    "                                                    positionTensor[1,curMatrixIndex]-prePositionTensor[1,curMatrixIndex])\n",
    "    for i in range(0,maxMatrixIndex):\n",
    "    #find vanished vehicle and remove from dict\n",
    "        if matrixIndexAndVehicleIDRecordDictParam[i]['refresh']==0:\n",
    "            #if refresh=0 then the corresponding vehicle ID was not found in this frame\n",
    "            vanishedVehicleList.append(copy.deepcopy(matrixIndexAndVehicleIDRecordDictParam[i]['Vehicle_ID']))\n",
    "            matrixIndexAndVehicleIDRecordDictParam[i]['refresh']=-1\n",
    "            matrixIndexAndVehicleIDRecordDictParam[i]['Vehicle_ID']=-1\n",
    "    \n",
    "    for i in range(0,maxMatrixIndex):\n",
    "    #set all refrshed which equivalent to 1 to 0 to prepare for the next frame\n",
    "        if matrixIndexAndVehicleIDRecordDictParam[i]['refresh']==1:\n",
    "                #if refresh=0 then the corresponding vehicle ID was not found in this frame\n",
    "                matrixIndexAndVehicleIDRecordDictParam[i]['refresh']=0\n",
    "\n",
    "    return positionTensor,speedTensor,accTensor,angleTensor,newVehicleIDList,vanishedVehicleList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as utils\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fromDirGenerateDict(trajectoryDir):\n",
    "    trajectoryDataFile=open('/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt')\n",
    "    count=0\n",
    "    allLineList=[]\n",
    "    count=0\n",
    "    for count,line in enumerate(trajectoryDataFile):\n",
    "        #read a single line, remove space and enter\n",
    "        lineList=line.split(' ')\n",
    "        try:\n",
    "            while True:\n",
    "                lineList.remove('')\n",
    "        except:\n",
    "            try:\n",
    "                lineList.remove('\\n')\n",
    "            except:\n",
    "                pass\n",
    "            pass\n",
    "        for i in range(0,lineList.__len__()):\n",
    "            # convert string to float\n",
    "            lineList[i]=float(lineList[i])\n",
    "        allLineList.append(lineList)\n",
    "    valueDict=rearrangeDataByGlobalTime(allLineList)\n",
    "    return valueDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tensorsDataset(Dataset):\n",
    "    def __init__(self, trajectoryFileList, numberOfTensorsEachBatch=100,lableTensorEachBatch=2):\n",
    "        if(numberOfTensorsEachBatch<5):\n",
    "            raise Exception(\"THE NUMBER OF TENSORS IN EACH BATCH IS TOO SMALL\")\n",
    "        self.valueDictList=[]\n",
    "        self.sizeList=[]\n",
    "        self.numberOfTensorsEachBatch=numberOfTensorsEachBatch\n",
    "        self.lableTensorEachBatch=lableTensorEachBatch\n",
    "        self.allTensorsEachBatch=numberOfTensorsEachBatch+lableTensorEachBatch\n",
    "        self.keysList=[]\n",
    "        for eachFile in trajectoryFileList:\n",
    "            valueDict=fromDirGenerateDict(eachFile)\n",
    "            self.valueDictList.append(copy.deepcopy(valueDict))\n",
    "            self.sizeList.append(valueDict.keys().__len__()-self.allTensorsEachBatch)\n",
    "            sortedKeys=list(valueDict.keys())\n",
    "            sortedKeys.sort()\n",
    "            self.keysList.append(copy.deepcopy(sortedKeys))\n",
    "\n",
    "    def __len__(self):\n",
    "        allLen=0\n",
    "        for length in self.sizeList:\n",
    "            allLen=allLen+length\n",
    "        return allLen\n",
    "    \n",
    "    def fromIdxMapToList(self,idx):\n",
    "        \"\"\"\n",
    "        since there are several lists,we have to know which list shoud we use and the ture index in the list\n",
    "        Return:\n",
    "            the trueIndex, listIndex\n",
    "        \"\"\"\n",
    "        countSection=0\n",
    "        for i in range(0,self.sizeList.__len__()):\n",
    "            countSection+=self.sizeList[i]\n",
    "            if(idx<countSection):\n",
    "                return idx-countSection+self.sizeList[i],i\n",
    "            \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        #initialize trueIndex, listIndex\n",
    "        #\n",
    "        #this dict record the relation between matrix index and vehicle ID in the last frame\n",
    "        matrixIndexAndVehicleIDRecordDict={}\n",
    "        #initialize dict above\n",
    "        for i in range(0,maxMatrixIndex):\n",
    "            matrixIndexAndVehicleIDRecordDict[i]={'Vehicle_ID':-1,'refresh':-1}\n",
    "        matrixIndexAndVehicleIDRecordDict['time']=-1\n",
    "        trueIndex,listIndex=self.fromIdxMapToList(idx)\n",
    "        itemDict={'positionTensorList':[],'speedTensorList':[],'accTensorList':[],'angleTensorList':[],'time':[]}\n",
    "        valueDict=self.valueDictList[listIndex] #valueDict is the Dict of many frames\n",
    "        dictKeys=self.keysList[listIndex]\n",
    "        #generate tensors of first frame\n",
    "        positionTensor,speedTensor,accTensor,angleTensor,newVehicleList\\\n",
    "        =readFirstFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[trueIndex]])\n",
    "        angleSinTensor=torch.sin(angleTensor)\n",
    "        angleCosTensor=torch.cos(angleTensor)\n",
    "        combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                 speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                 accTensor.mul(angleCosTensor)),0)\n",
    "        allCombineTensorTrain=combinedTensor.unsqueeze(0)\n",
    "        allCombineTensorValid=0\n",
    "#         itemDict['positionTensorList'].append(positionTensor)\n",
    "#         itemDict['speedTensorList'].append(speedTensor)\n",
    "#         itemDict['accTensorList'].append(accTensor)\n",
    "#         itemDict['angleTensorList'].append(angleTensor)\n",
    "#         time=getValueByLable(['Global_Time'],valueDict[dictKeys[trueIndex]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]][0]\n",
    "#         itemDict['time'].append(time)\n",
    "        \n",
    "        for i in range(trueIndex+1,trueIndex+self.allTensorsEachBatch):\n",
    "            positionTensor,speedTensor,accTensor,angleTensor,newVehicleList,vanishedVehicleList\\\n",
    "            =readGeneralFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[i]],positionTensor)\n",
    "            angleSinTensor=torch.sin(angleTensor)\n",
    "            angleCosTensor=torch.cos(angleTensor)\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "            if i<self.numberOfTensorsEachBatch+trueIndex:\n",
    "                allCombineTensorTrain=torch.cat((allCombineTensorTrain,combinedTensor.unsqueeze(0)),0)\n",
    "            elif i==self.numberOfTensorsEachBatch+trueIndex:\n",
    "                allCombineTensorValid=combinedTensor.unsqueeze(0)\n",
    "            else:\n",
    "                allCombineTensorValid=torch.cat((allCombineTensorValid,combinedTensor.unsqueeze(0)),0)\n",
    "#             itemDict['positionTensorList'].append(positionTensor)\n",
    "#             itemDict['speedTensorList'].append(speedTensor)\n",
    "#             itemDict['accTensorList'].append(accTensor)\n",
    "#             itemDict['angleTensorList'].append(angleTensor)\n",
    "#             time=getValueByLable(['Global_Time'],valueDict[dictKeys[i]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]]\n",
    "#             itemDict['time'].append(time)\n",
    "        return allCombineTensorTrain,allCombineTensorValid\n",
    "# trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0805am-0820am/trajectories-0805am-0820am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0820am-0835am/trajectories-0820am-0835am.txt']\n",
    "trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def generateAdjacencyMatrix(batchedPositionTensor,lambdaX,lambdaY,omegaX,omegaY,m):\n",
    "    \"\"\"\n",
    "    Using batched position tensor generate batched adjacency matrix\n",
    "    Args:\n",
    "        batchedPositionTensor: a batch of position tensor, which size in (batch, timeSequence,2,vehicles), the \n",
    "        value 2 in dim=2 is the position of x and y. \n",
    "        lambda1,lambda2,omega1,omega2,m are parameters of the function. m<1\n",
    "        see detail in my notebook\n",
    "    Returns:\n",
    "        a batch of adjacency matrix\n",
    "    Example:\n",
    "        if given a batch of combined tensor, named theTensor, which size as below:\n",
    "            (4,100,6,250)\n",
    "        which means 4 batches, 100 time step, 6 dimension which respectively of positonx, positony, velocityx, \n",
    "        velocityy, accx,accy.\n",
    "        then we apply the function in such way:\n",
    "        generateAdjacencyMatrix(theTensor(:,:,0:1,:))\n",
    "    \"\"\"\n",
    "    print(batchedPositionTensor.size())\n",
    "    sizeOfEachMatrix=batchedPositionTensor[0,0,0,:].size()[0]\n",
    "    print(sizeOfEachMatrix)\n",
    "    for batchI in range(batchedPositionTensor.size()[0]): #revolve each batch\n",
    "#         print('batchI',batchI)\n",
    "        timeStepsMatrixList=[]\n",
    "        for timeStepI in range(batchedPositionTensor.size()[1]):#revolve each time step\n",
    "#             print('timeStepI:',timeStepI)\n",
    "#             adjacencyMatrix=np.zeros((sizeOfEachMatrix,sizeOfEachMatrix))\n",
    "            adjacencyList=[]\n",
    "            tempPositionList=batchedPositionTensor[batchI,timeStepI,:,:].numpy().tolist()\n",
    "#             start=time.time()\n",
    "            for i in range(sizeOfEachMatrix):\n",
    "                tempLineList=[]\n",
    "                for j in range(sizeOfEachMatrix):\n",
    "#                     adjacencyMatrix[i,j]=1\n",
    "                    if (tempPositionList[1][i]*tempPositionList[1][j]==0):\n",
    "                        toZero=0\n",
    "                    else:\n",
    "                        toZero=1\n",
    "                        \n",
    "                    #calculate original element with linear function\n",
    "#                     tempLineList.append((1-abs(tempPositionList[1][i]-tempPositionList[1][j]))*\\\n",
    "#                         (1-abs(tempPositionList[0][i]-tempPositionList[0][j]))*toZero)\n",
    "                    \n",
    "                    #calculate original element with exponential function\n",
    "                    element=(omegaY/(math.exp(lambdaY*(abs(tempPositionList[1][j]-tempPositionList[1][i])))))*\\\n",
    "                    (omegaX/(math.exp(lambdaX*(abs(tempPositionList[0][j]-tempPositionList[0][i])))))*toZero\n",
    "                    tempLineList.append(element)\n",
    "#                     adjacencyMatrix[i,j]=(batchedPositionTensor[batchI,timeStepI,1,i]-batchedPositionTensor[batchI,timeStepI,1,j])*\\\n",
    "#                         (batchedPositionTensor[batchI,timeStepI,0,i]-batchedPositionTensor[batchI,timeStepI,0,j])\n",
    "#                     (omegaY/math.exp(lambdaX*abs(batchedPositionTensor[batchI,timeStepI,1,i]-batchedPositionTensor[batchI,timeStepI,1,j])))*\\\n",
    "#                     (omegaX/math.exp(lambdaY*abs(batchedPositionTensor[batchI,timeStepI,0,i]-batchedPositionTensor[batchI,timeStepI,0,j])))\n",
    "                    \n",
    "                    #calculate original element with expenential\n",
    "#                     adjacencyMatrix[i,j]=\n",
    "#                     (omegaY/math.exp(lambdaX*abs(batchedPositionTensor[batchI,timeStepI,1,i]-batchedPositionTensor[batchI,timeStepI,1,j])))*\\\n",
    "#                     (omegaX/math.exp(lambdaY*abs(batchedPositionTensor[batchI,timeStepI,0,i]-batchedPositionTensor[batchI,timeStepI,0,j])))\n",
    "                    if(tempPositionList[1][j]-tempPositionList[1][i]<0):\n",
    "                        #if i follows j, then multiple m, m<1\n",
    "                        tempLineList[j]=tempLineList[j]*m\n",
    "                adjacencyList.append(tempLineList)\n",
    "            \n",
    "#             end=time.time()\n",
    "#             print(end-start)\n",
    "            adjacencyMatrix=torch.tensor(adjacencyList).unsqueeze(0)\n",
    "            if timeStepI==0:\n",
    "                matrixSequenceInTimeStepDim=adjacencyMatrix\n",
    "            else:\n",
    "                matrixSequenceInTimeStepDim=\\\n",
    "                torch.cat((matrixSequenceInTimeStepDim,adjacencyMatrix),0)\n",
    "        matrixSequenceInTimeStepDim=matrixSequenceInTimeStepDim.unsqueeze(0)\n",
    "        if batchI==0:\n",
    "            matrixSequenceInBatchDim=matrixSequenceInTimeStepDim\n",
    "        else:\n",
    "            matrixSequenceInBatchDim=torch.cat((matrixSequenceInBatchDim,matrixSequenceInTimeStepDim),0)            \n",
    "    return matrixSequenceInBatchDim\n",
    "\n",
    "def tensorNormalization(inputTensor,minValue,maxValue):\n",
    "    inputTensor.div_(maxValue)\n",
    "    \n",
    "def batchNormalizationForCombinedTensor(inputBatchedTensor,minX,maxX,minY,maxY,minV,maxV,minA,maxA):\n",
    "    tensorNormalization(inputBatchedTensor[:,:,0,:],minX,maxX)\n",
    "    tensorNormalization(inputBatchedTensor[:,:,1,:],minY,maxY)\n",
    "    tensorNormalization(inputBatchedTensor[:,:,2:4,:],minV,maxV)\n",
    "    tensorNormalization(inputBatchedTensor[:,:,4:6,:],minA,maxA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    __init__(self, input_size, cell_size, hidden_size, output_last = True)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, cell_size, hidden_size, output_last = True):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        \"\"\"\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((input, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "            return Hidden_State\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectorDataSet=tensorsDataset(trajectoryFileList)\n",
    "dataLoader=DataLoader(trajectorDataSet,batch_size=4,shuffle=True,num_workers=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch] *",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
