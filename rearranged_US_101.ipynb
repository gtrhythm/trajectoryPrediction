{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def getValueByLable(lableList,valueList):\n",
    "    \"\"\"\n",
    "    For instance, given a lable list ['Local_X','Local_Y'] and a value list [2.0, 24.0, 437.0, 1118846981300.0, 16.254, \n",
    "    79.349, 6451167.199, 1873312.382, 14.5, 4.9, 2.0, 39.14, -5.73, 2.0, 0.0, 13.0, 0.0, 0.0] which values sorted by the \n",
    "    order of allLableList below, the function return a value Dict {'Local_X':16.254, 'Local_Y':79.349}\n",
    "    Args:\n",
    "        lableList: the list of lables you've required, such as['Vehicle_ID', 'Total_Frames','Global_Time']\n",
    "        valueList: the list contains all legally value, sorted by:['Vehicle_ID', 'Frame_ID','Total_Frames','Global_Time','Local_X','Local_Y','Global_X','Global_Y',\\\n",
    "                      'v_Length','v_Width','v_Class','v_Vel','v_Acc','Lane_ID','Preceding','Following','Space_Headway',\\\n",
    "                      'Time_Headway']\n",
    "    Returns: \n",
    "        value dict of the input lables\n",
    "    For instance, given a lable list ['Local_X','Local_Y'] and a value list [2.0, 24.0, 437.0, 1118846981300.0, 16.254, \n",
    "    79.349, 6451167.199, 1873312.382, 14.5, 4.9, 2.0, 39.14, -5.73, 2.0, 0.0, 13.0, 0.0, 0.0] which values sorted by the \n",
    "    order of allLableList above, the function return a value List [16.254, 79.349]\n",
    "\n",
    "    \"\"\"\n",
    "    allLableList=['Vehicle_ID', 'Frame_ID','Total_Frames','Global_Time','Local_X','Local_Y','Global_X','Global_Y',\\\n",
    "                  'v_Length','v_Width','v_Class','v_Vel','v_Acc','Lane_ID','Preceding','Following','Space_Headway',\\\n",
    "                  'Time_Headway']\n",
    "    valueDictReturn={}\n",
    "    for lableItem in lableList:\n",
    "        valueDictReturn[lableItem]=valueList[allLableList.index(lableItem)]\n",
    "    return valueDictReturn\n",
    "\n",
    "def rearrangeDataByGlobalTime(allValueLists):\n",
    "    '''\n",
    "    Args:\n",
    "        allValueLists: all values have been read from a txt file which have already been converted to a list\n",
    "    Returns:\n",
    "        dict have been arranged by global time. One single global time generally contains several value lists.\n",
    "    '''\n",
    "    valueDict={}\n",
    "    for valueList in allValueLists:\n",
    "        dictKey=getValueByLable(['Global_Time'],valueList)['Global_Time']\n",
    "        if dictKey in valueDict:\n",
    "            # if dictKey already there, then add valueList to the list of the key\n",
    "            valueDict[dictKey].append(valueList)\n",
    "        else:\n",
    "            #else, create a list and append valueList on it\n",
    "            valueDict[dictKey]=[valueList]\n",
    "    return valueDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def readFirstFrame(matrixIndexAndVehicleIDRecordDictParam, valueLists):\n",
    "    \"\"\"\n",
    "    To generate the first set of tensors from the first frame\n",
    "    Args:\n",
    "        matrixIndexAndVehicleIDRecordDictParam: just as its name\n",
    "        valueLists: a list consists of all valuelist at one time\n",
    "    Returns:\n",
    "        several tensors arranged by: positionTensor, speedTensor, accTensor, angleTensor,newVehicleList(type:list)\n",
    "    \n",
    "    \"\"\"\n",
    "    maxMatrixIndex=matrixIndexAndVehicleIDRecordDictParam.keys().__len__()-1\n",
    "    #tensors initialize\n",
    "    positionTensor=torch.zeros(2,maxMatrixIndex)\n",
    "    speedTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    accTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    angleTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    newVehicleIDList=[]\n",
    "    curMatrixIndex=0\n",
    "    matrixIndexAndVehicleIDRecordDictParam['time']=getValueByLable([\"Global_Time\"],valueLists[0])['Global_Time']\n",
    "    #fill out all tensors\n",
    "    for eachValueList in valueLists:\n",
    "        #get values from eachValueList, generate dict\n",
    "        returnedEachValueDict=getValueByLable(['Vehicle_ID','Local_X','Local_Y','v_Vel','v_Acc'],eachValueList)\n",
    "        #assign to the curMatrixIndex-th row of corresponding tensor\n",
    "        #angle Tensor assignment is not neeed for the initial value of each element in it is already zero\n",
    "        positionTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['Local_X'],returnedEachValueDict['Local_Y']))\n",
    "        speedTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Vel']))\n",
    "        accTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Acc']))\n",
    "        #then handle the record matrix\n",
    "        matrixIndexAndVehicleIDRecordDictParam[curMatrixIndex]['Vehicle_ID']=returnedEachValueDict['Vehicle_ID']\n",
    "        matrixIndexAndVehicleIDRecordDictParam[curMatrixIndex]['refresh']=0\n",
    "        newVehicleIDList.append(copy.deepcopy(returnedEachValueDict['Vehicle_ID']))\n",
    "        curMatrixIndex=curMatrixIndex+1\n",
    "    return positionTensor,speedTensor,accTensor,angleTensor,newVehicleIDList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMatrixIndexByVehicleID(matrixIndexAndVehicleIDRecordDictParam, vehicle_ID):\n",
    "    for i in range(0, len(matrixIndexAndVehicleIDRecordDictParam)-1):\n",
    "        if matrixIndexAndVehicleIDRecordDictParam[i]['Vehicle_ID']==vehicle_ID:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def findEmptyMatrixIndex(matrixIndexAndVehicleIDRecordDictParam):\n",
    "    for i in range(0, len(matrixIndexAndVehicleIDRecordDictParam)-1):\n",
    "        if matrixIndexAndVehicleIDRecordDictParam[i]['Vehicle_ID']==-1:\n",
    "            #Vehicle_ID=-1 when there is no existed vehicle ID bounding to the index\n",
    "            return i\n",
    "    raise Exception(\"NO EMPTY ELEMENT IN MATRIX\")\n",
    "\n",
    "def readGeneralFrame(matrixIndexAndVehicleIDRecordDictParam, valueLists, prePositionTensor):\n",
    "    \"\"\"\n",
    "    To generate the first set of tensors from the general frame that have a preceding one\n",
    "    Args:\n",
    "        matrixIndexAndVehicleIDRecordDictParam: just as its name\n",
    "        valueLists: a list consists of all valuelist at one time\n",
    "        prePositionTensor: positionTensor from the preceding frame, which is used to calculate angle tensor\n",
    "    Returns:\n",
    "        everal tensors arranged by: positionTensor, speedTensor, accTensor, angleTensor,newVehicleList(type:list),\n",
    "        vanishedVehicleList(type:list)\n",
    "    \n",
    "    \"\"\"\n",
    "    #tensors initialize\n",
    "    maxMatrixIndex=matrixIndexAndVehicleIDRecordDictParam.keys().__len__()-1\n",
    "    positionTensor=torch.zeros(2,maxMatrixIndex)\n",
    "    speedTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    accTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    angleTensor=torch.zeros(1,maxMatrixIndex)\n",
    "    newVehicleIDList=[]\n",
    "    vanishedVehicleList=[]\n",
    "    curMatrixIndex=0\n",
    "    matrixIndexAndVehicleIDRecordDictParam['time']=getValueByLable([\"Global_Time\"],valueLists[0])['Global_Time']\n",
    "    #fill out all tensors\n",
    "    for eachValueList in valueLists:\n",
    "        #get values from eachValueList, generate dict\n",
    "        returnedEachValueDict=getValueByLable(['Vehicle_ID','Local_X','Local_Y','v_Vel','v_Acc'],eachValueList)\n",
    "        indexOfVehicle=findMatrixIndexByVehicleID(matrixIndexAndVehicleIDRecordDictParam,returnedEachValueDict['Vehicle_ID'])\n",
    "        if indexOfVehicle!=-1:\n",
    "        #index exist then the vehicle already existed in the preceded frame\n",
    "            matrixIndexAndVehicleIDRecordDictParam[indexOfVehicle]['refresh']=1\n",
    "            curMatrixIndex=indexOfVehicle\n",
    "            #assign to the curMatrixIndex-th row of corresponding tensor\n",
    "            positionTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['Local_X'],returnedEachValueDict['Local_Y']))\n",
    "            speedTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Vel']))\n",
    "            accTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Acc']))\n",
    "            angleTensor[:,curMatrixIndex]=math.atan2(positionTensor[0,curMatrixIndex]-\\\n",
    "                                                     prePositionTensor[0,curMatrixIndex],\\\n",
    "                                                    positionTensor[1,curMatrixIndex]-prePositionTensor[1,curMatrixIndex])\n",
    "        else:\n",
    "        #a new vehicle ID\n",
    "            newVehicleIDList.append(copy.deepcopy(returnedEachValueDict['Vehicle_ID']))\n",
    "            curMatrixIndex=findEmptyMatrixIndex(matrixIndexAndVehicleIDRecordDictParam)\n",
    "            matrixIndexAndVehicleIDRecordDictParam[curMatrixIndex]['Vehicle_ID']=copy.deepcopy(returnedEachValueDict['Vehicle_ID'])\n",
    "            matrixIndexAndVehicleIDRecordDictParam[curMatrixIndex]['refresh']=1\n",
    "            #assign to the curMatrixIndex-th row of corresponding tensor\n",
    "            positionTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['Local_X'],returnedEachValueDict['Local_Y']))\n",
    "            speedTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Vel']))\n",
    "            accTensor[:,curMatrixIndex]=torch.tensor((returnedEachValueDict['v_Acc']))\n",
    "            angleTensor[:,curMatrixIndex]=math.atan2(positionTensor[0,curMatrixIndex]-\\\n",
    "                                                     prePositionTensor[0,curMatrixIndex],\\\n",
    "                                                    positionTensor[1,curMatrixIndex]-prePositionTensor[1,curMatrixIndex])\n",
    "    for i in range(0,maxMatrixIndex):\n",
    "    #find vanished vehicle and remove from dict\n",
    "        if matrixIndexAndVehicleIDRecordDictParam[i]['refresh']==0:\n",
    "            #if refresh=0 then the corresponding vehicle ID was not found in this frame\n",
    "            vanishedVehicleList.append(copy.deepcopy(matrixIndexAndVehicleIDRecordDictParam[i]['Vehicle_ID']))\n",
    "            matrixIndexAndVehicleIDRecordDictParam[i]['refresh']=-1\n",
    "            matrixIndexAndVehicleIDRecordDictParam[i]['Vehicle_ID']=-1\n",
    "    \n",
    "    for i in range(0,maxMatrixIndex):\n",
    "    #set all refrshed which equivalent to 1 to 0 to prepare for the next frame\n",
    "        if matrixIndexAndVehicleIDRecordDictParam[i]['refresh']==1:\n",
    "                #if refresh=0 then the corresponding vehicle ID was not found in this frame\n",
    "                matrixIndexAndVehicleIDRecordDictParam[i]['refresh']=0\n",
    "\n",
    "    return positionTensor,speedTensor,accTensor,angleTensor,newVehicleIDList,vanishedVehicleList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as utils\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fromDirGenerateDict(trajectoryDir):\n",
    "    trajectoryDataFile=open('/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt')\n",
    "    count=0\n",
    "    allLineList=[]\n",
    "    count=0\n",
    "    for count,line in enumerate(trajectoryDataFile):\n",
    "        #read a single line, remove space and enter\n",
    "        lineList=line.split(' ')\n",
    "        try:\n",
    "            while True:\n",
    "                lineList.remove('')\n",
    "        except:\n",
    "            try:\n",
    "                lineList.remove('\\n')\n",
    "            except:\n",
    "                pass\n",
    "            pass\n",
    "        for i in range(0,lineList.__len__()):\n",
    "            # convert string to float\n",
    "            lineList[i]=float(lineList[i])\n",
    "        allLineList.append(lineList)\n",
    "    valueDict=rearrangeDataByGlobalTime(allLineList)\n",
    "    return valueDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valueDict=fromDirGenerateDict(1)\n",
    "theKey=list(valueDict.keys())[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x3600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def visualizeData(valueVisualize, maxLength=5000,maxWidth=100,blocksize=10):\n",
    "    \"\"\"\n",
    "    visualize a frame on an white image\n",
    "    Args:\n",
    "        valueVisualize: a list of values, each item in the list can be obtained by function \n",
    "        getValueByLable\n",
    "    Returns:\n",
    "        the image of the input frame\n",
    "    \"\"\"\n",
    "    image=np.ones((maxLength,maxWidth,3),dtype=np.int8)\n",
    "    image=image*255\n",
    "    figure=plt.figure(figsize=(10,50))\n",
    "    axe=figure.add_subplot(1,1,1)\n",
    "    \n",
    "    for item in valueVisualize:\n",
    "        infoList=getValueByLable(['Vehicle_ID','Local_X','Local_Y'],item)\n",
    "        vehicleID=infoList['Vehicle_ID']\n",
    "        x=int(infoList['Local_X'])\n",
    "        y=int(infoList['Local_Y'])\n",
    "        colorR=int((vehicleID+100)%255)\n",
    "        colorG=int((vehicleID+150)%255)\n",
    "        colorB=int((vehicleID+200)%255)\n",
    "        cv2.circle(image,(x,y),int(blocksize/2),(colorB,colorG,colorR),-1) #\n",
    "    axe.imshow(image)\n",
    "visualizeData(valueDict[theKey])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tensorsDataset(Dataset):\n",
    "    def __init__(self, trajectoryFileList, numberOfTensorsEachBatch=100,lableTensorEachBatch=2):\n",
    "        if(numberOfTensorsEachBatch<5):\n",
    "            raise Exception(\"THE NUMBER OF TENSORS IN EACH BATCH IS TOO SMALL\")\n",
    "        self.valueDictList=[]\n",
    "        self.sizeList=[]\n",
    "        self.numberOfTensorsEachBatch=numberOfTensorsEachBatch\n",
    "        self.lableTensorEachBatch=lableTensorEachBatch\n",
    "        self.allTensorsEachBatch=numberOfTensorsEachBatch+lableTensorEachBatch\n",
    "        self.keysList=[]\n",
    "        for eachFile in trajectoryFileList:\n",
    "            valueDict=fromDirGenerateDict(eachFile)\n",
    "            self.valueDictList.append(copy.deepcopy(valueDict))\n",
    "            self.sizeList.append(valueDict.keys().__len__()-self.allTensorsEachBatch)\n",
    "            sortedKeys=list(valueDict.keys())\n",
    "            sortedKeys.sort()\n",
    "            self.keysList.append(copy.deepcopy(sortedKeys))\n",
    "\n",
    "    def __len__(self):\n",
    "        allLen=0\n",
    "        for length in self.sizeList:\n",
    "            allLen=allLen+length\n",
    "        return allLen\n",
    "    \n",
    "    def fromIdxMapToList(self,idx):\n",
    "        \"\"\"\n",
    "        since there are several lists,we have to know which list shoud we use and the ture index in the list\n",
    "        Return:\n",
    "            the trueIndex, listIndex\n",
    "        \"\"\"\n",
    "        countSection=0\n",
    "        for i in range(0,self.sizeList.__len__()):\n",
    "            countSection+=self.sizeList[i]\n",
    "            if(idx<countSection):\n",
    "                return idx-countSection+self.sizeList[i],i\n",
    "            \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        #initialize trueIndex, listIndex\n",
    "        #\n",
    "        #this dict record the relation between matrix index and vehicle ID in the last frame\n",
    "        matrixIndexAndVehicleIDRecordDict={}\n",
    "        #initialize dict above\n",
    "        for i in range(0,maxMatrixIndex):\n",
    "            matrixIndexAndVehicleIDRecordDict[i]={'Vehicle_ID':-1,'refresh':-1}\n",
    "        matrixIndexAndVehicleIDRecordDict['time']=-1\n",
    "        trueIndex,listIndex=self.fromIdxMapToList(idx)\n",
    "        itemDict={'positionTensorList':[],'speedTensorList':[],'accTensorList':[],'angleTensorList':[],'time':[]}\n",
    "        valueDict=self.valueDictList[listIndex] #valueDict is the Dict of many frames\n",
    "        dictKeys=self.keysList[listIndex]\n",
    "        #generate tensors of first frame\n",
    "        positionTensor,speedTensor,accTensor,angleTensor,newVehicleList\\\n",
    "        =readFirstFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[trueIndex]])\n",
    "        angleSinTensor=torch.sin(angleTensor)\n",
    "        angleCosTensor=torch.cos(angleTensor)\n",
    "        combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                 speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                 accTensor.mul(angleCosTensor)),0)\n",
    "        allCombineTensorTrain=combinedTensor.unsqueeze(0)\n",
    "        allCombineTensorValid=0\n",
    "#         itemDict['positionTensorList'].append(positionTensor)\n",
    "#         itemDict['speedTensorList'].append(speedTensor)\n",
    "#         itemDict['accTensorList'].append(accTensor)\n",
    "#         itemDict['angleTensorList'].append(angleTensor)\n",
    "#         time=getValueByLable(['Global_Time'],valueDict[dictKeys[trueIndex]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]][0]\n",
    "#         itemDict['time'].append(time)\n",
    "        \n",
    "        for i in range(trueIndex+1,trueIndex+self.allTensorsEachBatch):\n",
    "            positionTensor,speedTensor,accTensor,angleTensor,newVehicleList,vanishedVehicleList\\\n",
    "            =readGeneralFrame(matrixIndexAndVehicleIDRecordDict,valueDict[dictKeys[i]],positionTensor)\n",
    "            angleSinTensor=torch.sin(angleTensor)\n",
    "            angleCosTensor=torch.cos(angleTensor)\n",
    "            combinedTensor=torch.cat((positionTensor,speedTensor.mul(angleSinTensor),\\\n",
    "                                     speedTensor.mul(angleCosTensor),accTensor.mul(angleSinTensor),\\\n",
    "                                     accTensor.mul(angleCosTensor)),0)\n",
    "            if i<self.numberOfTensorsEachBatch+trueIndex:\n",
    "                allCombineTensorTrain=torch.cat((allCombineTensorTrain,combinedTensor.unsqueeze(0)),0)\n",
    "            elif i==self.numberOfTensorsEachBatch+trueIndex:\n",
    "                allCombineTensorValid=combinedTensor.unsqueeze(0)\n",
    "            else:\n",
    "                allCombineTensorValid=torch.cat((allCombineTensorValid,combinedTensor.unsqueeze(0)),0)\n",
    "#             itemDict['positionTensorList'].append(positionTensor)\n",
    "#             itemDict['speedTensorList'].append(speedTensor)\n",
    "#             itemDict['accTensorList'].append(accTensor)\n",
    "#             itemDict['angleTensorList'].append(angleTensor)\n",
    "#             time=getValueByLable(['Global_Time'],valueDict[dictKeys[i]][0]) #valueDict[sortedDitKey[theIndexOfSortedDictKey]]\n",
    "#             itemDict['time'].append(time)\n",
    "        return allCombineTensorTrain,allCombineTensorValid\n",
    "# trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0805am-0820am/trajectories-0805am-0820am.txt',\\\n",
    "#                    '/home/wangyuchen/trajectory_dataset/US101/0820am-0835am/trajectories-0820am-0835am.txt']\n",
    "trajectoryFileList=['/home/wangyuchen/trajectory_dataset/US101/0750am-0805am/trajectories-0750am-0805am.txt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def generateAdjacencyMatrix(batchedPositionTensor,lambdaX,lambdaY,omegaX,omegaY,m):\n",
    "    \"\"\"\n",
    "    Using batched position tensor generate batched adjacency matrix\n",
    "    Args:\n",
    "        batchedPositionTensor: a batch of position tensor, which size in (batch, timeSequence,2,vehicles), the \n",
    "        value 2 in dim=2 is the position of x and y. \n",
    "        lambda1,lambda2,omega1,omega2,m are parameters of the function. m<1\n",
    "        see detail in my notebook\n",
    "    Returns:\n",
    "        a batch of adjacency matrix\n",
    "    Example:\n",
    "        if given a batch of combined tensor, named theTensor, which size as below:\n",
    "            (4,100,6,250)\n",
    "        which means 4 batches, 100 time step, 6 dimension which respectively of positonx, positony, velocityx, \n",
    "        velocityy, accx,accy.\n",
    "        then we apply the function in such way:\n",
    "        generateAdjacencyMatrix(theTensor(:,:,0:1,:))\n",
    "    \"\"\"\n",
    "    print(batchedPositionTensor.size())\n",
    "    sizeOfEachMatrix=batchedPositionTensor[0,0,0,:].size()[0]\n",
    "    print(sizeOfEachMatrix)\n",
    "    for batchI in range(batchedPositionTensor.size()[0]): #revolve each batch\n",
    "#         print('batchI',batchI)\n",
    "        timeStepsMatrixList=[]\n",
    "        for timeStepI in range(batchedPositionTensor.size()[1]):#revolve each time step\n",
    "#             print('timeStepI:',timeStepI)\n",
    "#             adjacencyMatrix=np.zeros((sizeOfEachMatrix,sizeOfEachMatrix))\n",
    "            adjacencyList=[]\n",
    "            tempPositionList=batchedPositionTensor[batchI,timeStepI,:,:].numpy().tolist()\n",
    "#             start=time.time()\n",
    "            for i in range(sizeOfEachMatrix):\n",
    "                tempLineList=[]\n",
    "                for j in range(sizeOfEachMatrix):\n",
    "#                     adjacencyMatrix[i,j]=1\n",
    "                    if (tempPositionList[1][i]*tempPositionList[1][j]==0):\n",
    "                        toZero=0\n",
    "                    else:\n",
    "                        toZero=1\n",
    "                        \n",
    "                    #calculate original element with linear function\n",
    "#                     tempLineList.append((1-abs(tempPositionList[1][i]-tempPositionList[1][j]))*\\\n",
    "#                         (1-abs(tempPositionList[0][i]-tempPositionList[0][j]))*toZero)\n",
    "                    \n",
    "                    #calculate original element with exponential function\n",
    "                    element=(omegaY/(math.exp(lambdaY*(abs(tempPositionList[1][j]-tempPositionList[1][i])))))*\\\n",
    "                    (omegaX/(math.exp(lambdaX*(abs(tempPositionList[0][j]-tempPositionList[0][i])))))*toZero\n",
    "                    tempLineList.append(element)\n",
    "#                     adjacencyMatrix[i,j]=(batchedPositionTensor[batchI,timeStepI,1,i]-batchedPositionTensor[batchI,timeStepI,1,j])*\\\n",
    "#                         (batchedPositionTensor[batchI,timeStepI,0,i]-batchedPositionTensor[batchI,timeStepI,0,j])\n",
    "#                     (omegaY/math.exp(lambdaX*abs(batchedPositionTensor[batchI,timeStepI,1,i]-batchedPositionTensor[batchI,timeStepI,1,j])))*\\\n",
    "#                     (omegaX/math.exp(lambdaY*abs(batchedPositionTensor[batchI,timeStepI,0,i]-batchedPositionTensor[batchI,timeStepI,0,j])))\n",
    "                    \n",
    "                    #calculate original element with expenential\n",
    "#                     adjacencyMatrix[i,j]=\n",
    "#                     (omegaY/math.exp(lambdaX*abs(batchedPositionTensor[batchI,timeStepI,1,i]-batchedPositionTensor[batchI,timeStepI,1,j])))*\\\n",
    "#                     (omegaX/math.exp(lambdaY*abs(batchedPositionTensor[batchI,timeStepI,0,i]-batchedPositionTensor[batchI,timeStepI,0,j])))\n",
    "                    if(tempPositionList[1][j]-tempPositionList[1][i]<0):\n",
    "                        #if i follows j, then multiple m, m<1\n",
    "                        tempLineList[j]=tempLineList[j]*m\n",
    "                adjacencyList.append(tempLineList)\n",
    "            \n",
    "#             end=time.time()\n",
    "#             print(end-start)\n",
    "            adjacencyMatrix=torch.tensor(adjacencyList).unsqueeze(0)\n",
    "            if timeStepI==0:\n",
    "                matrixSequenceInTimeStepDim=adjacencyMatrix\n",
    "            else:\n",
    "                matrixSequenceInTimeStepDim=\\\n",
    "                torch.cat((matrixSequenceInTimeStepDim,adjacencyMatrix),0)\n",
    "        matrixSequenceInTimeStepDim=matrixSequenceInTimeStepDim.unsqueeze(0)\n",
    "        if batchI==0:\n",
    "            matrixSequenceInBatchDim=matrixSequenceInTimeStepDim\n",
    "        else:\n",
    "            matrixSequenceInBatchDim=torch.cat((matrixSequenceInBatchDim,matrixSequenceInTimeStepDim),0)            \n",
    "    return matrixSequenceInBatchDim\n",
    "\n",
    "def tensorNormalization(inputTensor,minValue,maxValue):\n",
    "    inputTensor.div_(maxValue)\n",
    "    \n",
    "def batchNormalizationForCombinedTensor(inputBatchedTensor,minX,maxX,minY,maxY,minV,maxV,minA,maxA):\n",
    "    tensorNormalization(inputBatchedTensor[:,:,0,:],minX,maxX)\n",
    "    tensorNormalization(inputBatchedTensor[:,:,1,:],minY,maxY)\n",
    "    tensorNormalization(inputBatchedTensor[:,:,2:4,:],minV,maxV)\n",
    "    tensorNormalization(inputBatchedTensor[:,:,4:6,:],minA,maxA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    __init__(self, input_size, cell_size, hidden_size, output_last = True)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, cell_size, hidden_size, output_last = True):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        \"\"\"\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((input, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "            return Hidden_State\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectorDataSet=tensorsDataset(trajectoryFileList)\n",
    "dataLoader=DataLoader(trajectorDataSet,batch_size=4,shuffle=True,num_workers=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch] *",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
